{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import h5py\n",
    "import logging\n",
    "from os import path\n",
    "from pandas import HDFStore\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pathlib\n",
    "import shutil\n",
    "import tempfile\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.modeling\n",
    "import tensorflow_docs.plots\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q git+https://github.com/tensorflow/docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = pathlib.Path(\"C:/tmp/\")/\"tensorboard_logs\"\n",
    "shutil.rmtree(logdir, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/tmp/tensorboard_logs')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data from hdf5 file\n",
    "root_path = \"Z:/elekin\"\n",
    "rdo_root_path = path.join(root_path,\"02-RESULTADOS/03-HANDWRITTING\")\n",
    "h5file = path.join(rdo_root_path, \"00-OUTPUT/archimedean-\")\n",
    "h5filename = h5file + str(17) + \".h5\"\n",
    "hdf = HDFStore(h5filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load and scale timeseries between 0 and 1\n",
    "raw_df = hdf['results/residues/rd'].T\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_df = pd.DataFrame(scaler.fit_transform(raw_df))\n",
    "scaled_df['target'] = hdf.get('source/labels').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test datasets (0.8, 0.2)\n",
    "shuffle_df = scaled_df.sample(frac=1).reset_index(drop=True)\n",
    "msk = np.random.rand(len(shuffle_df)) < 0.8\n",
    "x_train = shuffle_df[msk].iloc[:,0:4096].values.astype('float32')\n",
    "y_train = shuffle_df[msk]['target'].values.astype('int8')\n",
    "x_test = shuffle_df[~msk].iloc[:,0:4096].values.astype('float32')\n",
    "y_test = shuffle_df[~msk]['target'].values.astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Early stop configuration\n",
    "earlystop_callback = EarlyStopping(\n",
    "  monitor='val_accuracy', min_delta=0.0001,\n",
    "  patience=20)\n",
    "\n",
    "training_earlystop_callback = EarlyStopping(\n",
    "  monitor='accuracy', min_delta=0.0001,\n",
    "  patience=5)\n",
    "\n",
    "def get_callbacks(name):\n",
    "    return [\n",
    "        tfdocs.modeling.EpochDots(),\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_binary_crossentropy', patience=200),\n",
    "        tf.keras.callbacks.TensorBoard(logdir/name),\n",
    "      ]\n",
    "\n",
    "def compile_and_fit(model, name, optimizer=None, max_epochs=1000):\n",
    "    if optimizer is None:\n",
    "        optimizer = get_optimizer()\n",
    "        model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy', 'binary_crossentropy'])\n",
    "        model.summary()\n",
    "        history = model.fit(x_train, y_train, batch_size=None, use_multiprocessing=True, \n",
    "                            validation_data=(x_test,y_test), epochs=max_epochs, callbacks=get_callbacks(name),\n",
    "                            verbose=0)\n",
    "        return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(2019) # establecemos la semilla para tensorflow\n",
    "np.random.seed(2019) # establecemos la semilla para numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many models train better if you gradually reduce the learning rate during training. \n",
    "Use optimizers.schedules to reduce the learning rate over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEPS_PER_EPOCH = 1\n",
    "FEATURES = 4096\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "  0.001,\n",
    "  decay_steps=STEPS_PER_EPOCH*1000,\n",
    "  decay_rate=1,\n",
    "  staircase=False)\n",
    "\n",
    "def get_optimizer():\n",
    "  return tf.keras.optimizers.Adam(lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()# para evitar que entrenamientos annteriores afecten\n",
    "cnn = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),# expand the dimension form (50, 4096) to (50, 4096, 1)\n",
    "                      input_shape=[4096]),\n",
    "    tf.keras.layers.Conv1D(filters=16, kernel_size=5,\n",
    "                       activation=tf.nn.relu,\n",
    "                      input_shape=[4096, 1]),\n",
    "    tf.keras.layers.MaxPool1D(),\n",
    "    tf.keras.layers.Conv1D(filters=16, kernel_size=5,\n",
    "                           activation=tf.nn.relu),\n",
    "#    tf.keras.layers.LSTM(128, activation=tf.nn.relu),\n",
    "     tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(32, activation=tf.nn.relu),\n",
    "     tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_histories = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_histories['cnn/conv1d'] = compile_and_fit(tiny, \"cnn/conv1d\", optimizer=None, max_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter_loss = tfdocs.plots.HistoryPlotter(metric = 'binary_crossentropy', smoothing_std=10)\n",
    "plotter_loss.plot(size_histories)\n",
    "plt.ylim([0., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter_acc = tfdocs.plots.HistoryPlotter(metric = 'accuracy', smoothing_std=10)\n",
    "plotter_acc.plot(size_histories)\n",
    "plt.ylim([0.3, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter_acc.plot(size_histories)\n",
    "a = plt.xscale('log')\n",
    "plt.xlim([5, max(plt.xlim())])\n",
    "plt.ylim([0.5, 0.9])\n",
    "plt.xlabel(\"Epochs [Log Scale]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter_loss.plot(size_histories)\n",
    "a = plt.xscale('log')\n",
    "plt.xlim([5, max(plt.xlim())])\n",
    "plt.ylim([0., 0.9])\n",
    "plt.xlabel(\"Epochs [Log Scale]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Timed out waiting for TensorBoard to start. It may still be running as pid 244."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir {logdir}/sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
