{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current tracking uri: file:///./mlruns\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.modeling\n",
    "import tensorflow_docs.plots\n",
    "\n",
    "from utils import windowed_dataset, build_basic_lstm,split_train_test,split_train_test_val\n",
    "from config import *\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import datetime\n",
    "\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"file:///./mlruns\")\n",
    "tracking_uri = mlflow.get_tracking_uri()\n",
    "print(\"Current tracking uri: {}\".format(tracking_uri))\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = [35.0, 7.0]\n",
    "\n",
    "today=datetime.date.today().strftime(\"%Y%m%d\")\n",
    "coefficients=17\n",
    "\n",
    "rd_filename='tmp_residues_{}_{}.csv'.format(coefficients, today)\n",
    "rd_feat_filename='tmp_residues_feat_{}_{}.csv'.format(coefficients, today)\n",
    "rd_feat_norm_filename='tmp_residues_feat_norm_{}_{}.csv'.format(coefficients, today)\n",
    "\n",
    "r_filename='tmp_radius_{}.csv'.format(today)\n",
    "r_feat_filename='tmp_radius_feat_{}.csv'.format(today)\n",
    "r_feat_norm_filename='tmp_radius_feat_norm_{}.csv'.format(today)\n",
    "\n",
    "binary_labels_filename ='tmp_spiral_binaly_labels_{}.csv'.format(today)\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs\n",
    "!rm -rf ./tensorflow_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_df = pd.read_csv(rd_filename, index_col=0)\n",
    "binary_labels = pd.read_csv(binary_labels_filename, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53, 4096)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=rd_df.values.astype('float32')\n",
    "y=binary_labels.values.astype('int8').reshape(-1,1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Window function is applied to Dataset objects. Same windows lenghts for each time series corresponding to each subject are built asigning the rigth label. Then they are included in same Dataset object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#windowing parameters\n",
    "num_features = x.shape[1]\n",
    "window_size = int(num_features/5 + 1)\n",
    "shuffle_buffer = num_features\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=tf.data.Dataset.from_tensor_slices(x)\n",
    "labels=(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(None,), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(1,), dtype=tf.int8, name=None))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#series, window_size, batch_size,label\n",
    "for i,features in enumerate(x):\n",
    "    new = windowed_dataset(features,window_size,batch_size,labels[i])\n",
    "    if i>0:\n",
    "        dataset = tf.data.Dataset.concatenate(dataset,new)\n",
    "    else:\n",
    "        dataset = new\n",
    "        \n",
    "dataset.cache()\n",
    "dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET_SIZE = int((num_features/window_size)*50)\n",
    "# #TODO import from utils API\n",
    "# train_size = int(0.7 * DATASET_SIZE)\n",
    "# val_size = int(0.15 * DATASET_SIZE)\n",
    "# test_size = int(0.15 * DATASET_SIZE)\n",
    "\n",
    "# full_dataset = dataset\n",
    "# full_dataset = full_dataset.shuffle(DATASET_SIZE, seed=seed)\n",
    "# train_dataset = full_dataset.take(train_size).batch(mini_batch_size).prefetch(2).cache()\n",
    "# test_dataset = full_dataset.skip(train_size)\n",
    "# val_dataset = test_dataset.skip(test_size).batch(mini_batch_size).prefetch(2).cache()\n",
    "# test_dataset = test_dataset.take(test_size).batch(mini_batch_size).prefetch(2).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_SIZE = int((num_features/window_size)*50)\n",
    "train_dataset, val_dataset, test_dataset = split_train_test_val(dataset, DATASET_SIZE, train_ratio=0.67, val_ratio=0.17, test_ratio=0.16, shuffle_buffer=DATASET_SIZE, seed=seed, mini_batch_size=mini_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Early stop configuration\n",
    "earlystop_callback = EarlyStopping(\n",
    "  monitor='val_accuracy', min_delta=1e-3,\n",
    "  patience=200)\n",
    "\n",
    "training_earlystop_callback = EarlyStopping(\n",
    "  monitor='accuracy', min_delta=1e-4,\n",
    "  patience=200)\n",
    "\n",
    "log_dir = \"tensorflow_log/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "def get_callbacks(name):\n",
    "    return [\n",
    "        tfdocs.modeling.EpochDots(),\n",
    "        earlystop_callback,\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50, min_delta=1e-1),\n",
    "        tf.keras.callbacks.TensorBoard('tensorflow_log'),\n",
    "      ]\n",
    "\n",
    "def compile_and_fit(model, train_dataset, test_dataset, name, optimizer=None, max_epochs=1000):\n",
    "    tf.keras.backend.clear_session()# avoid clutter from old models and layers, especially when memory is limited\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    tf.random.set_seed(seed) # establecemos la semilla para tensorflow\n",
    "    history = model.fit(train_dataset, \n",
    "                        use_multiprocessing=True, \n",
    "                        validation_data=test_dataset, epochs=max_epochs, \n",
    "                        callbacks=get_callbacks(name),\n",
    "                        verbose=1, shuffle=True)\n",
    "    return history\n",
    "\n",
    "# Many models train better if you gradually reduce the learning rate during training. \n",
    "# Use optimizers.schedules to reduce the learning rate over time:\n",
    "def get_optimizer(steps_per_epoch=1, lr=1e-4, multiplier=1000):\n",
    "    lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(lr,\n",
    "                                                                 decay_steps=steps_per_epoch*multiplier,\n",
    "                                                                 decay_rate=1,\n",
    "                                                                 staircase=False)\n",
    "    return tf.keras.optimizers.Adam(lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-5ebfde54a45a38c0\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-5ebfde54a45a38c0\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir tensorflow_log/fit/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_histories = {}\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda (Lambda)              (None, 1, 820)            0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 8)                 26528     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 26,537\n",
      "Trainable params: 26,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10000\n",
      "      3/Unknown - 2s 251ms/step - loss: 0.2441 - accuracy: 0.5833WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0021s vs `on_train_batch_begin` time: 0.0575s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0021s vs `on_train_batch_end` time: 0.0254s). Check your callbacks.\n",
      "42/42 [==============================] - 70s 2s/step - loss: 0.0538 - accuracy: 0.9699 - val_loss: 0.2815 - val_accuracy: 0.6033\n",
      "\n",
      "Epoch: 0, accuracy:0.9699,  loss:0.0538,  val_accuracy:0.6033,  val_loss:0.2815,  \n",
      ".Epoch 2/10000\n",
      "42/42 [==============================] - 31s 745ms/step - loss: 0.0338 - accuracy: 1.0000 - val_loss: 0.2874 - val_accuracy: 0.6033\n",
      ".Epoch 3/10000\n",
      "34/42 [=======================>......] - ETA: 0s - loss: 0.0294 - accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    mlflow.tensorflow.autolog()\n",
    "    # LSTM basic architectures --> #TODO import from utils API\n",
    "    tf.keras.backend.clear_session()# para evitar que entrenamientos annteriores afecten\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=1),input_shape=(window_size,)))\n",
    "    model.add(tf.keras.layers.LSTM(8, activation=tf.nn.tanh, return_sequences=False))\n",
    "    # model.add(tf.keras.layers.Dropout(dropout))\n",
    "    model.add(tf.keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
    "\n",
    "    size_histories['lstm/windows'] = compile_and_fit(model, train_dataset, \n",
    "                                                  val_dataset,\n",
    "                                                  \"fcnn/tiny\", \n",
    "    #                                               optimizer=get_optimizer(),\n",
    "                                                  optimizer=tf.keras.optimizers.Adam(learning_rate=lr), \n",
    "    #                                               optimizer = tf.keras.optimizers.SGD(lr=lr, momentum=0.9),\n",
    "                                                  max_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n#######################Evaluation###########################\")\n",
    "# Evaluate the model on the test data using `evaluate`\n",
    "print('train acc:', max(size_histories['lstm/windows'].history[\"accuracy\"]))\n",
    "print('val acc:', max(size_histories['lstm/windows'].history[\"val_accuracy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter_loss = tfdocs.plots.HistoryPlotter(metric = 'loss', smoothing_std=1)\n",
    "plotter_loss.plot(size_histories)\n",
    "# plt.ylim(0., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter_acc = tfdocs.plots.HistoryPlotter(metric = 'accuracy', smoothing_std=1)\n",
    "plotter_acc.plot(size_histories)\n",
    "# plt.ylim([0., 1.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4,1)\n",
    "fig.tight_layout()\n",
    "\n",
    "i=0\n",
    "for (x,y),ax in zip(dataset.take(4), axes):\n",
    "    ax.plot(x.numpy(), color=colors[y.numpy()[0]])\n",
    "    ax.set_xticks(range(i,window_size,100))\n",
    "    input_tensor=tf.expand_dims(x, axis=1)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter(dataset.filter(f).take(4).cache()).next()\n",
    "prediction=model.predict(first[0])\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### model.evaluate(test_dataset)[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
