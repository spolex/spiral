{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current tracking uri: file:///./mlruns\n",
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.modeling\n",
    "import tensorflow_docs.plots\n",
    "\n",
    "from utils import windowed_dataset, build_basic_lstm,split_train_test,split_train_test_val\n",
    "from config import *\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import datetime\n",
    "\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"file:///./mlruns\")\n",
    "tracking_uri = mlflow.get_tracking_uri()\n",
    "print(\"Current tracking uri: {}\".format(tracking_uri))\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = [35.0, 7.0]\n",
    "\n",
    "today=datetime.date.today().strftime(\"%Y%m%d\")\n",
    "coefficients=17\n",
    "\n",
    "rd_filename='tmp_residues_{}_{}.csv'.format(coefficients, today)\n",
    "rd_feat_filename='tmp_residues_feat_{}_{}.csv'.format(coefficients, today)\n",
    "rd_feat_norm_filename='tmp_residues_feat_norm_{}_{}.csv'.format(coefficients, today)\n",
    "\n",
    "r_filename='tmp_radius_{}.csv'.format(today)\n",
    "r_feat_filename='tmp_radius_feat_{}.csv'.format(today)\n",
    "r_feat_norm_filename='tmp_radius_feat_norm_{}.csv'.format(today)\n",
    "\n",
    "binary_labels_filename ='tmp_spiral_binaly_labels_{}.csv'.format(today)\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs\n",
    "!rm -rf ./tensorflow_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_df = pd.read_csv(rd_filename, index_col=0)\n",
    "binary_labels = pd.read_csv(binary_labels_filename, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53, 4096)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=rd_df.values.astype('float32')\n",
    "y=binary_labels.values.astype('int8').reshape(-1,1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Window function is applied to Dataset objects. Same windows lenghts for each time series corresponding to each subject are built asigning the rigth label. Then they are included in same Dataset object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#windowing parameters\n",
    "num_features = x.shape[1]\n",
    "window_size = int(num_features/5 + 1)\n",
    "shuffle_buffer = num_features\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=tf.data.Dataset.from_tensor_slices(x)\n",
    "labels=(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(None,), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(1,), dtype=tf.int8, name=None))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#series, window_size, batch_size,label\n",
    "for i,features in enumerate(x):\n",
    "    new = windowed_dataset(features,window_size,batch_size,labels[i])\n",
    "    if i>0:\n",
    "        dataset = tf.data.Dataset.concatenate(dataset,new)\n",
    "    else:\n",
    "        dataset = new\n",
    "        \n",
    "dataset.cache()\n",
    "dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET_SIZE = int((num_features/window_size)*50)\n",
    "# #TODO import from utils API\n",
    "# train_size = int(0.7 * DATASET_SIZE)\n",
    "# val_size = int(0.15 * DATASET_SIZE)\n",
    "# test_size = int(0.15 * DATASET_SIZE)\n",
    "\n",
    "# full_dataset = dataset\n",
    "# full_dataset = full_dataset.shuffle(DATASET_SIZE, seed=seed)\n",
    "# train_dataset = full_dataset.take(train_size).batch(mini_batch_size).prefetch(2).cache()\n",
    "# test_dataset = full_dataset.skip(train_size)\n",
    "# val_dataset = test_dataset.skip(test_size).batch(mini_batch_size).prefetch(2).cache()\n",
    "# test_dataset = test_dataset.take(test_size).batch(mini_batch_size).prefetch(2).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_SIZE = int((num_features/window_size)*50)\n",
    "train_dataset, val_dataset, test_dataset = split_train_test_val(dataset, DATASET_SIZE, train_ratio=0.67, val_ratio=0.17, test_ratio=0.16, shuffle_buffer=DATASET_SIZE, seed=seed, mini_batch_size=mini_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Early stop configuration\n",
    "earlystop_callback = EarlyStopping(\n",
    "  monitor='val_accuracy', min_delta=1e-3,\n",
    "  patience=200)\n",
    "\n",
    "training_earlystop_callback = EarlyStopping(\n",
    "  monitor='accuracy', min_delta=1e-4,\n",
    "  patience=200)\n",
    "\n",
    "log_dir = \"tensorflow_log/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "def get_callbacks(name):\n",
    "    return [\n",
    "        tfdocs.modeling.EpochDots(),\n",
    "        earlystop_callback,\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50, min_delta=1e-1),\n",
    "        tf.keras.callbacks.TensorBoard('tensorflow_log'),\n",
    "      ]\n",
    "\n",
    "def compile_and_fit(model, train_dataset, test_dataset, name, optimizer=None, max_epochs=1000):\n",
    "    tf.keras.backend.clear_session()# avoid clutter from old models and layers, especially when memory is limited\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    tf.random.set_seed(seed) # establecemos la semilla para tensorflow\n",
    "    history = model.fit(train_dataset, \n",
    "                        use_multiprocessing=True, \n",
    "                        validation_data=test_dataset, epochs=max_epochs, \n",
    "                        callbacks=get_callbacks(name),\n",
    "                        verbose=1, shuffle=True)\n",
    "    return history\n",
    "\n",
    "# Many models train better if you gradually reduce the learning rate during training. \n",
    "# Use optimizers.schedules to reduce the learning rate over time:\n",
    "def get_optimizer(steps_per_epoch=1, lr=1e-4, multiplier=1000):\n",
    "    lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(lr,\n",
    "                                                                 decay_steps=steps_per_epoch*multiplier,\n",
    "                                                                 decay_rate=1,\n",
    "                                                                 staircase=False)\n",
    "    return tf.keras.optimizers.Adam(lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-5ebfde54a45a38c0\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-5ebfde54a45a38c0\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir tensorflow_log/fit/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_histories = {}\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda (Lambda)              (None, 1, 820)            0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 8)                 26528     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 26,537\n",
      "Trainable params: 26,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "      3/Unknown - 1s 207ms/step - loss: 0.3970 - accuracy: 0.0000e+00WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0019s vs `on_train_batch_begin` time: 0.0481s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0019s vs `on_train_batch_end` time: 0.0203s). Check your callbacks.\n",
      "42/42 [==============================] - 32s 766ms/step - loss: 0.2706 - accuracy: 0.2530 - val_loss: 0.2487 - val_accuracy: 0.5998\n",
      "\n",
      "Epoch: 0, accuracy:0.2530,  loss:0.2706,  val_accuracy:0.5998,  val_loss:0.2487,  \n",
      ".Epoch 2/5\n",
      "42/42 [==============================] - 31s 746ms/step - loss: 0.2295 - accuracy: 1.0000 - val_loss: 0.2444 - val_accuracy: 0.5999\n",
      ".Epoch 3/5\n",
      "42/42 [==============================] - 30s 740ms/step - loss: 0.2048 - accuracy: 1.0000 - val_loss: 0.2416 - val_accuracy: 0.6001\n",
      ".Epoch 4/5\n",
      "42/42 [==============================] - 30s 726ms/step - loss: 0.1826 - accuracy: 1.0000 - val_loss: 0.2400 - val_accuracy: 0.6002\n",
      ".Epoch 5/5\n",
      "42/42 [==============================] - 30s 735ms/step - loss: 0.1628 - accuracy: 1.0000 - val_loss: 0.2397 - val_accuracy: 0.6002\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp21gt30mc/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp21gt30mc/model/data/model/assets\n",
      "2021/10/24 10:46:19 ERROR mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmp21gt30mc/model, flavor: keras)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/mlflow/utils/environment.py\", line 212, in infer_pip_requirements\n",
      "    return _infer_requirements(model_uri, flavor)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/mlflow/utils/requirements_utils.py\", line 263, in _infer_requirements\n",
      "    modules = _capture_imported_modules(model_uri, flavor)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/mlflow/utils/requirements_utils.py\", line 232, in _capture_imported_modules\n",
      "    json.dumps(sys.path),\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/mlflow/utils/requirements_utils.py\", line 173, in _run_command\n",
      "    raise MlflowException(msg)\n",
      "mlflow.exceptions.MlflowException: Encountered an unexpected error while running ['/usr/bin/python3', '/usr/local/lib/python3.6/dist-packages/mlflow/utils/_capture_modules.py', '--model-path', '/tmp/tmp21gt30mc/model', '--flavor', 'keras', '--output-file', '/tmp/tmpsfvnbei7/imported_modules.txt', '--sys-path', '[\"/usr/lib/python36.zip\", \"/usr/local/lib/python3.6/dist-packages/git/ext/gitdb\", \"/usr/lib/python3.6\", \"/usr/lib/python3.6/lib-dynload\", \"\", \"/usr/local/lib/python3.6/dist-packages\", \"/usr/lib/python3/dist-packages\", \"/usr/local/lib/python3.6/dist-packages/IPython/extensions\", \"/root/.ipython\", \"/usr/local/lib/python3.6/dist-packages/gitdb/ext/smmap\"]']\n",
      "exit status: 1\n",
      "stdout: \n",
      "stderr: /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py:435: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/mlflow/utils/_capture_modules.py\", line 125, in <module>\n",
      "    main()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/mlflow/utils/_capture_modules.py\", line 112, in main\n",
      "    mlflow.pyfunc.load_model(model_path)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/mlflow/pyfunc/__init__.py\", line 667, in load_model\n",
      "    model_impl = importlib.import_module(conf[MAIN])._load_pyfunc(data_path)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/mlflow/utils/_capture_modules.py\", line 109, in _load_pyfunc_patch\n",
      "    return original(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/mlflow/keras.py\", line 548, in _load_pyfunc\n",
      "    path, keras_module=keras_module, save_format=save_format, compile=should_compile\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/mlflow/keras.py\", line 473, in _load_model\n",
      "    return keras_models.load_model(model_path, custom_objects=custom_objects, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py\", line 206, in load_model\n",
      "    return saved_model_load.load(filepath, compile, options)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/load.py\", line 155, in load\n",
      "    keras_loader.finalize_objects()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/load.py\", line 626, in finalize_objects\n",
      "    self._reconstruct_all_models()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/load.py\", line 645, in _reconstruct_all_models\n",
      "    self._reconstruct_model(model_id, model, layers)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/load.py\", line 681, in _reconstruct_model\n",
      "    model.__init__(layers, name=config['name'])\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py\", line 522, in _method_wrapper\n",
      "    result = method(self, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py\", line 141, in __init__\n",
      "    self.add(layer)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py\", line 522, in _method_wrapper\n",
      "    result = method(self, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py\", line 228, in add\n",
      "    output_tensor = layer(self.outputs[0])\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 970, in __call__\n",
      "    input_list)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 1108, in _functional_construction_call\n",
      "    inputs, input_masks, args, kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 840, in _keras_tensor_symbolic_call\n",
      "    return self._infer_output_signature(inputs, args, kwargs, input_masks)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 880, in _infer_output_signature\n",
      "    outputs = call_fn(inputs, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py\", line 919, in call\n",
      "    result = self.function(inputs, **kwargs)\n",
      "  File \"<ipython-input-14-6cd93e462ee9>\", line 6, in <lambda>\n",
      "NameError: name 'tf' is not defined\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    mlflow.tensorflow.autolog()\n",
    "    # LSTM basic architectures --> #TODO import from utils API\n",
    "    tf.keras.backend.clear_session()# para evitar que entrenamientos annteriores afecten\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=1),input_shape=(window_size,)))\n",
    "    model.add(tf.keras.layers.LSTM(8, activation=tf.nn.tanh, return_sequences=False))\n",
    "    # model.add(tf.keras.layers.Dropout(dropout))\n",
    "    model.add(tf.keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
    "\n",
    "    size_histories['lstm/windows'] = compile_and_fit(model, train_dataset, \n",
    "                                                  val_dataset,\n",
    "                                                  \"fcnn/tiny\", \n",
    "    #                                               optimizer=get_optimizer(),\n",
    "                                                  optimizer=tf.keras.optimizers.Adam(learning_rate=lr), \n",
    "    #                                               optimizer = tf.keras.optimizers.SGD(lr=lr, momentum=0.9),\n",
    "                                                  max_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n#######################Evaluation###########################\")\n",
    "# Evaluate the model on the test data using `evaluate`\n",
    "print('train acc:', max(size_histories['lstm/windows'].history[\"accuracy\"]))\n",
    "print('val acc:', max(size_histories['lstm/windows'].history[\"val_accuracy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter_loss = tfdocs.plots.HistoryPlotter(metric = 'loss', smoothing_std=1)\n",
    "plotter_loss.plot(size_histories)\n",
    "# plt.ylim(0., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter_acc = tfdocs.plots.HistoryPlotter(metric = 'accuracy', smoothing_std=1)\n",
    "plotter_acc.plot(size_histories)\n",
    "# plt.ylim([0., 1.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4,1)\n",
    "fig.tight_layout()\n",
    "\n",
    "i=0\n",
    "for (x,y),ax in zip(dataset.take(4), axes):\n",
    "    ax.plot(x.numpy(), color=colors[y.numpy()[0]])\n",
    "    ax.set_xticks(range(i,window_size,100))\n",
    "    input_tensor=tf.expand_dims(x, axis=1)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter(dataset.filter(f).take(4).cache()).next()\n",
    "prediction=model.predict(first[0])\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### model.evaluate(test_dataset)[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
