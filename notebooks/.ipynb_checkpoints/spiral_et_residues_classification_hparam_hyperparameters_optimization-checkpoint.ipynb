{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import h5py\n",
    "import logging\n",
    "from os import path\n",
    "from pandas import HDFStore\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EarlyStopping' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-1073ade258c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Early stop configuration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m earlystop_callback = EarlyStopping(\n\u001b[0m\u001b[0;32m      3\u001b[0m   \u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_delta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m   patience=2)\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'EarlyStopping' is not defined"
     ]
    }
   ],
   "source": [
    "#Early stop configuration\n",
    "earlystop_callback = EarlyStopping(\n",
    "  monitor='val_accuracy', min_delta=0.0001,\n",
    "  patience=2)\n",
    "\n",
    "training_earlystop_callback = EarlyStopping(\n",
    "  monitor='accuracy', min_delta=0.0001,\n",
    "  patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data from hdf5 file\n",
    "root_path = \"Z:/elekin\"\n",
    "rdo_root_path = path.join(root_path,\"02-RESULTADOS/03-HANDWRITTING\")\n",
    "h5file = path.join(rdo_root_path, \"00-OUTPUT/archimedean-\")\n",
    "h5filename = h5file + str(17) + \".h5\"\n",
    "hdf = HDFStore(h5filename)\n",
    "#Load and scale timeseries between 0 and 1\n",
    "raw_df = hdf['results/residues/rd'].T\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_df = pd.DataFrame(scaler.fit_transform(raw_df))\n",
    "scaled_df['target'] = hdf.get('source/labels').values\n",
    "# split data into train and test datasets (0.8, 0.2)\n",
    "shuffle_df = scaled_df.sample(frac=1).reset_index(drop=True)\n",
    "msk = np.random.rand(len(shuffle_df)) < 0.8\n",
    "x_train = shuffle_df[msk].iloc[:,0:4096].values.astype('float32')\n",
    "y_train = shuffle_df[msk]['target'].values.astype('int8')\n",
    "x_test = shuffle_df[~msk].iloc[:,0:4096].values.astype('float32')\n",
    "y_test = shuffle_df[~msk]['target'].values.astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([16, 32, 64, 128, 256]))\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.1, 0.2))\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n",
    "HP_CONV_KERNEL_SIZE = hp.HParam(\"conv_kernel_size\", hp.Discrete([3, 5]))\n",
    "\n",
    "\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "  hp.hparams_config(\n",
    "    hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_OPTIMIZER, HP_CONV_KERNEL_SIZE],\n",
    "    metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(hparams, num_epochs):\n",
    "  model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),# expand the dimension form (50, 4096) to (50, 4096, 1)\n",
    "                      input_shape=[4096]),\n",
    "     tf.keras.layers.Conv1D(filters=16, kernel_size=hparams[HP_CONV_KERNEL_SIZE],\n",
    "                      strides=1, padding=\"causal\",\n",
    "                      activation=tf.nn.relu,\n",
    "                      input_shape=[4096, 1]),\n",
    "    tf.keras.layers.Bidirectional( tf.keras.layers.LSTM(hparams[HP_NUM_UNITS], activation=tf.nn.tanh)),\n",
    "    tf.keras.layers.Dense(hparams[HP_NUM_UNITS], activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
    "    tf.keras.layers.Dense(1, activation=tf.nn.sigmoid),\n",
    "  ])\n",
    "  model.compile(\n",
    "      optimizer=hparams[HP_OPTIMIZER],\n",
    "      loss='binary_crossentropy',\n",
    "      metrics=['accuracy'],\n",
    "  )\n",
    "\n",
    "  model.fit(x_train, y_train, epochs=num_epochs, callbacks=[training_earlystop_callback]) # Run with 1 epoch to speed things up for demo purposes\n",
    "  _, accuracy = model.evaluate(x_test, y_test)\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(run_dir, hparams, num_epochs=20):\n",
    "  with tf.summary.create_file_writer(run_dir).as_default():\n",
    "    hp.hparams(hparams)  # record the values used in this trial\n",
    "    accuracy = train_test_model(hparams, num_epochs)\n",
    "    tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-0\n",
      "{'num_units': 16, 'dropout': 0.1, 'optimizer': 'adam'}\n",
      "Train on 40 samples\n",
      "40/40 [==============================] - 12s 290ms/sample - loss: 0.6887 - accuracy: 0.5500\n",
      "10/1 [============================================================================================================================================================================================================================================================================================================] - 2s 163ms/sample - loss: 0.6922 - accuracy: 0.5000\n",
      "--- Starting trial: run-1\n",
      "{'num_units': 16, 'dropout': 0.1, 'optimizer': 'sgd'}\n",
      "Train on 40 samples\n",
      "40/40 [==============================] - 11s 265ms/sample - loss: 0.7073 - accuracy: 0.3750\n",
      "10/1 [============================================================================================================================================================================================================================================================================================================] - 2s 162ms/sample - loss: 0.6907 - accuracy: 0.5000\n",
      "--- Starting trial: run-2\n",
      "{'num_units': 16, 'dropout': 0.2, 'optimizer': 'adam'}\n",
      "Train on 40 samples\n",
      "40/40 [==============================] - 11s 279ms/sample - loss: 0.6915 - accuracy: 0.5000\n",
      "10/1 [============================================================================================================================================================================================================================================================================================================] - 2s 174ms/sample - loss: 0.6883 - accuracy: 0.6000\n",
      "--- Starting trial: run-3\n",
      "{'num_units': 16, 'dropout': 0.2, 'optimizer': 'sgd'}\n",
      "Train on 40 samples\n",
      "40/40 [==============================] - 12s 300ms/sample - loss: 0.7058 - accuracy: 0.4250\n",
      "10/1 [============================================================================================================================================================================================================================================================================================================] - 1s 137ms/sample - loss: 0.6918 - accuracy: 0.6000\n",
      "--- Starting trial: run-4\n",
      "{'num_units': 32, 'dropout': 0.1, 'optimizer': 'adam'}\n",
      "Train on 40 samples\n",
      "40/40 [==============================] - 14s 354ms/sample - loss: 0.6902 - accuracy: 0.6000\n",
      "10/1 [============================================================================================================================================================================================================================================================================================================] - 2s 168ms/sample - loss: 0.6936 - accuracy: 0.4000\n",
      "--- Starting trial: run-5\n",
      "{'num_units': 32, 'dropout': 0.1, 'optimizer': 'sgd'}\n",
      "Train on 40 samples\n",
      "40/40 [==============================] - 14s 360ms/sample - loss: 0.7097 - accuracy: 0.4250\n",
      "10/1 [============================================================================================================================================================================================================================================================================================================] - 2s 204ms/sample - loss: 0.6967 - accuracy: 0.5000\n",
      "--- Starting trial: run-6\n",
      "{'num_units': 32, 'dropout': 0.2, 'optimizer': 'adam'}\n",
      "Train on 40 samples\n",
      "40/40 [==============================] - 17s 419ms/sample - loss: 0.6904 - accuracy: 0.7000\n",
      "10/1 [============================================================================================================================================================================================================================================================================================================] - 2s 179ms/sample - loss: 0.6921 - accuracy: 0.4000\n",
      "--- Starting trial: run-7\n",
      "{'num_units': 32, 'dropout': 0.2, 'optimizer': 'sgd'}\n",
      "Train on 40 samples\n",
      "40/40 [==============================] - 15s 369ms/sample - loss: 0.6934 - accuracy: 0.4500\n",
      "10/1 [============================================================================================================================================================================================================================================================================================================] - 2s 156ms/sample - loss: 0.6930 - accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "session_num = 0\n",
    "\n",
    "for num_units in HP_NUM_UNITS.domain.values:\n",
    "  for dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\n",
    "    for optimizer in HP_OPTIMIZER.domain.values:\n",
    "      hparams = {\n",
    "          HP_NUM_UNITS: num_units,\n",
    "          HP_DROPOUT: dropout_rate,\n",
    "          HP_OPTIMIZER: optimizer,\n",
    "      }\n",
    "      run_name = \"run-%d\" % session_num\n",
    "      print('--- Starting trial: %s' % run_name)\n",
    "      print({h.name: hparams[h] for h in hparams})\n",
    "      run('logs/hparam_tuning/' + run_name, hparams, 100)\n",
    "      session_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Timed out waiting for TensorBoard to start. It may still be running as pid 31876."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/hparam_tuning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
