{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current tracking uri: http://mlflow_server:5001\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "\n",
    "from utils import windowed_dataset, build_basic_lstm,split_train_test,split_train_test_val, plot_report\n",
    "from config import *\n",
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import datetime\n",
    "\n",
    "import os\n",
    "\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"http://mlflow_server:5001\")\n",
    "tracking_uri = mlflow.get_tracking_uri()\n",
    "print(\"Current tracking uri: {}\".format(tracking_uri))\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = [35.0, 7.0]\n",
    "\n",
    "today=datetime.date.today().strftime(\"%Y%m%d\")\n",
    "today = 20220905\n",
    "coefficients=17\n",
    "\n",
    "results_path = \"/data/elekin/data/results/handwriting\"\n",
    "\n",
    "rd_filename='residues_{}_{}.csv'.format(coefficients, today)\n",
    "rd_feat_filename='residues_feat_{}_{}.csv'.format(coefficients, today)\n",
    "rd_feat_norm_filename='residues_feat_norm_{}_{}.csv'.format(coefficients, today)\n",
    "\n",
    "r_filename='radius_{}.csv'.format(today)\n",
    "r_feat_filename='radius_feat_{}.csv'.format(today)\n",
    "r_feat_norm_filename='radius_feat_norm_{}.csv'.format(today)\n",
    "\n",
    "binary_labels_filename ='binary_labels_20220903.csv'.format(today)\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "mpl.style.use('seaborn-notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_df = pd.read_csv(os.path.join(results_path, rd_filename), index_col=0)\n",
    "binary_labels = pd.read_csv(os.path.join(results_path, binary_labels_filename), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeYAAAFrCAYAAAAEvSrJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAWlElEQVR4nO3df2zUhf3H8df1J7MVXNGeX0mzr93aOXrCEkFWjZCV2WqEtSspQhWhsrBEs240EQssJCNxuCUjMPYDOxZDAjNu3Wz54TLSLtsSkJDVaL1MIEwMBWxPTytrGZ9ej8/3j33t7EDO3l35vO/u+fgL7nrnS8yHp5/PXa8+13VdAQAAE7K8HgAAAP6DMAMAYAhhBgDAEMIMAIAhhBkAAENyvB5w+fJlDQ8PKzc3Vz6fz+s5AABMKtd1FYlEVFBQoKysK8+PPQ/z8PCwTp486fUMAACuq/Lyct14441X3B4zzI7j6JFHHtHIyIii0ahqamrU3Nysvr4+tbS0aHBwUBUVFfrRj36kvLy8CQ/Lzc0dGxjP4+G9YDCoQCDg9Qwg43DspaaRkRGdPHlyrH//LWaY8/LytHv3bhUUFCgSiaixsVHz58/X888/r1WrVumhhx7Spk2b1N7ersbGxgkP/OjydV5envLz8yf8eNjAfzvAGxx7qeuTXr6N+eYvn8+ngoICSdLo6KhGR0fl8/l09OhR1dTUSJK+8Y1vqLu7O4lzAQDITJ/qNeZoNKr6+nqdOXNGjY2NKikp0dSpU5WT8++H33rrrRoYGEhoSDAYTOjx8FZPT4/XE4CMxLGXfj5VmLOzs9XZ2akLFy7oySef1FtvvZX0IYFAgEsyKaqnp0d33XWX1zOAjMOxl5ocx7nmyeiEvo956tSpmjdvnl577TVduHBBo6OjkqT+/n75/f7ElgIAgNhhfv/993XhwgVJ0qVLl3TkyBF9/vOf17x58/THP/5RkvTSSy+pqqpqcpcCAJABYl7KDoVCam1tVTQaleu6euCBB/TVr35VX/jCF7R27Vpt27ZNX/rSl9TQ0HA99gIAkNZihvmOO+5QR0fHFbeXlJSovb19MjYBAJCx+KxsAAAMIcwAABhCmAEAMIQwI2F8/zkAJI/nP10qE2xqO6KB8EWvZ0yu/f1eL0g6//QbtHnNPV7PAJBhCPN1MBC+qPPvDXs9AwCQAriUDQCAIYQZAABDCDMAAIYQZgAADCHMAAAYQpgBADCEMAMAYAhhBgDAEMIMAIAhhBkAAEMIMwAAhhBmAAAMIcwAABhCmAEAMIQwAwBgCGEGAMAQwgwAgCGEGQAAQwgzAACGEGYAAAwhzAAAGEKYAQAwhDADAGAIYQYAwBDCDACAIYQZAABDCDMAAIYQZgAADCHMAAAYQpgBADCEMAMAYAhhBgDAEMIMAIAhhBkAAENyYn3BO++8o3Xr1ikcDsvn82np0qVauXKlduzYod/85jcqKiqSJLW0tGjBggWTPhgAgHQWM8zZ2dlqbW1VRUWFhoaGtGTJEt17772SpFWrVmn16tWTPhIAgEwRM8zFxcUqLi6WJBUWFqq0tFQDAwOTPgwAgEwUM8wfd/bsWb355puaPXu2Xn31Ve3du1cdHR0KBAJqbW3VtGnT4h4SDAbjfqxl+fn5Xk9AAoLBoBzH8XoG8Il6enq8noAk+9RhHh4eVnNzszZs2KDCwkItX75cTzzxhHw+n7Zv365nn31WW7ZsiXtIIBBI34jt7/d6AeIUCAS8ngB8op6eHt11111ez8AEOY5zzZPRT/Wu7EgkoubmZi1evFjV1dWSpJtvvlnZ2dnKyspSQ0OD3njjjeQsBgAgg8UMs+u62rhxo0pLS9XU1DR2eygUGvt1V1eXysrKJmchAAAZJOal7J6eHnV2dqq8vFy1tbWS/v2tUQcOHNDx48clSTNmzNDmzZsndykAABkgZpjnzJmjEydOXHE737MMAEDy8clfAAAYQpgBADCEMAMAYAhhBoAUlbaf/ZDhJvTJXwCQSja1HdFA+KLXMyZXmn6AkX/6Ddq85h6vZ3iCMANIWwPhizr/3rDXM4AJ4VI2AACGEGYAAAwhzAAAGEKYAQAwhDADAGAIYQYAwBDCDACAIYQZAABDCDMAAIYQZgAADCHMAAAYQpgBADCEMAMAYAhhBgDAEMIMAIAhhBkAAEMIMwAAhhBmAAAMIcwAABhCmAEAMIQwAwBgCGEGAMAQwgwAgCGEGQAAQwgzAACGEGYAAAwhzAAAGEKYAQAwhDADAGAIYQYAwBDCDACAIYQZAABDCDMAAIYQZgAADMmJ9QXvvPOO1q1bp3A4LJ/Pp6VLl2rlypUaHBzU2rVrde7cOc2YMUPbtm3TtGnTrsdmAADSVswz5uzsbLW2turll1/Wiy++qF//+tc6deqU2traVFlZqUOHDqmyslJtbW3XYy8AAGktZpiLi4tVUVEhSSosLFRpaakGBgbU3d2turo6SVJdXZ26uromdSgAAJkg5qXsjzt79qzefPNNzZ49W+FwWMXFxZKkW265ReFwOKEhwWAwocdblZ+f7/UEJCAYDMpxHK9nIA4ce6kvU4+/Tx3m4eFhNTc3a8OGDSosLBx3n8/nk8/nS2hIIBBI3wNpf7/XCxCnQCDg9QQkgmMvpaXr8ec4zjVPRj/Vu7IjkYiam5u1ePFiVVdXS5KmT5+uUCgkSQqFQioqKkrCXAAAMlvMMLuuq40bN6q0tFRNTU1jt1dVVamjo0OS1NHRoYULF07aSAAAMkXMS9k9PT3q7OxUeXm5amtrJUktLS1as2aNvvvd76q9vV233Xabtm3bNtlbAQBIezHDPGfOHJ04ceKq9+3evTvpgwAAyGR88hcAAIYQZgAADCHMAAAYQpgBADCEMAMAYAhhBgDAEMIMAIAhhBkAAEMIMwAAhhBmAAAMIcwAABhCmAEAMIQwAwBgCGEGAMAQwgwAgCGEGQAAQwgzAACGEGYAAAwhzAAAGEKYAQAwhDADAGAIYQYAwBDCDACAIYQZAABDCDMAAIYQZgAADCHMAAAYQpgBADCEMAMAYAhhBgDAEMIMAIAhhBkAAEMIMwAAhhBmAAAMIcwAABhCmAEAMIQwAwBgCGEGAMAQwgwAgCGEGQAAQ2KGef369aqsrNSiRYvGbtuxY4fuu+8+1dbWqra2Vn/5y18mdSQAAJkiJ9YX1NfX69FHH9XTTz897vZVq1Zp9erVkzYMAIBMFPOMee7cuZo2bdr12AIAQMaLecb8Sfbu3auOjg4FAgG1trYmHO9gMJjQ463Kz8/3egISEAwG5TiO1zMQB4691Jepx19cYV6+fLmeeOIJ+Xw+bd++Xc8++6y2bNmS0JBAIJC+B9L+fq8XIE6BQMDrCUgEx15KS9fjz3Gca56MxvWu7JtvvlnZ2dnKyspSQ0OD3njjjbgHAgCA/4grzKFQaOzXXV1dKisrS9ogAAAyWcxL2S0tLTp27Jg++OADzZ8/X9/+9rd17NgxHT9+XJI0Y8YMbd68edKHAgCQCWKGeevWrVfc1tDQMCljAADIdHzyFwAAhhBmAAAMIcwAABhCmAEAMIQwAwBgCGEGAMAQwgwAgCGEGQAAQwgzAACGEGYAAAwhzAAAGEKYAQAwhDADAGAIYQYAwBDCDACAIYQZAABDCDMAAIYQZgAADCHMAAAYQpgBADCEMAMAYAhhBgDAEMIMAIAhhBkAAEMIMwAAhhBmAAAMIcwAABhCmAEAMIQwAwBgCGEGAMAQwgwAgCGEGQAAQwgzAACGEGYAAAwhzAAAGEKYAQAwhDADAGAIYQYAwBDCDACAIYQZAABDYoZ5/fr1qqys1KJFi8ZuGxwcVFNTk6qrq9XU1KQPP/xwUkcCAJApYoa5vr5eu3btGndbW1ubKisrdejQIVVWVqqtrW3SBgIAkElihnnu3LmaNm3auNu6u7tVV1cnSaqrq1NXV9ekjAMAINPkxPOgcDis4uJiSdItt9yicDic8JBgMJjwc1iUn5/v9QQkIBgMynEcr2cgDhx7qS9Tj7+4wvxxPp9PPp8v4SGBQCB9D6T9/V4vQJwCgYDXE5AIjr2Ulq7Hn+M41zwZjetd2dOnT1coFJIkhUIhFRUVxbcOAACME1eYq6qq1NHRIUnq6OjQwoULk7kJAICMFTPMLS0tWrZsmU6fPq358+frt7/9rdasWaPDhw+rurpaR44c0Zo1a67HVgAA0l7M15i3bt161dt3796d9DEAAGQ6PvkLAABDCDMAAIYQZgAADCHMAAAYQpgBADCEMAMAYAhhBgDAEMIMAIAhhBkAAEMIMwAAhhBmAAAMIcwAABhCmAEAMIQwAwBgCGEGAMAQwgwAgCGEGQAAQwgzAACGEGYAAAwhzAAAGEKYAQAwhDADAGAIYQYAwBDCDACAIYQZAABDCDMAAIYQZgAADCHMAAAYQpgBADCEMAMAYAhhBgDAEMIMAIAhhBkAAEMIMwAAhhBmAAAMIcwAABhCmAEAMIQwAwBgCGEGAMAQwgwAgCE5iTy4qqpKBQUFysrKUnZ2tn7/+98naxcAABkpoTBL0u7du1VUVJSMLQAAZDwuZQMAYEjCZ8yrV6+Wz+fTww8/rIcffjju5wkGg4lOMSk/P9/rCUhAMBiU4zhez0AcOPZSX6YefwmF+YUXXpDf71c4HFZTU5NKS0s1d+7cuJ4rEAik74G0v9/rBYhTIBDwegISwbGX0tL1+HMc55onowldyvb7/ZKk6dOn6/7771dvb28iTwcAQMaLO8wXL17U0NDQ2K8PHz6ssrKypA0DACATxX0pOxwO68knn5QkRaNRLVq0SPPnz0/aMAAAMlHcYS4pKdG+ffuSuQUAgIzHt0sBAGAIYQYAwBDCDACAIYQZAABDCDMAAIYQZgAADCHMAAAYQpgBADCEMAMAYAhhBgDAEMIMAIAhhBkAAEMIMwAAhhBmAAAMIcwAABhCmAEAMIQwAwBgCGEGAMAQwgwAgCGEGQAAQwgzAACGEGYAAAwhzAAAGEKYAQAwhDADAGAIYQYAwBDCDACAIYQZAABDCDMAAIYQZgAADCHMAAAYQpgBADCEMAMAYAhhBgDAEMIMAIAhhBkAAEMIMwAAhhBmAAAMIcwAABhCmAEAMCShMP/1r39VTU2N7r//frW1tSVrEwAAGSvuMEejUW3evFm7du3SwYMHdeDAAZ06dSqZ2wAAyDhxh7m3t1ef+9znVFJSory8PD300EPq7u5O5jYAADJOTrwPHBgY0K233jr2e7/fr97e3gk/j+u6kqSRkZF4p5j3v/9zgwqn8HJ+qrn5s1PkOI7XM5AAjr3Ulc7H30e9+6h//y3uMCdLJBKRJJ08edLjJZOn+s58Sflez0AcgsGg1xOQAI691Jbux18kEtGUKVOuuD3uMPv9fvX394/9fmBgQH6/f8LPU1BQoPLycuXm5srn88U7BwCAlOC6riKRiAoKCq56f9xhvvPOO/X222+rr69Pfr9fBw8e1I9//OMJP09WVpZuvPHGeGcAAJByrnam/JG4w5yTk6NNmzbpm9/8pqLRqJYsWaKysrJ4nw4AAEjyuZ/06jMAALjueLsiAACGEGYAAAwhzAAAGEKYAQAwhDADAGAIYQYAwBDCDACAIYQZAABDCDMAAIYQZgAADPH8xz4iNYXDYb366qsKhULKz89XeXm5AoGAsrL4fz1gsn344YcKhUKaMmWKZsyYwXGXZvisbEzI0aNH9ctf/lKDg4OaOXOmioqKNDIyotOnT6uvr081NTV6/PHHVVhY6PVUIK3885//1N69e3Xw4EGNjIyoqKhIjuMoHA5r9uzZamxs1Fe+8hWvZyIJCDMm5Ic//KFWrFih22677Yr7RkdH9ec//1nRaFQ1NTUerAPSV1NTk2pra1VVVaWpU6eOuy8YDKqzs1Pl5eVqaGjwaCGShTADAGAIL0wgKbq6uvT66697PQPIOKFQSCMjI17PQBLx5i8kRW9vr06ePKnR0VHt2rXL6zlAxli3bp3OnDmjmpoaPf30017PQRJwKRsAUpzrujp16pTKysq8noIkIMyISyQS0QsvvKC//e1vkqS5c+dq2bJlys3N9XgZkJ6GhoZUWFiowcHBq95/0003Xdc9mDyEGXHZuHGjRkdHVVdXJ0nat2+fsrKy9Mwzz3g7DEhT3/rWt/Tcc8+pqqpKPp9PH/+r2+fzqbu728N1SCbCjLh8/etf1759+2LeBgCYGN6VjbhkZ2frzJkzY7/v6+tTdna2h4uAzNDT06OLFy9Kkjo7O7VlyxadP3/e41VIJs6YEZdXXnlF69evV0lJiVzX1fnz5/WDH/yATx4CJtnixYu1b98+nThxQq2trWpoaNAf/vAH7dmzx+tpSBK+XQpxqays1KFDh/TWW29JkkpLS5WXl+fxKiD95eTkyOfzqaurS4888ogaGhrU3t7u9SwkEWFG3ILBoM6dO6doNKrjx49L0tibwQBMjoKCAj333HPav3+/9uzZo8uXL2t0dNTrWUgiLmUjLk899ZT6+vp0xx13jL227PP59L3vfc/jZUB6cl1XPp9P7777rg4cOKA777xTc+bM0fnz53Xs2DHV1dWNfQ1SG2FGXB588EG9/PLL/CUAXCcrVqxQdXW1Fi5cOO6HyIyMjKinp0cdHR2aN2+e6uvrPVyJZOBSNuJSVlamd999V8XFxV5PATLCrl271N7erpaWFp09e1ZTp06V4zi6fPmy7r33Xq1cuVIzZ870eiaSgDNmxGXFihU6fvy4Zs2aNe7Tvnbu3OnhKiAzRCIRffDBB5oyZcoVPwISqY8wY0I+eg3r2LFjV73/7rvv5nUuAEgAYcaE8DoXAEwuwowJcRxH7e3t2r9//1Vf52psbOR1LgBIAGFG3HidCwCSjzADAGAIP8QCAABDCDMAAIYQZiCF7NixQyMjI0l9zi9+8YsaHh6e8H0AJgdhBlLIT3/6U0UiEa9nXBM/UAFIDB/JCaSI73//+5KkZcuWKSsrS7/4xS/0s5/9TCdOnJDjOJo3b57Wr1+v7OxsrVixQhUVFert7dW5c+f02GOPye/3a8+ePQqFQnrqqaf04IMPjj33r371K3V3d+vSpUtqaWlRTU3NFf/83t5ePfPMM7p48aJuuOEGbdy4UbNmzdLZs2e1ZMkS1dfX6+jRo1q6dKmWL19+3f5cgLTjAkgZ5eXl7tDQkOu6rrthwwb3pZdecl3XdaPRqLt27Vr3xRdfdF3XdR999FH3O9/5jhuNRt3+/n531qxZ7tatW13Xdd3XX3/dve+++8Y9544dO1zXdd1//OMf7t133+2+99574/55juO4CxYscI8cOeK6rusePnzYXbBgges4jtvX1+eWl5e7Bw8evC5/BkC644wZSFF/+tOf1Nvbq+eff16SdOnSJfn9/rH7H3jgAWVlZcnv9+umm27S1772NUlSRUWFBgYG5DiO8vPzJUkNDQ2SpNLSUs2cOVOvvfaaFi5cOPZcp0+fVm5uriorKyVJ99xzj3Jzc3X69GkVFBQoPz9/3Bk4gPgRZiBFua6rn//85yopKbnq/R9FV5Kys7PHfv/Rz88eHR0d9zWJ+MxnPsPnowNJwpu/gBRSUFCgoaEhSVJVVZXa2toUjUYlSe+//776+vriet7f/e53kqS3335bf//73/XlL3953P233367IpGIjh49Kkl65ZVXNDo6qttvvz3OfxMAn4QzZiCFPP7443rsscc0ZcoU7dy5Uzt37lRtba18Pp9yc3O1YcOGTzyDvpZoNKq6ujr961//0ubNmzV9+vRx9+fl5eknP/nJuDd/bd++XXl5ecn6VwPw//hITgAADOFSNgAAhhBmAAAMIcwAABhCmAEAMIQwAwBgCGEGAMAQwgwAgCGEGQAAQ/4P+3i2fsewLAIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_=binary_labels.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53, 4096)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=rd_df.values.astype('float32')\n",
    "y=(binary_labels == 'si').values.astype('int8').reshape(-1,1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Window function is applied to Dataset objects. Same windows lenghts for each time series corresponding to each subject are built asigning the rigth label. Then they are included in same Dataset object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#windowing parameters\n",
    "num_features = x.shape[1]\n",
    "window_size = int(num_features/5 + 1)\n",
    "shuffle_buffer = num_features\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=tf.data.Dataset.from_tensor_slices(x)\n",
    "labels=(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(None,), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(1,), dtype=tf.int8, name=None))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#series, window_size, batch_size,label\n",
    "for i,features in enumerate(x):\n",
    "    new = windowed_dataset(features,window_size,batch_size,labels[i])\n",
    "    if i>0:\n",
    "        dataset = tf.data.Dataset.concatenate(dataset,new)\n",
    "    else:\n",
    "        dataset = new\n",
    "        \n",
    "dataset.cache()\n",
    "dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET_SIZE = int((num_features/window_size)*50)\n",
    "# #TODO import from utils API\n",
    "# train_size = int(0.7 * DATASET_SIZE)\n",
    "# val_size = int(0.15 * DATASET_SIZE)\n",
    "# test_size = int(0.15 * DATASET_SIZE)\n",
    "\n",
    "# full_dataset = dataset\n",
    "# full_dataset = full_dataset.shuffle(DATASET_SIZE, seed=seed)\n",
    "# train_dataset = full_dataset.take(train_size).batch(mini_batch_size).prefetch(2).cache()\n",
    "# test_dataset = full_dataset.skip(train_size)\n",
    "# val_dataset = test_dataset.skip(test_size).batch(mini_batch_size).prefetch(2).cache()\n",
    "# test_dataset = test_dataset.take(test_size).batch(mini_batch_size).prefetch(2).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_SIZE = int((num_features/window_size)*50)\n",
    "train_dataset, val_dataset, test_dataset = split_train_test_val(dataset, DATASET_SIZE, train_ratio=0.67, val_ratio=0.17, test_ratio=0.16, shuffle_buffer=DATASET_SIZE, seed=seed, mini_batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "249"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks(name):\n",
    "    return [\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50, min_delta=1e-4),\n",
    "      ]\n",
    "\n",
    "def compile_and_fit(model, train_dataset, test_dataset, name, optimizer=None, max_epochs=1000):\n",
    "    tf.keras.backend.clear_session()# avoid clutter from old models and layers, especially when memory is limited\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    tf.random.set_seed(seed) # establecemos la semilla para tensorflow\n",
    "    history = model.fit(train_dataset, \n",
    "                        use_multiprocessing=True, \n",
    "                        validation_data=test_dataset, epochs=max_epochs, \n",
    "                        callbacks=get_callbacks(name),\n",
    "                        verbose=1, shuffle=True)\n",
    "    return history\n",
    "\n",
    "# Many models train better if you gradually reduce the learning rate during training. \n",
    "# Use optimizers.schedules to reduce the learning rate over time:\n",
    "def get_optimizer(steps_per_epoch=1, lr=1e-4, multiplier=1000):\n",
    "    lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(lr,\n",
    "                                                                 decay_steps=steps_per_epoch*multiplier,\n",
    "                                                                 decay_rate=1,\n",
    "                                                                 staircase=False)\n",
    "    return tf.keras.optimizers.Adam(lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_histories = {}\n",
    "mini_batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # LSTM basic architectures --> #TODO import from utils API\n",
    "# model = tf.keras.models.Sequential()\n",
    "# model.add(tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=1),input_shape=(window_size,)))\n",
    "# model.add(tf.keras.layers.LSTM(8, activation=tf.nn.tanh, return_sequences=False))\n",
    "# # model.add(tf.keras.layers.Dropout(dropout))\n",
    "# model.add(tf.keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
    "\n",
    "# size_histories['lstm/windows'] = compile_and_fit(model, train_dataset, \n",
    "#                                           val_dataset,\n",
    "#                                           \"fcnn/tiny\", \n",
    "# #                                               optimizer=get_optimizer(),\n",
    "#                                           optimizer=tf.keras.optimizers.Adam(learning_rate=lr), \n",
    "# #                                               optimizer = tf.keras.optimizers.SGD(lr=lr, momentum=0.9),\n",
    "#                                           max_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\n#######################Evaluation###########################\")\n",
    "# # Evaluate the model on the test data using `evaluate`\n",
    "# print('train acc:', max(size_histories['lstm/windows'].history[\"accuracy\"]))\n",
    "# print('val acc:', max(size_histories['lstm/windows'].history[\"val_accuracy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_report(size_histories, metric = 'loss')\n",
    "plt.ylim(0., 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4, 1.05)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_report(size_histories, metric = 'accuracy')\n",
    "plt.ylim(0.4, 1.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(4,1)\n",
    "fig.tight_layout()\n",
    "\n",
    "i=0\n",
    "for (x,y),ax in zip(dataset.take(4), axes):\n",
    "    ax.plot(x.numpy(), color=colors[y.numpy()[0]])\n",
    "    ax.set_xticks(range(i,window_size,100))\n",
    "    input_tensor=tf.expand_dims(x, axis=1)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.evaluate(test_dataset)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from CSV\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C01_1</th>\n",
       "      <td>7.349452e-15</td>\n",
       "      <td>-13.291940</td>\n",
       "      <td>1.024601</td>\n",
       "      <td>10.161138</td>\n",
       "      <td>3.315941</td>\n",
       "      <td>-3.097414</td>\n",
       "      <td>1.440666</td>\n",
       "      <td>7.129718</td>\n",
       "      <td>4.707049</td>\n",
       "      <td>0.572884</td>\n",
       "      <td>...</td>\n",
       "      <td>8.309032</td>\n",
       "      <td>7.649810</td>\n",
       "      <td>6.732932</td>\n",
       "      <td>7.404337</td>\n",
       "      <td>8.742733</td>\n",
       "      <td>8.548355</td>\n",
       "      <td>7.366941</td>\n",
       "      <td>7.579698</td>\n",
       "      <td>9.223219</td>\n",
       "      <td>10.153316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C01_1</th>\n",
       "      <td>-1.329194e+01</td>\n",
       "      <td>1.024601</td>\n",
       "      <td>10.161138</td>\n",
       "      <td>3.315941</td>\n",
       "      <td>-3.097414</td>\n",
       "      <td>1.440666</td>\n",
       "      <td>7.129718</td>\n",
       "      <td>4.707049</td>\n",
       "      <td>0.572884</td>\n",
       "      <td>3.012018</td>\n",
       "      <td>...</td>\n",
       "      <td>7.649810</td>\n",
       "      <td>6.732932</td>\n",
       "      <td>7.404337</td>\n",
       "      <td>8.742733</td>\n",
       "      <td>8.548355</td>\n",
       "      <td>7.366941</td>\n",
       "      <td>7.579698</td>\n",
       "      <td>9.223219</td>\n",
       "      <td>10.153316</td>\n",
       "      <td>10.014390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C01_1</th>\n",
       "      <td>1.024601e+00</td>\n",
       "      <td>10.161138</td>\n",
       "      <td>3.315941</td>\n",
       "      <td>-3.097414</td>\n",
       "      <td>1.440666</td>\n",
       "      <td>7.129718</td>\n",
       "      <td>4.707049</td>\n",
       "      <td>0.572884</td>\n",
       "      <td>3.012018</td>\n",
       "      <td>7.796532</td>\n",
       "      <td>...</td>\n",
       "      <td>6.732932</td>\n",
       "      <td>7.404337</td>\n",
       "      <td>8.742733</td>\n",
       "      <td>8.548355</td>\n",
       "      <td>7.366941</td>\n",
       "      <td>7.579698</td>\n",
       "      <td>9.223219</td>\n",
       "      <td>10.153316</td>\n",
       "      <td>10.014390</td>\n",
       "      <td>10.637240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C01_1</th>\n",
       "      <td>1.016114e+01</td>\n",
       "      <td>3.315941</td>\n",
       "      <td>-3.097414</td>\n",
       "      <td>1.440666</td>\n",
       "      <td>7.129718</td>\n",
       "      <td>4.707049</td>\n",
       "      <td>0.572884</td>\n",
       "      <td>3.012018</td>\n",
       "      <td>7.796532</td>\n",
       "      <td>7.401986</td>\n",
       "      <td>...</td>\n",
       "      <td>7.404337</td>\n",
       "      <td>8.742733</td>\n",
       "      <td>8.548355</td>\n",
       "      <td>7.366941</td>\n",
       "      <td>7.579698</td>\n",
       "      <td>9.223219</td>\n",
       "      <td>10.153316</td>\n",
       "      <td>10.014390</td>\n",
       "      <td>10.637240</td>\n",
       "      <td>12.426966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C01_1</th>\n",
       "      <td>3.315941e+00</td>\n",
       "      <td>-3.097414</td>\n",
       "      <td>1.440666</td>\n",
       "      <td>7.129718</td>\n",
       "      <td>4.707049</td>\n",
       "      <td>0.572884</td>\n",
       "      <td>3.012018</td>\n",
       "      <td>7.796532</td>\n",
       "      <td>7.401986</td>\n",
       "      <td>4.388565</td>\n",
       "      <td>...</td>\n",
       "      <td>8.742733</td>\n",
       "      <td>8.548355</td>\n",
       "      <td>7.366941</td>\n",
       "      <td>7.579698</td>\n",
       "      <td>9.223219</td>\n",
       "      <td>10.153316</td>\n",
       "      <td>10.014390</td>\n",
       "      <td>10.637240</td>\n",
       "      <td>12.426966</td>\n",
       "      <td>13.660017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C01_1</th>\n",
       "      <td>-3.097414e+00</td>\n",
       "      <td>1.440666</td>\n",
       "      <td>7.129718</td>\n",
       "      <td>4.707049</td>\n",
       "      <td>0.572884</td>\n",
       "      <td>3.012018</td>\n",
       "      <td>7.796532</td>\n",
       "      <td>7.401986</td>\n",
       "      <td>4.388565</td>\n",
       "      <td>5.414847</td>\n",
       "      <td>...</td>\n",
       "      <td>8.548355</td>\n",
       "      <td>7.366941</td>\n",
       "      <td>7.579698</td>\n",
       "      <td>9.223219</td>\n",
       "      <td>10.153316</td>\n",
       "      <td>10.014390</td>\n",
       "      <td>10.637240</td>\n",
       "      <td>12.426966</td>\n",
       "      <td>13.660017</td>\n",
       "      <td>13.831796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C01_1</th>\n",
       "      <td>1.440666e+00</td>\n",
       "      <td>7.129718</td>\n",
       "      <td>4.707049</td>\n",
       "      <td>0.572884</td>\n",
       "      <td>3.012018</td>\n",
       "      <td>7.796532</td>\n",
       "      <td>7.401986</td>\n",
       "      <td>4.388565</td>\n",
       "      <td>5.414847</td>\n",
       "      <td>8.975251</td>\n",
       "      <td>...</td>\n",
       "      <td>7.366941</td>\n",
       "      <td>7.579698</td>\n",
       "      <td>9.223219</td>\n",
       "      <td>10.153316</td>\n",
       "      <td>10.014390</td>\n",
       "      <td>10.637240</td>\n",
       "      <td>12.426966</td>\n",
       "      <td>13.660017</td>\n",
       "      <td>13.831796</td>\n",
       "      <td>14.565094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C01_1</th>\n",
       "      <td>7.129718e+00</td>\n",
       "      <td>4.707049</td>\n",
       "      <td>0.572884</td>\n",
       "      <td>3.012018</td>\n",
       "      <td>7.796532</td>\n",
       "      <td>7.401986</td>\n",
       "      <td>4.388565</td>\n",
       "      <td>5.414847</td>\n",
       "      <td>8.975251</td>\n",
       "      <td>9.042866</td>\n",
       "      <td>...</td>\n",
       "      <td>7.579698</td>\n",
       "      <td>9.223219</td>\n",
       "      <td>10.153316</td>\n",
       "      <td>10.014390</td>\n",
       "      <td>10.637240</td>\n",
       "      <td>12.426966</td>\n",
       "      <td>13.660017</td>\n",
       "      <td>13.831796</td>\n",
       "      <td>14.565094</td>\n",
       "      <td>16.379218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C01_1</th>\n",
       "      <td>4.707049e+00</td>\n",
       "      <td>0.572884</td>\n",
       "      <td>3.012018</td>\n",
       "      <td>7.796532</td>\n",
       "      <td>7.401986</td>\n",
       "      <td>4.388565</td>\n",
       "      <td>5.414847</td>\n",
       "      <td>8.975251</td>\n",
       "      <td>9.042866</td>\n",
       "      <td>6.266289</td>\n",
       "      <td>...</td>\n",
       "      <td>9.223219</td>\n",
       "      <td>10.153316</td>\n",
       "      <td>10.014390</td>\n",
       "      <td>10.637240</td>\n",
       "      <td>12.426966</td>\n",
       "      <td>13.660017</td>\n",
       "      <td>13.831796</td>\n",
       "      <td>14.565094</td>\n",
       "      <td>16.379218</td>\n",
       "      <td>17.498379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C01_1</th>\n",
       "      <td>5.728839e-01</td>\n",
       "      <td>3.012018</td>\n",
       "      <td>7.796532</td>\n",
       "      <td>7.401986</td>\n",
       "      <td>4.388565</td>\n",
       "      <td>5.414847</td>\n",
       "      <td>8.975251</td>\n",
       "      <td>9.042866</td>\n",
       "      <td>6.266289</td>\n",
       "      <td>6.126338</td>\n",
       "      <td>...</td>\n",
       "      <td>10.153316</td>\n",
       "      <td>10.014390</td>\n",
       "      <td>10.637240</td>\n",
       "      <td>12.426966</td>\n",
       "      <td>13.660017</td>\n",
       "      <td>13.831796</td>\n",
       "      <td>14.565094</td>\n",
       "      <td>16.379218</td>\n",
       "      <td>17.498379</td>\n",
       "      <td>17.017866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0          1          2          3         4         5  \\\n",
       "Unnamed: 0                                                                      \n",
       "C01_1       7.349452e-15 -13.291940   1.024601  10.161138  3.315941 -3.097414   \n",
       "C01_1      -1.329194e+01   1.024601  10.161138   3.315941 -3.097414  1.440666   \n",
       "C01_1       1.024601e+00  10.161138   3.315941  -3.097414  1.440666  7.129718   \n",
       "C01_1       1.016114e+01   3.315941  -3.097414   1.440666  7.129718  4.707049   \n",
       "C01_1       3.315941e+00  -3.097414   1.440666   7.129718  4.707049  0.572884   \n",
       "C01_1      -3.097414e+00   1.440666   7.129718   4.707049  0.572884  3.012018   \n",
       "C01_1       1.440666e+00   7.129718   4.707049   0.572884  3.012018  7.796532   \n",
       "C01_1       7.129718e+00   4.707049   0.572884   3.012018  7.796532  7.401986   \n",
       "C01_1       4.707049e+00   0.572884   3.012018   7.796532  7.401986  4.388565   \n",
       "C01_1       5.728839e-01   3.012018   7.796532   7.401986  4.388565  5.414847   \n",
       "\n",
       "                   6         7         8         9  ...         40         41  \\\n",
       "Unnamed: 0                                          ...                         \n",
       "C01_1       1.440666  7.129718  4.707049  0.572884  ...   8.309032   7.649810   \n",
       "C01_1       7.129718  4.707049  0.572884  3.012018  ...   7.649810   6.732932   \n",
       "C01_1       4.707049  0.572884  3.012018  7.796532  ...   6.732932   7.404337   \n",
       "C01_1       0.572884  3.012018  7.796532  7.401986  ...   7.404337   8.742733   \n",
       "C01_1       3.012018  7.796532  7.401986  4.388565  ...   8.742733   8.548355   \n",
       "C01_1       7.796532  7.401986  4.388565  5.414847  ...   8.548355   7.366941   \n",
       "C01_1       7.401986  4.388565  5.414847  8.975251  ...   7.366941   7.579698   \n",
       "C01_1       4.388565  5.414847  8.975251  9.042866  ...   7.579698   9.223219   \n",
       "C01_1       5.414847  8.975251  9.042866  6.266289  ...   9.223219  10.153316   \n",
       "C01_1       8.975251  9.042866  6.266289  6.126338  ...  10.153316  10.014390   \n",
       "\n",
       "                   42         43         44         45         46         47  \\\n",
       "Unnamed: 0                                                                     \n",
       "C01_1        6.732932   7.404337   8.742733   8.548355   7.366941   7.579698   \n",
       "C01_1        7.404337   8.742733   8.548355   7.366941   7.579698   9.223219   \n",
       "C01_1        8.742733   8.548355   7.366941   7.579698   9.223219  10.153316   \n",
       "C01_1        8.548355   7.366941   7.579698   9.223219  10.153316  10.014390   \n",
       "C01_1        7.366941   7.579698   9.223219  10.153316  10.014390  10.637240   \n",
       "C01_1        7.579698   9.223219  10.153316  10.014390  10.637240  12.426966   \n",
       "C01_1        9.223219  10.153316  10.014390  10.637240  12.426966  13.660017   \n",
       "C01_1       10.153316  10.014390  10.637240  12.426966  13.660017  13.831796   \n",
       "C01_1       10.014390  10.637240  12.426966  13.660017  13.831796  14.565094   \n",
       "C01_1       10.637240  12.426966  13.660017  13.831796  14.565094  16.379218   \n",
       "\n",
       "                   48         49  \n",
       "Unnamed: 0                        \n",
       "C01_1        9.223219  10.153316  \n",
       "C01_1       10.153316  10.014390  \n",
       "C01_1       10.014390  10.637240  \n",
       "C01_1       10.637240  12.426966  \n",
       "C01_1       12.426966  13.660017  \n",
       "C01_1       13.660017  13.831796  \n",
       "C01_1       13.831796  14.565094  \n",
       "C01_1       14.565094  16.379218  \n",
       "C01_1       16.379218  17.498379  \n",
       "C01_1       17.498379  17.017866  \n",
       "\n",
       "[10 rows x 50 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this data has been previously processed by airflow\n",
    "features = pd.read_csv(\"/data/elekin/data/results/handwriting/tmp/windowed_data_data_augmentation_residues_20220827_17.csv\") #TODO automate\n",
    "features = features.set_index(features.columns[0])\n",
    "labels = pd.read_csv(\"/data/elekin/data/results/handwriting/tmp/windowed_data_data_augmentation_residues_20220827_17_labels.csv\") #TODO automate\n",
    "labels = labels.set_index(labels.columns[0])\n",
    "print(\"Loaded data from CSV\")\n",
    "features.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(214491,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder().fit(labels.values.ravel())\n",
    "y = LabelEncoder().fit_transform(labels.values.ravel())\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(214491, 50)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=features.values\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281 train batches and 139 test batches of 512 mini batch size and 1 steps per epoch\n"
     ]
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "mini_batch_size = 512\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).take(len(x_train)).batch(mini_batch_size).prefetch(AUTOTUNE).cache()\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).take(len(x_test)).batch(mini_batch_size).prefetch(AUTOTUNE).cache()\n",
    "steps_per_epoch = round(len(train_dataset)/mini_batch_size)\n",
    "\n",
    "if print_sample:\n",
    "    for feat, targ in test_dataset.take(10):\n",
    "        print ('Features test: {}, Target: {}'.format(feat, targ))\n",
    "\n",
    "    for feat, targ in test_dataset.take(10):\n",
    "        print ('Features train: {}, Target: {}'.format(feat, targ))\n",
    "\n",
    "print(\"{0} train batches and {1} test batches of {2} mini batch size and {3} steps per epoch\".format(len(train_dataset), \n",
    "                                                                              len(test_dataset),\n",
    "                                                                              mini_batch_size,\n",
    "                                                                                steps_per_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                3264      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,329\n",
      "Trainable params: 3,329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10000\n",
      "  1/281 [..............................] - ETA: 2:49 - loss: 0.5979 - accuracy: 0.4004WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0011s vs `on_train_batch_end` time: 0.0017s). Check your callbacks.\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.6040 - accuracy: 0.3957 - val_loss: 0.6055 - val_accuracy: 0.3942\n",
      "Epoch 2/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.6034 - accuracy: 0.3963 - val_loss: 0.6045 - val_accuracy: 0.3950\n",
      "Epoch 3/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.4484 - val_loss: 0.3943 - val_accuracy: 0.6047\n",
      "Epoch 4/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3962 - accuracy: 0.6026 - val_loss: 0.3944 - val_accuracy: 0.6047\n",
      "Epoch 5/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3959 - accuracy: 0.6031 - val_loss: 0.3947 - val_accuracy: 0.6047\n",
      "Epoch 6/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3952 - accuracy: 0.6031 - val_loss: 0.3926 - val_accuracy: 0.6054\n",
      "Epoch 7/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3935 - accuracy: 0.6036 - val_loss: 0.3900 - val_accuracy: 0.6070\n",
      "Epoch 8/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3910 - accuracy: 0.6061 - val_loss: 0.3884 - val_accuracy: 0.6084\n",
      "Epoch 9/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3883 - accuracy: 0.6079 - val_loss: 0.3843 - val_accuracy: 0.6114\n",
      "Epoch 10/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3842 - accuracy: 0.6093 - val_loss: 0.3798 - val_accuracy: 0.6140\n",
      "Epoch 11/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3927 - accuracy: 0.6002 - val_loss: 0.3795 - val_accuracy: 0.6149\n",
      "Epoch 12/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3804 - accuracy: 0.6095 - val_loss: 0.3766 - val_accuracy: 0.6143\n",
      "Epoch 13/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3800 - accuracy: 0.6104 - val_loss: 0.3820 - val_accuracy: 0.6146\n",
      "Epoch 14/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.3822 - accuracy: 0.6128 - val_loss: 0.3758 - val_accuracy: 0.6153\n",
      "Epoch 15/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3789 - accuracy: 0.6111 - val_loss: 0.3787 - val_accuracy: 0.6162\n",
      "Epoch 16/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.3797 - accuracy: 0.6129 - val_loss: 0.3721 - val_accuracy: 0.6135\n",
      "Epoch 17/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.6129 - val_loss: 0.3749 - val_accuracy: 0.6163\n",
      "Epoch 18/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3748 - accuracy: 0.6110 - val_loss: 0.3698 - val_accuracy: 0.6149\n",
      "Epoch 19/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.3735 - accuracy: 0.6116 - val_loss: 0.3698 - val_accuracy: 0.6153\n",
      "Epoch 20/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3701 - accuracy: 0.6113 - val_loss: 0.3703 - val_accuracy: 0.6162\n",
      "Epoch 21/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.3687 - accuracy: 0.6116 - val_loss: 0.3705 - val_accuracy: 0.6170\n",
      "Epoch 22/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3655 - accuracy: 0.6125 - val_loss: 0.3695 - val_accuracy: 0.6172\n",
      "Epoch 23/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3679 - accuracy: 0.6134 - val_loss: 0.3687 - val_accuracy: 0.6177\n",
      "Epoch 24/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.3589 - accuracy: 0.6154 - val_loss: 0.3604 - val_accuracy: 0.6187\n",
      "Epoch 25/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3558 - accuracy: 0.6171 - val_loss: 0.3596 - val_accuracy: 0.6198\n",
      "Epoch 26/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.3491 - accuracy: 0.6212 - val_loss: 0.3468 - val_accuracy: 0.6275\n",
      "Epoch 27/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.3478 - accuracy: 0.6237 - val_loss: 0.3432 - val_accuracy: 0.6275\n",
      "Epoch 28/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.3474 - accuracy: 0.6241 - val_loss: 0.3478 - val_accuracy: 0.6287\n",
      "Epoch 29/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.3464 - accuracy: 0.6248 - val_loss: 0.3415 - val_accuracy: 0.6290\n",
      "Epoch 30/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3458 - accuracy: 0.6255 - val_loss: 0.3422 - val_accuracy: 0.6307\n",
      "Epoch 31/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.3438 - accuracy: 0.6272 - val_loss: 0.3413 - val_accuracy: 0.6320\n",
      "Epoch 32/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3437 - accuracy: 0.6276 - val_loss: 0.3399 - val_accuracy: 0.6329\n",
      "Epoch 33/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.3438 - accuracy: 0.6275 - val_loss: 0.3386 - val_accuracy: 0.6327\n",
      "Epoch 34/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.3405 - accuracy: 0.6303 - val_loss: 0.3372 - val_accuracy: 0.6340\n",
      "Epoch 35/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.3383 - accuracy: 0.6329 - val_loss: 0.3315 - val_accuracy: 0.6374\n",
      "Epoch 36/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3357 - accuracy: 0.6360 - val_loss: 0.3298 - val_accuracy: 0.6408\n",
      "Epoch 37/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3342 - accuracy: 0.6367 - val_loss: 0.3320 - val_accuracy: 0.6416\n",
      "Epoch 38/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3371 - accuracy: 0.6354 - val_loss: 0.3337 - val_accuracy: 0.6413\n",
      "Epoch 39/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3323 - accuracy: 0.6379 - val_loss: 0.3289 - val_accuracy: 0.6422\n",
      "Epoch 40/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3320 - accuracy: 0.6390 - val_loss: 0.3299 - val_accuracy: 0.6433\n",
      "Epoch 41/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3316 - accuracy: 0.6394 - val_loss: 0.3289 - val_accuracy: 0.6437\n",
      "Epoch 42/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.3311 - accuracy: 0.6398 - val_loss: 0.3290 - val_accuracy: 0.6439\n",
      "Epoch 43/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3311 - accuracy: 0.6394 - val_loss: 0.3284 - val_accuracy: 0.6442\n",
      "Epoch 44/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.6395 - val_loss: 0.3284 - val_accuracy: 0.6446\n",
      "Epoch 45/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.6405 - val_loss: 0.3282 - val_accuracy: 0.6448\n",
      "Epoch 46/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.6409 - val_loss: 0.3275 - val_accuracy: 0.6455\n",
      "Epoch 47/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.6412 - val_loss: 0.3272 - val_accuracy: 0.6455\n",
      "Epoch 48/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.6412 - val_loss: 0.3280 - val_accuracy: 0.6455\n",
      "Epoch 49/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.6415 - val_loss: 0.3263 - val_accuracy: 0.6453\n",
      "Epoch 50/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.6413 - val_loss: 0.3260 - val_accuracy: 0.6455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.6421 - val_loss: 0.3257 - val_accuracy: 0.6460\n",
      "Epoch 52/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.6423 - val_loss: 0.3258 - val_accuracy: 0.6465\n",
      "Epoch 53/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.6424 - val_loss: 0.3253 - val_accuracy: 0.6469\n",
      "Epoch 54/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.3267 - accuracy: 0.6441 - val_loss: 0.3253 - val_accuracy: 0.6473\n",
      "Epoch 55/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3262 - accuracy: 0.6443 - val_loss: 0.3248 - val_accuracy: 0.6469\n",
      "Epoch 56/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.6434 - val_loss: 0.3250 - val_accuracy: 0.6476\n",
      "Epoch 57/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3257 - accuracy: 0.6450 - val_loss: 0.3239 - val_accuracy: 0.6465\n",
      "Epoch 58/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3255 - accuracy: 0.6453 - val_loss: 0.3237 - val_accuracy: 0.6474\n",
      "Epoch 59/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3256 - accuracy: 0.6453 - val_loss: 0.3240 - val_accuracy: 0.6483\n",
      "Epoch 60/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.3253 - accuracy: 0.6456 - val_loss: 0.3235 - val_accuracy: 0.6484\n",
      "Epoch 61/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3249 - accuracy: 0.6460 - val_loss: 0.3233 - val_accuracy: 0.6486\n",
      "Epoch 62/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3247 - accuracy: 0.6461 - val_loss: 0.3230 - val_accuracy: 0.6489\n",
      "Epoch 63/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.3243 - accuracy: 0.6464 - val_loss: 0.3227 - val_accuracy: 0.6485\n",
      "Epoch 64/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.3241 - accuracy: 0.6470 - val_loss: 0.3238 - val_accuracy: 0.6498\n",
      "Epoch 65/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3239 - accuracy: 0.6473 - val_loss: 0.3230 - val_accuracy: 0.6496\n",
      "Epoch 66/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.3236 - accuracy: 0.6477 - val_loss: 0.3231 - val_accuracy: 0.6502\n",
      "Epoch 67/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3234 - accuracy: 0.6482 - val_loss: 0.3232 - val_accuracy: 0.6507\n",
      "Epoch 68/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3229 - accuracy: 0.6484 - val_loss: 0.3219 - val_accuracy: 0.6488\n",
      "Epoch 69/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.3231 - accuracy: 0.6482 - val_loss: 0.3228 - val_accuracy: 0.6510\n",
      "Epoch 70/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3228 - accuracy: 0.6488 - val_loss: 0.3215 - val_accuracy: 0.6494\n",
      "Epoch 71/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3223 - accuracy: 0.6488 - val_loss: 0.3213 - val_accuracy: 0.6498\n",
      "Epoch 72/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.3224 - accuracy: 0.6494 - val_loss: 0.3212 - val_accuracy: 0.6495\n",
      "Epoch 73/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3221 - accuracy: 0.6492 - val_loss: 0.3210 - val_accuracy: 0.6497\n",
      "Epoch 74/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.3219 - accuracy: 0.6494 - val_loss: 0.3209 - val_accuracy: 0.6500\n",
      "Epoch 75/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.3218 - accuracy: 0.6495 - val_loss: 0.3207 - val_accuracy: 0.6506\n",
      "Epoch 76/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.3218 - accuracy: 0.6498 - val_loss: 0.3206 - val_accuracy: 0.6500\n",
      "Epoch 77/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.3216 - accuracy: 0.6499 - val_loss: 0.3204 - val_accuracy: 0.6505\n",
      "Epoch 78/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.3214 - accuracy: 0.6504 - val_loss: 0.3202 - val_accuracy: 0.6506\n",
      "Epoch 79/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.3208 - accuracy: 0.6508 - val_loss: 0.3201 - val_accuracy: 0.6508\n",
      "Epoch 80/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.3205 - accuracy: 0.6510 - val_loss: 0.3199 - val_accuracy: 0.6510\n",
      "Epoch 81/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.3204 - accuracy: 0.6513 - val_loss: 0.3198 - val_accuracy: 0.6512\n",
      "Epoch 82/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3202 - accuracy: 0.6514 - val_loss: 0.3196 - val_accuracy: 0.6513\n",
      "Epoch 83/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.3206 - accuracy: 0.6511 - val_loss: 0.3197 - val_accuracy: 0.6526\n",
      "Epoch 84/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3206 - accuracy: 0.6510 - val_loss: 0.3198 - val_accuracy: 0.6531\n",
      "Epoch 85/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3199 - accuracy: 0.6516 - val_loss: 0.3192 - val_accuracy: 0.6523\n",
      "Epoch 86/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3196 - accuracy: 0.6520 - val_loss: 0.3192 - val_accuracy: 0.6532\n",
      "Epoch 87/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3196 - accuracy: 0.6516 - val_loss: 0.3189 - val_accuracy: 0.6524\n",
      "Epoch 88/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3197 - accuracy: 0.6517 - val_loss: 0.3188 - val_accuracy: 0.6525\n",
      "Epoch 89/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3197 - accuracy: 0.6517 - val_loss: 0.3197 - val_accuracy: 0.6541\n",
      "Epoch 90/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3202 - accuracy: 0.6511 - val_loss: 0.3192 - val_accuracy: 0.6542\n",
      "Epoch 91/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3187 - accuracy: 0.6525 - val_loss: 0.3183 - val_accuracy: 0.6525\n",
      "Epoch 92/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3186 - accuracy: 0.6525 - val_loss: 0.3183 - val_accuracy: 0.6537\n",
      "Epoch 93/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3184 - accuracy: 0.6529 - val_loss: 0.3180 - val_accuracy: 0.6529\n",
      "Epoch 94/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3183 - accuracy: 0.6528 - val_loss: 0.3179 - val_accuracy: 0.6533\n",
      "Epoch 95/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3182 - accuracy: 0.6533 - val_loss: 0.3177 - val_accuracy: 0.6533\n",
      "Epoch 96/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3181 - accuracy: 0.6534 - val_loss: 0.3176 - val_accuracy: 0.6539\n",
      "Epoch 97/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3180 - accuracy: 0.6533 - val_loss: 0.3185 - val_accuracy: 0.6552\n",
      "Epoch 98/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3183 - accuracy: 0.6530 - val_loss: 0.3174 - val_accuracy: 0.6537\n",
      "Epoch 99/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3176 - accuracy: 0.6538 - val_loss: 0.3172 - val_accuracy: 0.6540\n",
      "Epoch 100/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3175 - accuracy: 0.6535 - val_loss: 0.3180 - val_accuracy: 0.6558\n",
      "Epoch 101/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3179 - accuracy: 0.6532 - val_loss: 0.3180 - val_accuracy: 0.6558\n",
      "Epoch 102/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3179 - accuracy: 0.6534 - val_loss: 0.3172 - val_accuracy: 0.6556\n",
      "Epoch 103/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3171 - accuracy: 0.6540 - val_loss: 0.3172 - val_accuracy: 0.6557\n",
      "Epoch 104/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3171 - accuracy: 0.6544 - val_loss: 0.3172 - val_accuracy: 0.6559\n",
      "Epoch 105/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3172 - accuracy: 0.6542 - val_loss: 0.3169 - val_accuracy: 0.6564\n",
      "Epoch 106/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3167 - accuracy: 0.6546 - val_loss: 0.3170 - val_accuracy: 0.6564\n",
      "Epoch 107/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3167 - accuracy: 0.6548 - val_loss: 0.3163 - val_accuracy: 0.6558\n",
      "Epoch 108/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3163 - accuracy: 0.6552 - val_loss: 0.3161 - val_accuracy: 0.6560\n",
      "Epoch 109/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3162 - accuracy: 0.6555 - val_loss: 0.3160 - val_accuracy: 0.6557\n",
      "Epoch 110/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3160 - accuracy: 0.6555 - val_loss: 0.3159 - val_accuracy: 0.6558\n",
      "Epoch 111/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3159 - accuracy: 0.6557 - val_loss: 0.3158 - val_accuracy: 0.6559\n",
      "Epoch 112/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3158 - accuracy: 0.6558 - val_loss: 0.3156 - val_accuracy: 0.6560\n",
      "Epoch 113/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3156 - accuracy: 0.6561 - val_loss: 0.3155 - val_accuracy: 0.6561\n",
      "Epoch 114/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3155 - accuracy: 0.6561 - val_loss: 0.3156 - val_accuracy: 0.6568\n",
      "Epoch 115/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.3154 - accuracy: 0.6563 - val_loss: 0.3155 - val_accuracy: 0.6568\n",
      "Epoch 116/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3153 - accuracy: 0.6564 - val_loss: 0.3152 - val_accuracy: 0.6562\n",
      "Epoch 117/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3151 - accuracy: 0.6564 - val_loss: 0.3151 - val_accuracy: 0.6566\n",
      "Epoch 118/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3150 - accuracy: 0.6564 - val_loss: 0.3150 - val_accuracy: 0.6568\n",
      "Epoch 119/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3149 - accuracy: 0.6565 - val_loss: 0.3150 - val_accuracy: 0.6573\n",
      "Epoch 120/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3147 - accuracy: 0.6567 - val_loss: 0.3150 - val_accuracy: 0.6577\n",
      "Epoch 121/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.3145 - accuracy: 0.6568 - val_loss: 0.3150 - val_accuracy: 0.6581\n",
      "Epoch 122/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3144 - accuracy: 0.6569 - val_loss: 0.3148 - val_accuracy: 0.6583\n",
      "Epoch 123/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3142 - accuracy: 0.6572 - val_loss: 0.3146 - val_accuracy: 0.6580\n",
      "Epoch 124/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3141 - accuracy: 0.6573 - val_loss: 0.3145 - val_accuracy: 0.6583\n",
      "Epoch 125/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.3139 - accuracy: 0.6575 - val_loss: 0.3143 - val_accuracy: 0.6582\n",
      "Epoch 126/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3138 - accuracy: 0.6575 - val_loss: 0.3142 - val_accuracy: 0.6583\n",
      "Epoch 127/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3137 - accuracy: 0.6576 - val_loss: 0.3141 - val_accuracy: 0.6585\n",
      "Epoch 128/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3136 - accuracy: 0.6576 - val_loss: 0.3140 - val_accuracy: 0.6587\n",
      "Epoch 129/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3135 - accuracy: 0.6576 - val_loss: 0.3140 - val_accuracy: 0.6585\n",
      "Epoch 130/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3134 - accuracy: 0.6578 - val_loss: 0.3138 - val_accuracy: 0.6587\n",
      "Epoch 131/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3132 - accuracy: 0.6580 - val_loss: 0.3138 - val_accuracy: 0.6589\n",
      "Epoch 132/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3131 - accuracy: 0.6581 - val_loss: 0.3136 - val_accuracy: 0.6589\n",
      "Epoch 133/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3129 - accuracy: 0.6582 - val_loss: 0.3135 - val_accuracy: 0.6589\n",
      "Epoch 134/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3127 - accuracy: 0.6584 - val_loss: 0.3133 - val_accuracy: 0.6591\n",
      "Epoch 135/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3126 - accuracy: 0.6586 - val_loss: 0.3132 - val_accuracy: 0.6592\n",
      "Epoch 136/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3124 - accuracy: 0.6589 - val_loss: 0.3130 - val_accuracy: 0.6593\n",
      "Epoch 137/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.3123 - accuracy: 0.6590 - val_loss: 0.3128 - val_accuracy: 0.6595\n",
      "Epoch 138/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3121 - accuracy: 0.6592 - val_loss: 0.3126 - val_accuracy: 0.6598\n",
      "Epoch 139/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3120 - accuracy: 0.6596 - val_loss: 0.3125 - val_accuracy: 0.6597\n",
      "Epoch 140/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3118 - accuracy: 0.6596 - val_loss: 0.3123 - val_accuracy: 0.6598\n",
      "Epoch 141/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3117 - accuracy: 0.6599 - val_loss: 0.3122 - val_accuracy: 0.6599\n",
      "Epoch 142/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3115 - accuracy: 0.6599 - val_loss: 0.3120 - val_accuracy: 0.6600\n",
      "Epoch 143/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3114 - accuracy: 0.6601 - val_loss: 0.3119 - val_accuracy: 0.6602\n",
      "Epoch 144/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.3113 - accuracy: 0.6602 - val_loss: 0.3118 - val_accuracy: 0.6603\n",
      "Epoch 145/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.3111 - accuracy: 0.6603 - val_loss: 0.3116 - val_accuracy: 0.6603\n",
      "Epoch 146/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.3110 - accuracy: 0.6604 - val_loss: 0.3114 - val_accuracy: 0.6604\n",
      "Epoch 147/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3108 - accuracy: 0.6606 - val_loss: 0.3113 - val_accuracy: 0.6605\n",
      "Epoch 148/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3106 - accuracy: 0.6607 - val_loss: 0.3111 - val_accuracy: 0.6605\n",
      "Epoch 149/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3105 - accuracy: 0.6607 - val_loss: 0.3109 - val_accuracy: 0.6606\n",
      "Epoch 150/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3103 - accuracy: 0.6607 - val_loss: 0.3106 - val_accuracy: 0.6610\n",
      "Epoch 151/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3100 - accuracy: 0.6610 - val_loss: 0.3104 - val_accuracy: 0.6611\n",
      "Epoch 152/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3098 - accuracy: 0.6611 - val_loss: 0.3101 - val_accuracy: 0.6614\n",
      "Epoch 153/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3096 - accuracy: 0.6614 - val_loss: 0.3098 - val_accuracy: 0.6614\n",
      "Epoch 154/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.3093 - accuracy: 0.6616 - val_loss: 0.3096 - val_accuracy: 0.6615\n",
      "Epoch 155/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.3090 - accuracy: 0.6620 - val_loss: 0.3092 - val_accuracy: 0.6620\n",
      "Epoch 156/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.3087 - accuracy: 0.6623 - val_loss: 0.3086 - val_accuracy: 0.6620\n",
      "Epoch 157/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.3081 - accuracy: 0.6625 - val_loss: 0.3083 - val_accuracy: 0.6631\n",
      "Epoch 158/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3077 - accuracy: 0.6629 - val_loss: 0.3079 - val_accuracy: 0.6634\n",
      "Epoch 159/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.3074 - accuracy: 0.6632 - val_loss: 0.3077 - val_accuracy: 0.6636\n",
      "Epoch 160/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3070 - accuracy: 0.6635 - val_loss: 0.3073 - val_accuracy: 0.6638\n",
      "Epoch 161/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3068 - accuracy: 0.6637 - val_loss: 0.3071 - val_accuracy: 0.6640\n",
      "Epoch 162/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.3065 - accuracy: 0.6638 - val_loss: 0.3069 - val_accuracy: 0.6641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 163/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.3063 - accuracy: 0.6639 - val_loss: 0.3067 - val_accuracy: 0.6640\n",
      "Epoch 164/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.3060 - accuracy: 0.6640 - val_loss: 0.3062 - val_accuracy: 0.6641\n",
      "Epoch 165/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.3055 - accuracy: 0.6642 - val_loss: 0.3060 - val_accuracy: 0.6645\n",
      "Epoch 166/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3043 - accuracy: 0.6644 - val_loss: 0.3052 - val_accuracy: 0.6651\n",
      "Epoch 167/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.3039 - accuracy: 0.6646 - val_loss: 0.3049 - val_accuracy: 0.6654\n",
      "Epoch 168/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.3037 - accuracy: 0.6647 - val_loss: 0.3046 - val_accuracy: 0.6655\n",
      "Epoch 169/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.3035 - accuracy: 0.6649 - val_loss: 0.3044 - val_accuracy: 0.6656\n",
      "Epoch 170/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3033 - accuracy: 0.6651 - val_loss: 0.3041 - val_accuracy: 0.6657\n",
      "Epoch 171/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3031 - accuracy: 0.6653 - val_loss: 0.3039 - val_accuracy: 0.6658\n",
      "Epoch 172/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3029 - accuracy: 0.6654 - val_loss: 0.3037 - val_accuracy: 0.6661\n",
      "Epoch 173/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.3027 - accuracy: 0.6656 - val_loss: 0.3035 - val_accuracy: 0.6662\n",
      "Epoch 174/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.3025 - accuracy: 0.6657 - val_loss: 0.3033 - val_accuracy: 0.6667\n",
      "Epoch 175/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3023 - accuracy: 0.6659 - val_loss: 0.3031 - val_accuracy: 0.6668\n",
      "Epoch 176/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3021 - accuracy: 0.6660 - val_loss: 0.3028 - val_accuracy: 0.6670\n",
      "Epoch 177/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3019 - accuracy: 0.6663 - val_loss: 0.3027 - val_accuracy: 0.6673\n",
      "Epoch 178/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3016 - accuracy: 0.6664 - val_loss: 0.3025 - val_accuracy: 0.6677\n",
      "Epoch 179/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3013 - accuracy: 0.6667 - val_loss: 0.3022 - val_accuracy: 0.6678\n",
      "Epoch 180/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3010 - accuracy: 0.6670 - val_loss: 0.3018 - val_accuracy: 0.6683\n",
      "Epoch 181/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.3007 - accuracy: 0.6675 - val_loss: 0.3012 - val_accuracy: 0.6682\n",
      "Epoch 182/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2997 - accuracy: 0.6679 - val_loss: 0.2983 - val_accuracy: 0.6691\n",
      "Epoch 183/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2965 - accuracy: 0.6697 - val_loss: 0.2967 - val_accuracy: 0.6699\n",
      "Epoch 184/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2962 - accuracy: 0.6700 - val_loss: 0.2965 - val_accuracy: 0.6700\n",
      "Epoch 185/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2960 - accuracy: 0.6703 - val_loss: 0.2964 - val_accuracy: 0.6702\n",
      "Epoch 186/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2959 - accuracy: 0.6706 - val_loss: 0.2962 - val_accuracy: 0.6703\n",
      "Epoch 187/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2957 - accuracy: 0.6707 - val_loss: 0.2961 - val_accuracy: 0.6706\n",
      "Epoch 188/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2956 - accuracy: 0.6708 - val_loss: 0.2960 - val_accuracy: 0.6707\n",
      "Epoch 189/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2954 - accuracy: 0.6710 - val_loss: 0.2959 - val_accuracy: 0.6708\n",
      "Epoch 190/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2953 - accuracy: 0.6712 - val_loss: 0.2957 - val_accuracy: 0.6709\n",
      "Epoch 191/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2952 - accuracy: 0.6713 - val_loss: 0.2956 - val_accuracy: 0.6711\n",
      "Epoch 192/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2950 - accuracy: 0.6715 - val_loss: 0.2955 - val_accuracy: 0.6713\n",
      "Epoch 193/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2949 - accuracy: 0.6717 - val_loss: 0.2954 - val_accuracy: 0.6713\n",
      "Epoch 194/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2947 - accuracy: 0.6716 - val_loss: 0.2953 - val_accuracy: 0.6714\n",
      "Epoch 195/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2946 - accuracy: 0.6719 - val_loss: 0.2951 - val_accuracy: 0.6716\n",
      "Epoch 196/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2945 - accuracy: 0.6719 - val_loss: 0.2950 - val_accuracy: 0.6717\n",
      "Epoch 197/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2943 - accuracy: 0.6720 - val_loss: 0.2949 - val_accuracy: 0.6717\n",
      "Epoch 198/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2942 - accuracy: 0.6721 - val_loss: 0.2948 - val_accuracy: 0.6719\n",
      "Epoch 199/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2941 - accuracy: 0.6721 - val_loss: 0.2947 - val_accuracy: 0.6720\n",
      "Epoch 200/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2940 - accuracy: 0.6722 - val_loss: 0.2946 - val_accuracy: 0.6718\n",
      "Epoch 201/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2938 - accuracy: 0.6722 - val_loss: 0.2945 - val_accuracy: 0.6718\n",
      "Epoch 202/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2937 - accuracy: 0.6724 - val_loss: 0.2943 - val_accuracy: 0.6721\n",
      "Epoch 203/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2936 - accuracy: 0.6726 - val_loss: 0.2942 - val_accuracy: 0.6722\n",
      "Epoch 204/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2935 - accuracy: 0.6727 - val_loss: 0.2941 - val_accuracy: 0.6722\n",
      "Epoch 205/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2933 - accuracy: 0.6728 - val_loss: 0.2940 - val_accuracy: 0.6722\n",
      "Epoch 206/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2932 - accuracy: 0.6727 - val_loss: 0.2939 - val_accuracy: 0.6723\n",
      "Epoch 207/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2931 - accuracy: 0.6727 - val_loss: 0.2938 - val_accuracy: 0.6725\n",
      "Epoch 208/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2930 - accuracy: 0.6729 - val_loss: 0.2937 - val_accuracy: 0.6724\n",
      "Epoch 209/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2929 - accuracy: 0.6730 - val_loss: 0.2936 - val_accuracy: 0.6726\n",
      "Epoch 210/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2928 - accuracy: 0.6730 - val_loss: 0.2935 - val_accuracy: 0.6725\n",
      "Epoch 211/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2926 - accuracy: 0.6731 - val_loss: 0.2934 - val_accuracy: 0.6726\n",
      "Epoch 212/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2925 - accuracy: 0.6731 - val_loss: 0.2933 - val_accuracy: 0.6726\n",
      "Epoch 213/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2924 - accuracy: 0.6733 - val_loss: 0.2932 - val_accuracy: 0.6728\n",
      "Epoch 214/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2923 - accuracy: 0.6734 - val_loss: 0.2931 - val_accuracy: 0.6728\n",
      "Epoch 215/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2922 - accuracy: 0.6735 - val_loss: 0.2930 - val_accuracy: 0.6730\n",
      "Epoch 216/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2921 - accuracy: 0.6736 - val_loss: 0.2929 - val_accuracy: 0.6729\n",
      "Epoch 217/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2920 - accuracy: 0.6737 - val_loss: 0.2927 - val_accuracy: 0.6731\n",
      "Epoch 218/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2918 - accuracy: 0.6738 - val_loss: 0.2926 - val_accuracy: 0.6732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 219/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2917 - accuracy: 0.6738 - val_loss: 0.2925 - val_accuracy: 0.6733\n",
      "Epoch 220/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2916 - accuracy: 0.6740 - val_loss: 0.2924 - val_accuracy: 0.6735\n",
      "Epoch 221/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2915 - accuracy: 0.6740 - val_loss: 0.2923 - val_accuracy: 0.6737\n",
      "Epoch 222/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2913 - accuracy: 0.6740 - val_loss: 0.2922 - val_accuracy: 0.6739\n",
      "Epoch 223/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2912 - accuracy: 0.6742 - val_loss: 0.2921 - val_accuracy: 0.6740\n",
      "Epoch 224/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2911 - accuracy: 0.6743 - val_loss: 0.2920 - val_accuracy: 0.6740\n",
      "Epoch 225/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2910 - accuracy: 0.6744 - val_loss: 0.2919 - val_accuracy: 0.6741\n",
      "Epoch 226/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2909 - accuracy: 0.6746 - val_loss: 0.2918 - val_accuracy: 0.6742\n",
      "Epoch 227/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2908 - accuracy: 0.6747 - val_loss: 0.2917 - val_accuracy: 0.6744\n",
      "Epoch 228/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2907 - accuracy: 0.6748 - val_loss: 0.2916 - val_accuracy: 0.6744\n",
      "Epoch 229/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2906 - accuracy: 0.6749 - val_loss: 0.2915 - val_accuracy: 0.6746\n",
      "Epoch 230/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2905 - accuracy: 0.6750 - val_loss: 0.2915 - val_accuracy: 0.6745\n",
      "Epoch 231/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2904 - accuracy: 0.6752 - val_loss: 0.2914 - val_accuracy: 0.6745\n",
      "Epoch 232/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2903 - accuracy: 0.6754 - val_loss: 0.2913 - val_accuracy: 0.6747\n",
      "Epoch 233/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2902 - accuracy: 0.6755 - val_loss: 0.2912 - val_accuracy: 0.6748\n",
      "Epoch 234/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2901 - accuracy: 0.6756 - val_loss: 0.2911 - val_accuracy: 0.6748\n",
      "Epoch 235/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2900 - accuracy: 0.6756 - val_loss: 0.2910 - val_accuracy: 0.6749\n",
      "Epoch 236/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2899 - accuracy: 0.6757 - val_loss: 0.2909 - val_accuracy: 0.6748\n",
      "Epoch 237/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2898 - accuracy: 0.6758 - val_loss: 0.2908 - val_accuracy: 0.6748\n",
      "Epoch 238/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2897 - accuracy: 0.6758 - val_loss: 0.2907 - val_accuracy: 0.6750\n",
      "Epoch 239/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2896 - accuracy: 0.6759 - val_loss: 0.2906 - val_accuracy: 0.6751\n",
      "Epoch 240/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2895 - accuracy: 0.6760 - val_loss: 0.2905 - val_accuracy: 0.6751\n",
      "Epoch 241/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2894 - accuracy: 0.6761 - val_loss: 0.2904 - val_accuracy: 0.6751\n",
      "Epoch 242/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2893 - accuracy: 0.6762 - val_loss: 0.2903 - val_accuracy: 0.6753\n",
      "Epoch 243/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2892 - accuracy: 0.6763 - val_loss: 0.2902 - val_accuracy: 0.6753\n",
      "Epoch 244/10000\n",
      "281/281 [==============================] - 1s 3ms/step - loss: 0.2891 - accuracy: 0.6764 - val_loss: 0.2901 - val_accuracy: 0.6755\n",
      "Epoch 245/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2890 - accuracy: 0.6764 - val_loss: 0.2900 - val_accuracy: 0.6756\n",
      "Epoch 246/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2889 - accuracy: 0.6764 - val_loss: 0.2899 - val_accuracy: 0.6756\n",
      "Epoch 247/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2888 - accuracy: 0.6766 - val_loss: 0.2898 - val_accuracy: 0.6755\n",
      "Epoch 248/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2887 - accuracy: 0.6766 - val_loss: 0.2897 - val_accuracy: 0.6756\n",
      "Epoch 249/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2886 - accuracy: 0.6768 - val_loss: 0.2896 - val_accuracy: 0.6758\n",
      "Epoch 250/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2885 - accuracy: 0.6768 - val_loss: 0.2895 - val_accuracy: 0.6758\n",
      "Epoch 251/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2884 - accuracy: 0.6768 - val_loss: 0.2894 - val_accuracy: 0.6758\n",
      "Epoch 252/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2883 - accuracy: 0.6769 - val_loss: 0.2893 - val_accuracy: 0.6759\n",
      "Epoch 253/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2882 - accuracy: 0.6771 - val_loss: 0.2892 - val_accuracy: 0.6759\n",
      "Epoch 254/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2881 - accuracy: 0.6771 - val_loss: 0.2891 - val_accuracy: 0.6759\n",
      "Epoch 255/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2880 - accuracy: 0.6772 - val_loss: 0.2891 - val_accuracy: 0.6759\n",
      "Epoch 256/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2879 - accuracy: 0.6772 - val_loss: 0.2890 - val_accuracy: 0.6760\n",
      "Epoch 257/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2878 - accuracy: 0.6773 - val_loss: 0.2889 - val_accuracy: 0.6760\n",
      "Epoch 258/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2877 - accuracy: 0.6773 - val_loss: 0.2888 - val_accuracy: 0.6762\n",
      "Epoch 259/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2876 - accuracy: 0.6774 - val_loss: 0.2887 - val_accuracy: 0.6763\n",
      "Epoch 260/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2875 - accuracy: 0.6775 - val_loss: 0.2887 - val_accuracy: 0.6763\n",
      "Epoch 261/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2874 - accuracy: 0.6776 - val_loss: 0.2886 - val_accuracy: 0.6764\n",
      "Epoch 262/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2873 - accuracy: 0.6777 - val_loss: 0.2885 - val_accuracy: 0.6763\n",
      "Epoch 263/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2872 - accuracy: 0.6777 - val_loss: 0.2884 - val_accuracy: 0.6764\n",
      "Epoch 264/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2871 - accuracy: 0.6777 - val_loss: 0.2883 - val_accuracy: 0.6766\n",
      "Epoch 265/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2870 - accuracy: 0.6779 - val_loss: 0.2882 - val_accuracy: 0.6767\n",
      "Epoch 266/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2870 - accuracy: 0.6779 - val_loss: 0.2881 - val_accuracy: 0.6768\n",
      "Epoch 267/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2869 - accuracy: 0.6781 - val_loss: 0.2880 - val_accuracy: 0.6768\n",
      "Epoch 268/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2868 - accuracy: 0.6781 - val_loss: 0.2880 - val_accuracy: 0.6768\n",
      "Epoch 269/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2867 - accuracy: 0.6782 - val_loss: 0.2879 - val_accuracy: 0.6768\n",
      "Epoch 270/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2866 - accuracy: 0.6783 - val_loss: 0.2878 - val_accuracy: 0.6769\n",
      "Epoch 271/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2865 - accuracy: 0.6784 - val_loss: 0.2877 - val_accuracy: 0.6770\n",
      "Epoch 272/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2864 - accuracy: 0.6784 - val_loss: 0.2876 - val_accuracy: 0.6770\n",
      "Epoch 273/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2863 - accuracy: 0.6784 - val_loss: 0.2875 - val_accuracy: 0.6771\n",
      "Epoch 274/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2862 - accuracy: 0.6785 - val_loss: 0.2874 - val_accuracy: 0.6771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 275/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2861 - accuracy: 0.6784 - val_loss: 0.2873 - val_accuracy: 0.6770\n",
      "Epoch 276/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2860 - accuracy: 0.6786 - val_loss: 0.2872 - val_accuracy: 0.6771\n",
      "Epoch 277/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2859 - accuracy: 0.6787 - val_loss: 0.2871 - val_accuracy: 0.6773\n",
      "Epoch 278/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2858 - accuracy: 0.6788 - val_loss: 0.2870 - val_accuracy: 0.6775\n",
      "Epoch 279/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2857 - accuracy: 0.6788 - val_loss: 0.2869 - val_accuracy: 0.6776\n",
      "Epoch 280/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2857 - accuracy: 0.6789 - val_loss: 0.2868 - val_accuracy: 0.6777\n",
      "Epoch 281/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2856 - accuracy: 0.6790 - val_loss: 0.2867 - val_accuracy: 0.6777\n",
      "Epoch 282/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2855 - accuracy: 0.6791 - val_loss: 0.2866 - val_accuracy: 0.6779\n",
      "Epoch 283/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2854 - accuracy: 0.6791 - val_loss: 0.2865 - val_accuracy: 0.6779\n",
      "Epoch 284/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2853 - accuracy: 0.6793 - val_loss: 0.2864 - val_accuracy: 0.6779\n",
      "Epoch 285/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2852 - accuracy: 0.6794 - val_loss: 0.2864 - val_accuracy: 0.6781\n",
      "Epoch 286/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2851 - accuracy: 0.6794 - val_loss: 0.2863 - val_accuracy: 0.6782\n",
      "Epoch 287/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2850 - accuracy: 0.6795 - val_loss: 0.2862 - val_accuracy: 0.6782\n",
      "Epoch 288/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2849 - accuracy: 0.6795 - val_loss: 0.2861 - val_accuracy: 0.6782\n",
      "Epoch 289/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2848 - accuracy: 0.6795 - val_loss: 0.2860 - val_accuracy: 0.6781\n",
      "Epoch 290/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2847 - accuracy: 0.6796 - val_loss: 0.2859 - val_accuracy: 0.6783\n",
      "Epoch 291/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2846 - accuracy: 0.6796 - val_loss: 0.2858 - val_accuracy: 0.6784\n",
      "Epoch 292/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2845 - accuracy: 0.6797 - val_loss: 0.2857 - val_accuracy: 0.6785\n",
      "Epoch 293/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2844 - accuracy: 0.6798 - val_loss: 0.2856 - val_accuracy: 0.6787\n",
      "Epoch 294/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2844 - accuracy: 0.6798 - val_loss: 0.2855 - val_accuracy: 0.6787\n",
      "Epoch 295/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2843 - accuracy: 0.6799 - val_loss: 0.2854 - val_accuracy: 0.6789\n",
      "Epoch 296/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2842 - accuracy: 0.6800 - val_loss: 0.2853 - val_accuracy: 0.6789\n",
      "Epoch 297/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2841 - accuracy: 0.6801 - val_loss: 0.2853 - val_accuracy: 0.6790\n",
      "Epoch 298/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2840 - accuracy: 0.6802 - val_loss: 0.2852 - val_accuracy: 0.6789\n",
      "Epoch 299/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2839 - accuracy: 0.6803 - val_loss: 0.2851 - val_accuracy: 0.6790\n",
      "Epoch 300/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2838 - accuracy: 0.6803 - val_loss: 0.2850 - val_accuracy: 0.6790\n",
      "Epoch 301/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2837 - accuracy: 0.6804 - val_loss: 0.2849 - val_accuracy: 0.6789\n",
      "Epoch 302/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2836 - accuracy: 0.6806 - val_loss: 0.2848 - val_accuracy: 0.6790\n",
      "Epoch 303/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2835 - accuracy: 0.6805 - val_loss: 0.2848 - val_accuracy: 0.6790\n",
      "Epoch 304/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2834 - accuracy: 0.6807 - val_loss: 0.2847 - val_accuracy: 0.6789\n",
      "Epoch 305/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2833 - accuracy: 0.6807 - val_loss: 0.2846 - val_accuracy: 0.6790\n",
      "Epoch 306/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2832 - accuracy: 0.6808 - val_loss: 0.2845 - val_accuracy: 0.6792\n",
      "Epoch 307/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2831 - accuracy: 0.6809 - val_loss: 0.2843 - val_accuracy: 0.6793\n",
      "Epoch 308/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2830 - accuracy: 0.6810 - val_loss: 0.2842 - val_accuracy: 0.6794\n",
      "Epoch 309/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2828 - accuracy: 0.6811 - val_loss: 0.2840 - val_accuracy: 0.6796\n",
      "Epoch 310/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2826 - accuracy: 0.6814 - val_loss: 0.2836 - val_accuracy: 0.6801\n",
      "Epoch 311/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2820 - accuracy: 0.6819 - val_loss: 0.2824 - val_accuracy: 0.6810\n",
      "Epoch 312/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2811 - accuracy: 0.6825 - val_loss: 0.2820 - val_accuracy: 0.6813\n",
      "Epoch 313/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2810 - accuracy: 0.6825 - val_loss: 0.2819 - val_accuracy: 0.6814\n",
      "Epoch 314/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2809 - accuracy: 0.6826 - val_loss: 0.2818 - val_accuracy: 0.6815\n",
      "Epoch 315/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2808 - accuracy: 0.6827 - val_loss: 0.2817 - val_accuracy: 0.6816\n",
      "Epoch 316/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2807 - accuracy: 0.6828 - val_loss: 0.2816 - val_accuracy: 0.6817\n",
      "Epoch 317/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2806 - accuracy: 0.6830 - val_loss: 0.2815 - val_accuracy: 0.6817\n",
      "Epoch 318/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2805 - accuracy: 0.6830 - val_loss: 0.2814 - val_accuracy: 0.6817\n",
      "Epoch 319/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2804 - accuracy: 0.6831 - val_loss: 0.2813 - val_accuracy: 0.6818\n",
      "Epoch 320/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2804 - accuracy: 0.6831 - val_loss: 0.2812 - val_accuracy: 0.6817\n",
      "Epoch 321/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2803 - accuracy: 0.6832 - val_loss: 0.2812 - val_accuracy: 0.6816\n",
      "Epoch 322/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2802 - accuracy: 0.6833 - val_loss: 0.2811 - val_accuracy: 0.6816\n",
      "Epoch 323/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2801 - accuracy: 0.6833 - val_loss: 0.2810 - val_accuracy: 0.6817\n",
      "Epoch 324/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2800 - accuracy: 0.6834 - val_loss: 0.2809 - val_accuracy: 0.6819\n",
      "Epoch 325/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2799 - accuracy: 0.6834 - val_loss: 0.2809 - val_accuracy: 0.6819\n",
      "Epoch 326/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2799 - accuracy: 0.6834 - val_loss: 0.2808 - val_accuracy: 0.6819\n",
      "Epoch 327/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2798 - accuracy: 0.6835 - val_loss: 0.2807 - val_accuracy: 0.6819\n",
      "Epoch 328/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2797 - accuracy: 0.6836 - val_loss: 0.2806 - val_accuracy: 0.6819\n",
      "Epoch 329/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2796 - accuracy: 0.6836 - val_loss: 0.2806 - val_accuracy: 0.6819\n",
      "Epoch 330/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2795 - accuracy: 0.6837 - val_loss: 0.2805 - val_accuracy: 0.6819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 331/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2795 - accuracy: 0.6838 - val_loss: 0.2804 - val_accuracy: 0.6820\n",
      "Epoch 332/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2794 - accuracy: 0.6839 - val_loss: 0.2803 - val_accuracy: 0.6822\n",
      "Epoch 333/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2793 - accuracy: 0.6839 - val_loss: 0.2803 - val_accuracy: 0.6823\n",
      "Epoch 334/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2792 - accuracy: 0.6838 - val_loss: 0.2802 - val_accuracy: 0.6824\n",
      "Epoch 335/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2791 - accuracy: 0.6839 - val_loss: 0.2801 - val_accuracy: 0.6825\n",
      "Epoch 336/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2791 - accuracy: 0.6840 - val_loss: 0.2801 - val_accuracy: 0.6824\n",
      "Epoch 337/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2790 - accuracy: 0.6841 - val_loss: 0.2800 - val_accuracy: 0.6824\n",
      "Epoch 338/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2789 - accuracy: 0.6842 - val_loss: 0.2799 - val_accuracy: 0.6824\n",
      "Epoch 339/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2789 - accuracy: 0.6842 - val_loss: 0.2798 - val_accuracy: 0.6826\n",
      "Epoch 340/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2788 - accuracy: 0.6843 - val_loss: 0.2798 - val_accuracy: 0.6825\n",
      "Epoch 341/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2787 - accuracy: 0.6844 - val_loss: 0.2797 - val_accuracy: 0.6825\n",
      "Epoch 342/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2786 - accuracy: 0.6844 - val_loss: 0.2796 - val_accuracy: 0.6825\n",
      "Epoch 343/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2786 - accuracy: 0.6845 - val_loss: 0.2796 - val_accuracy: 0.6825\n",
      "Epoch 344/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2785 - accuracy: 0.6846 - val_loss: 0.2795 - val_accuracy: 0.6826\n",
      "Epoch 345/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2784 - accuracy: 0.6846 - val_loss: 0.2794 - val_accuracy: 0.6826\n",
      "Epoch 346/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2784 - accuracy: 0.6846 - val_loss: 0.2794 - val_accuracy: 0.6826\n",
      "Epoch 347/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2783 - accuracy: 0.6847 - val_loss: 0.2793 - val_accuracy: 0.6826\n",
      "Epoch 348/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2782 - accuracy: 0.6847 - val_loss: 0.2793 - val_accuracy: 0.6826\n",
      "Epoch 349/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2782 - accuracy: 0.6848 - val_loss: 0.2792 - val_accuracy: 0.6827\n",
      "Epoch 350/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2781 - accuracy: 0.6850 - val_loss: 0.2791 - val_accuracy: 0.6828\n",
      "Epoch 351/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2781 - accuracy: 0.6850 - val_loss: 0.2791 - val_accuracy: 0.6828\n",
      "Epoch 352/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2780 - accuracy: 0.6851 - val_loss: 0.2790 - val_accuracy: 0.6828\n",
      "Epoch 353/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2779 - accuracy: 0.6852 - val_loss: 0.2789 - val_accuracy: 0.6829\n",
      "Epoch 354/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2779 - accuracy: 0.6853 - val_loss: 0.2789 - val_accuracy: 0.6829\n",
      "Epoch 355/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2778 - accuracy: 0.6854 - val_loss: 0.2788 - val_accuracy: 0.6830\n",
      "Epoch 356/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2777 - accuracy: 0.6854 - val_loss: 0.2787 - val_accuracy: 0.6831\n",
      "Epoch 357/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2777 - accuracy: 0.6855 - val_loss: 0.2787 - val_accuracy: 0.6831\n",
      "Epoch 358/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2776 - accuracy: 0.6855 - val_loss: 0.2786 - val_accuracy: 0.6831\n",
      "Epoch 359/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2776 - accuracy: 0.6856 - val_loss: 0.2786 - val_accuracy: 0.6831\n",
      "Epoch 360/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2775 - accuracy: 0.6857 - val_loss: 0.2785 - val_accuracy: 0.6832\n",
      "Epoch 361/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2774 - accuracy: 0.6857 - val_loss: 0.2784 - val_accuracy: 0.6833\n",
      "Epoch 362/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2774 - accuracy: 0.6858 - val_loss: 0.2784 - val_accuracy: 0.6833\n",
      "Epoch 363/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2773 - accuracy: 0.6858 - val_loss: 0.2783 - val_accuracy: 0.6833\n",
      "Epoch 364/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2772 - accuracy: 0.6859 - val_loss: 0.2782 - val_accuracy: 0.6833\n",
      "Epoch 365/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2772 - accuracy: 0.6858 - val_loss: 0.2782 - val_accuracy: 0.6833\n",
      "Epoch 366/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2771 - accuracy: 0.6859 - val_loss: 0.2781 - val_accuracy: 0.6833\n",
      "Epoch 367/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2770 - accuracy: 0.6860 - val_loss: 0.2780 - val_accuracy: 0.6833\n",
      "Epoch 368/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2770 - accuracy: 0.6861 - val_loss: 0.2780 - val_accuracy: 0.6833\n",
      "Epoch 369/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2769 - accuracy: 0.6861 - val_loss: 0.2779 - val_accuracy: 0.6832\n",
      "Epoch 370/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2768 - accuracy: 0.6861 - val_loss: 0.2778 - val_accuracy: 0.6832\n",
      "Epoch 371/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2768 - accuracy: 0.6861 - val_loss: 0.2778 - val_accuracy: 0.6834\n",
      "Epoch 372/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2767 - accuracy: 0.6863 - val_loss: 0.2777 - val_accuracy: 0.6834\n",
      "Epoch 373/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2766 - accuracy: 0.6864 - val_loss: 0.2776 - val_accuracy: 0.6834\n",
      "Epoch 374/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2765 - accuracy: 0.6864 - val_loss: 0.2776 - val_accuracy: 0.6835\n",
      "Epoch 375/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2765 - accuracy: 0.6864 - val_loss: 0.2775 - val_accuracy: 0.6837\n",
      "Epoch 376/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2764 - accuracy: 0.6865 - val_loss: 0.2774 - val_accuracy: 0.6839\n",
      "Epoch 377/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2764 - accuracy: 0.6866 - val_loss: 0.2773 - val_accuracy: 0.6840\n",
      "Epoch 378/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2763 - accuracy: 0.6866 - val_loss: 0.2773 - val_accuracy: 0.6842\n",
      "Epoch 379/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2762 - accuracy: 0.6867 - val_loss: 0.2772 - val_accuracy: 0.6844\n",
      "Epoch 380/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2762 - accuracy: 0.6867 - val_loss: 0.2771 - val_accuracy: 0.6845\n",
      "Epoch 381/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2761 - accuracy: 0.6868 - val_loss: 0.2770 - val_accuracy: 0.6845\n",
      "Epoch 382/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2760 - accuracy: 0.6869 - val_loss: 0.2770 - val_accuracy: 0.6847\n",
      "Epoch 383/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2760 - accuracy: 0.6869 - val_loss: 0.2769 - val_accuracy: 0.6847\n",
      "Epoch 384/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2759 - accuracy: 0.6869 - val_loss: 0.2768 - val_accuracy: 0.6848\n",
      "Epoch 385/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2758 - accuracy: 0.6870 - val_loss: 0.2768 - val_accuracy: 0.6849\n",
      "Epoch 386/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2758 - accuracy: 0.6870 - val_loss: 0.2767 - val_accuracy: 0.6850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 387/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2757 - accuracy: 0.6871 - val_loss: 0.2766 - val_accuracy: 0.6851\n",
      "Epoch 388/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2756 - accuracy: 0.6872 - val_loss: 0.2766 - val_accuracy: 0.6851\n",
      "Epoch 389/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2756 - accuracy: 0.6873 - val_loss: 0.2765 - val_accuracy: 0.6853\n",
      "Epoch 390/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2755 - accuracy: 0.6874 - val_loss: 0.2764 - val_accuracy: 0.6854\n",
      "Epoch 391/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2755 - accuracy: 0.6874 - val_loss: 0.2764 - val_accuracy: 0.6854\n",
      "Epoch 392/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2754 - accuracy: 0.6875 - val_loss: 0.2763 - val_accuracy: 0.6854\n",
      "Epoch 393/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2753 - accuracy: 0.6875 - val_loss: 0.2762 - val_accuracy: 0.6855\n",
      "Epoch 394/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2753 - accuracy: 0.6876 - val_loss: 0.2762 - val_accuracy: 0.6855\n",
      "Epoch 395/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2752 - accuracy: 0.6876 - val_loss: 0.2761 - val_accuracy: 0.6856\n",
      "Epoch 396/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2752 - accuracy: 0.6877 - val_loss: 0.2761 - val_accuracy: 0.6856\n",
      "Epoch 397/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2751 - accuracy: 0.6878 - val_loss: 0.2760 - val_accuracy: 0.6857\n",
      "Epoch 398/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2751 - accuracy: 0.6878 - val_loss: 0.2760 - val_accuracy: 0.6858\n",
      "Epoch 399/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2750 - accuracy: 0.6879 - val_loss: 0.2759 - val_accuracy: 0.6859\n",
      "Epoch 400/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2749 - accuracy: 0.6880 - val_loss: 0.2758 - val_accuracy: 0.6860\n",
      "Epoch 401/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2749 - accuracy: 0.6880 - val_loss: 0.2758 - val_accuracy: 0.6861\n",
      "Epoch 402/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2748 - accuracy: 0.6880 - val_loss: 0.2757 - val_accuracy: 0.6862\n",
      "Epoch 403/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2748 - accuracy: 0.6881 - val_loss: 0.2757 - val_accuracy: 0.6863\n",
      "Epoch 404/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2747 - accuracy: 0.6882 - val_loss: 0.2756 - val_accuracy: 0.6864\n",
      "Epoch 405/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2746 - accuracy: 0.6882 - val_loss: 0.2755 - val_accuracy: 0.6864\n",
      "Epoch 406/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2746 - accuracy: 0.6882 - val_loss: 0.2755 - val_accuracy: 0.6865\n",
      "Epoch 407/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2745 - accuracy: 0.6883 - val_loss: 0.2754 - val_accuracy: 0.6865\n",
      "Epoch 408/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2745 - accuracy: 0.6884 - val_loss: 0.2754 - val_accuracy: 0.6865\n",
      "Epoch 409/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2744 - accuracy: 0.6884 - val_loss: 0.2753 - val_accuracy: 0.6865\n",
      "Epoch 410/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2744 - accuracy: 0.6885 - val_loss: 0.2752 - val_accuracy: 0.6866\n",
      "Epoch 411/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2743 - accuracy: 0.6886 - val_loss: 0.2752 - val_accuracy: 0.6867\n",
      "Epoch 412/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2743 - accuracy: 0.6886 - val_loss: 0.2751 - val_accuracy: 0.6868\n",
      "Epoch 413/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2742 - accuracy: 0.6885 - val_loss: 0.2751 - val_accuracy: 0.6868\n",
      "Epoch 414/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2741 - accuracy: 0.6886 - val_loss: 0.2750 - val_accuracy: 0.6869\n",
      "Epoch 415/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2741 - accuracy: 0.6885 - val_loss: 0.2749 - val_accuracy: 0.6869\n",
      "Epoch 416/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2740 - accuracy: 0.6886 - val_loss: 0.2749 - val_accuracy: 0.6869\n",
      "Epoch 417/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2740 - accuracy: 0.6886 - val_loss: 0.2748 - val_accuracy: 0.6869\n",
      "Epoch 418/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2739 - accuracy: 0.6886 - val_loss: 0.2748 - val_accuracy: 0.6869\n",
      "Epoch 419/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2739 - accuracy: 0.6887 - val_loss: 0.2747 - val_accuracy: 0.6870\n",
      "Epoch 420/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2738 - accuracy: 0.6888 - val_loss: 0.2747 - val_accuracy: 0.6870\n",
      "Epoch 421/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2738 - accuracy: 0.6889 - val_loss: 0.2746 - val_accuracy: 0.6871\n",
      "Epoch 422/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2737 - accuracy: 0.6890 - val_loss: 0.2746 - val_accuracy: 0.6872\n",
      "Epoch 423/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2737 - accuracy: 0.6890 - val_loss: 0.2745 - val_accuracy: 0.6872\n",
      "Epoch 424/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2736 - accuracy: 0.6891 - val_loss: 0.2745 - val_accuracy: 0.6872\n",
      "Epoch 425/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2736 - accuracy: 0.6891 - val_loss: 0.2744 - val_accuracy: 0.6873\n",
      "Epoch 426/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2735 - accuracy: 0.6892 - val_loss: 0.2744 - val_accuracy: 0.6873\n",
      "Epoch 427/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2735 - accuracy: 0.6892 - val_loss: 0.2743 - val_accuracy: 0.6874\n",
      "Epoch 428/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2734 - accuracy: 0.6893 - val_loss: 0.2743 - val_accuracy: 0.6874\n",
      "Epoch 429/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2734 - accuracy: 0.6894 - val_loss: 0.2742 - val_accuracy: 0.6875\n",
      "Epoch 430/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2733 - accuracy: 0.6895 - val_loss: 0.2742 - val_accuracy: 0.6876\n",
      "Epoch 431/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2733 - accuracy: 0.6895 - val_loss: 0.2741 - val_accuracy: 0.6877\n",
      "Epoch 432/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2732 - accuracy: 0.6896 - val_loss: 0.2741 - val_accuracy: 0.6877\n",
      "Epoch 433/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2732 - accuracy: 0.6896 - val_loss: 0.2740 - val_accuracy: 0.6878\n",
      "Epoch 434/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2731 - accuracy: 0.6896 - val_loss: 0.2740 - val_accuracy: 0.6878\n",
      "Epoch 435/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2731 - accuracy: 0.6896 - val_loss: 0.2739 - val_accuracy: 0.6878\n",
      "Epoch 436/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2730 - accuracy: 0.6897 - val_loss: 0.2739 - val_accuracy: 0.6879\n",
      "Epoch 437/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2730 - accuracy: 0.6898 - val_loss: 0.2738 - val_accuracy: 0.6879\n",
      "Epoch 438/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2730 - accuracy: 0.6898 - val_loss: 0.2738 - val_accuracy: 0.6880\n",
      "Epoch 439/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2729 - accuracy: 0.6898 - val_loss: 0.2737 - val_accuracy: 0.6880\n",
      "Epoch 440/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2729 - accuracy: 0.6898 - val_loss: 0.2737 - val_accuracy: 0.6881\n",
      "Epoch 441/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2728 - accuracy: 0.6898 - val_loss: 0.2736 - val_accuracy: 0.6882\n",
      "Epoch 442/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2728 - accuracy: 0.6899 - val_loss: 0.2736 - val_accuracy: 0.6881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 443/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2727 - accuracy: 0.6899 - val_loss: 0.2735 - val_accuracy: 0.6881\n",
      "Epoch 444/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2727 - accuracy: 0.6900 - val_loss: 0.2735 - val_accuracy: 0.6881\n",
      "Epoch 445/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2726 - accuracy: 0.6900 - val_loss: 0.2734 - val_accuracy: 0.6882\n",
      "Epoch 446/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2726 - accuracy: 0.6901 - val_loss: 0.2734 - val_accuracy: 0.6882\n",
      "Epoch 447/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2726 - accuracy: 0.6901 - val_loss: 0.2733 - val_accuracy: 0.6882\n",
      "Epoch 448/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2725 - accuracy: 0.6902 - val_loss: 0.2733 - val_accuracy: 0.6883\n",
      "Epoch 449/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2725 - accuracy: 0.6902 - val_loss: 0.2732 - val_accuracy: 0.6884\n",
      "Epoch 450/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2724 - accuracy: 0.6902 - val_loss: 0.2732 - val_accuracy: 0.6883\n",
      "Epoch 451/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2724 - accuracy: 0.6903 - val_loss: 0.2731 - val_accuracy: 0.6883\n",
      "Epoch 452/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2723 - accuracy: 0.6903 - val_loss: 0.2731 - val_accuracy: 0.6883\n",
      "Epoch 453/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2723 - accuracy: 0.6903 - val_loss: 0.2731 - val_accuracy: 0.6883\n",
      "Epoch 454/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2723 - accuracy: 0.6904 - val_loss: 0.2730 - val_accuracy: 0.6884\n",
      "Epoch 455/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2722 - accuracy: 0.6904 - val_loss: 0.2730 - val_accuracy: 0.6884\n",
      "Epoch 456/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2722 - accuracy: 0.6904 - val_loss: 0.2729 - val_accuracy: 0.6885\n",
      "Epoch 457/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2721 - accuracy: 0.6904 - val_loss: 0.2729 - val_accuracy: 0.6886\n",
      "Epoch 458/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2721 - accuracy: 0.6905 - val_loss: 0.2728 - val_accuracy: 0.6886\n",
      "Epoch 459/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2720 - accuracy: 0.6906 - val_loss: 0.2728 - val_accuracy: 0.6887\n",
      "Epoch 460/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2720 - accuracy: 0.6907 - val_loss: 0.2727 - val_accuracy: 0.6887\n",
      "Epoch 461/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2720 - accuracy: 0.6906 - val_loss: 0.2727 - val_accuracy: 0.6888\n",
      "Epoch 462/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2719 - accuracy: 0.6906 - val_loss: 0.2726 - val_accuracy: 0.6888\n",
      "Epoch 463/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2719 - accuracy: 0.6907 - val_loss: 0.2726 - val_accuracy: 0.6889\n",
      "Epoch 464/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2718 - accuracy: 0.6908 - val_loss: 0.2725 - val_accuracy: 0.6890\n",
      "Epoch 465/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2718 - accuracy: 0.6908 - val_loss: 0.2725 - val_accuracy: 0.6891\n",
      "Epoch 466/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2718 - accuracy: 0.6908 - val_loss: 0.2725 - val_accuracy: 0.6891\n",
      "Epoch 467/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2717 - accuracy: 0.6909 - val_loss: 0.2724 - val_accuracy: 0.6893\n",
      "Epoch 468/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2717 - accuracy: 0.6909 - val_loss: 0.2724 - val_accuracy: 0.6893\n",
      "Epoch 469/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2716 - accuracy: 0.6909 - val_loss: 0.2723 - val_accuracy: 0.6894\n",
      "Epoch 470/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2716 - accuracy: 0.6910 - val_loss: 0.2723 - val_accuracy: 0.6895\n",
      "Epoch 471/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2716 - accuracy: 0.6910 - val_loss: 0.2723 - val_accuracy: 0.6896\n",
      "Epoch 472/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2715 - accuracy: 0.6910 - val_loss: 0.2722 - val_accuracy: 0.6897\n",
      "Epoch 473/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2715 - accuracy: 0.6910 - val_loss: 0.2722 - val_accuracy: 0.6898\n",
      "Epoch 474/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2714 - accuracy: 0.6911 - val_loss: 0.2721 - val_accuracy: 0.6898\n",
      "Epoch 475/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2714 - accuracy: 0.6911 - val_loss: 0.2721 - val_accuracy: 0.6899\n",
      "Epoch 476/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2714 - accuracy: 0.6912 - val_loss: 0.2721 - val_accuracy: 0.6899\n",
      "Epoch 477/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2713 - accuracy: 0.6912 - val_loss: 0.2720 - val_accuracy: 0.6898\n",
      "Epoch 478/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2713 - accuracy: 0.6913 - val_loss: 0.2720 - val_accuracy: 0.6899\n",
      "Epoch 479/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2713 - accuracy: 0.6913 - val_loss: 0.2719 - val_accuracy: 0.6898\n",
      "Epoch 480/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2712 - accuracy: 0.6914 - val_loss: 0.2719 - val_accuracy: 0.6899\n",
      "Epoch 481/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2712 - accuracy: 0.6914 - val_loss: 0.2719 - val_accuracy: 0.6898\n",
      "Epoch 482/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2712 - accuracy: 0.6915 - val_loss: 0.2718 - val_accuracy: 0.6899\n",
      "Epoch 483/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2711 - accuracy: 0.6915 - val_loss: 0.2718 - val_accuracy: 0.6899\n",
      "Epoch 484/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2711 - accuracy: 0.6915 - val_loss: 0.2717 - val_accuracy: 0.6899\n",
      "Epoch 485/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2710 - accuracy: 0.6915 - val_loss: 0.2717 - val_accuracy: 0.6899\n",
      "Epoch 486/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2710 - accuracy: 0.6916 - val_loss: 0.2717 - val_accuracy: 0.6900\n",
      "Epoch 487/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2710 - accuracy: 0.6916 - val_loss: 0.2716 - val_accuracy: 0.6900\n",
      "Epoch 488/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2709 - accuracy: 0.6916 - val_loss: 0.2716 - val_accuracy: 0.6901\n",
      "Epoch 489/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2709 - accuracy: 0.6916 - val_loss: 0.2716 - val_accuracy: 0.6901\n",
      "Epoch 490/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2709 - accuracy: 0.6917 - val_loss: 0.2715 - val_accuracy: 0.6902\n",
      "Epoch 491/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2708 - accuracy: 0.6916 - val_loss: 0.2715 - val_accuracy: 0.6903\n",
      "Epoch 492/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2708 - accuracy: 0.6917 - val_loss: 0.2714 - val_accuracy: 0.6903\n",
      "Epoch 493/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2708 - accuracy: 0.6917 - val_loss: 0.2714 - val_accuracy: 0.6903\n",
      "Epoch 494/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2707 - accuracy: 0.6917 - val_loss: 0.2714 - val_accuracy: 0.6904\n",
      "Epoch 495/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2707 - accuracy: 0.6918 - val_loss: 0.2713 - val_accuracy: 0.6904\n",
      "Epoch 496/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2706 - accuracy: 0.6918 - val_loss: 0.2713 - val_accuracy: 0.6905\n",
      "Epoch 497/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2706 - accuracy: 0.6918 - val_loss: 0.2712 - val_accuracy: 0.6904\n",
      "Epoch 498/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2706 - accuracy: 0.6919 - val_loss: 0.2712 - val_accuracy: 0.6905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2705 - accuracy: 0.6919 - val_loss: 0.2712 - val_accuracy: 0.6904\n",
      "Epoch 500/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2705 - accuracy: 0.6919 - val_loss: 0.2711 - val_accuracy: 0.6904\n",
      "Epoch 501/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2705 - accuracy: 0.6919 - val_loss: 0.2711 - val_accuracy: 0.6905\n",
      "Epoch 502/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2704 - accuracy: 0.6920 - val_loss: 0.2711 - val_accuracy: 0.6905\n",
      "Epoch 503/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2704 - accuracy: 0.6920 - val_loss: 0.2710 - val_accuracy: 0.6905\n",
      "Epoch 504/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2704 - accuracy: 0.6920 - val_loss: 0.2710 - val_accuracy: 0.6906\n",
      "Epoch 505/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2703 - accuracy: 0.6921 - val_loss: 0.2710 - val_accuracy: 0.6906\n",
      "Epoch 506/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2703 - accuracy: 0.6922 - val_loss: 0.2709 - val_accuracy: 0.6906\n",
      "Epoch 507/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2703 - accuracy: 0.6921 - val_loss: 0.2709 - val_accuracy: 0.6906\n",
      "Epoch 508/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2702 - accuracy: 0.6922 - val_loss: 0.2709 - val_accuracy: 0.6907\n",
      "Epoch 509/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2702 - accuracy: 0.6923 - val_loss: 0.2708 - val_accuracy: 0.6907\n",
      "Epoch 510/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2702 - accuracy: 0.6923 - val_loss: 0.2708 - val_accuracy: 0.6907\n",
      "Epoch 511/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2701 - accuracy: 0.6923 - val_loss: 0.2708 - val_accuracy: 0.6908\n",
      "Epoch 512/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2701 - accuracy: 0.6924 - val_loss: 0.2708 - val_accuracy: 0.6907\n",
      "Epoch 513/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2701 - accuracy: 0.6923 - val_loss: 0.2707 - val_accuracy: 0.6908\n",
      "Epoch 514/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2701 - accuracy: 0.6923 - val_loss: 0.2707 - val_accuracy: 0.6908\n",
      "Epoch 515/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2700 - accuracy: 0.6923 - val_loss: 0.2707 - val_accuracy: 0.6909\n",
      "Epoch 516/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2700 - accuracy: 0.6924 - val_loss: 0.2706 - val_accuracy: 0.6908\n",
      "Epoch 517/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2700 - accuracy: 0.6924 - val_loss: 0.2706 - val_accuracy: 0.6909\n",
      "Epoch 518/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2699 - accuracy: 0.6925 - val_loss: 0.2706 - val_accuracy: 0.6909\n",
      "Epoch 519/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2699 - accuracy: 0.6925 - val_loss: 0.2706 - val_accuracy: 0.6909\n",
      "Epoch 520/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2699 - accuracy: 0.6925 - val_loss: 0.2705 - val_accuracy: 0.6910\n",
      "Epoch 521/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2699 - accuracy: 0.6925 - val_loss: 0.2705 - val_accuracy: 0.6910\n",
      "Epoch 522/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2698 - accuracy: 0.6926 - val_loss: 0.2705 - val_accuracy: 0.6910\n",
      "Epoch 523/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2698 - accuracy: 0.6926 - val_loss: 0.2705 - val_accuracy: 0.6911\n",
      "Epoch 524/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2698 - accuracy: 0.6926 - val_loss: 0.2704 - val_accuracy: 0.6911\n",
      "Epoch 525/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2698 - accuracy: 0.6927 - val_loss: 0.2704 - val_accuracy: 0.6911\n",
      "Epoch 526/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2697 - accuracy: 0.6927 - val_loss: 0.2704 - val_accuracy: 0.6912\n",
      "Epoch 527/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2697 - accuracy: 0.6928 - val_loss: 0.2703 - val_accuracy: 0.6911\n",
      "Epoch 528/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2697 - accuracy: 0.6928 - val_loss: 0.2703 - val_accuracy: 0.6912\n",
      "Epoch 529/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2696 - accuracy: 0.6928 - val_loss: 0.2703 - val_accuracy: 0.6912\n",
      "Epoch 530/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2696 - accuracy: 0.6928 - val_loss: 0.2703 - val_accuracy: 0.6913\n",
      "Epoch 531/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2696 - accuracy: 0.6930 - val_loss: 0.2702 - val_accuracy: 0.6913\n",
      "Epoch 532/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2696 - accuracy: 0.6930 - val_loss: 0.2702 - val_accuracy: 0.6913\n",
      "Epoch 533/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2695 - accuracy: 0.6930 - val_loss: 0.2702 - val_accuracy: 0.6914\n",
      "Epoch 534/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2695 - accuracy: 0.6931 - val_loss: 0.2702 - val_accuracy: 0.6916\n",
      "Epoch 535/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2695 - accuracy: 0.6932 - val_loss: 0.2701 - val_accuracy: 0.6917\n",
      "Epoch 536/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2694 - accuracy: 0.6931 - val_loss: 0.2701 - val_accuracy: 0.6917\n",
      "Epoch 537/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2694 - accuracy: 0.6932 - val_loss: 0.2701 - val_accuracy: 0.6918\n",
      "Epoch 538/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2694 - accuracy: 0.6932 - val_loss: 0.2701 - val_accuracy: 0.6919\n",
      "Epoch 539/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2694 - accuracy: 0.6933 - val_loss: 0.2700 - val_accuracy: 0.6919\n",
      "Epoch 540/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2693 - accuracy: 0.6933 - val_loss: 0.2700 - val_accuracy: 0.6920\n",
      "Epoch 541/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2693 - accuracy: 0.6933 - val_loss: 0.2700 - val_accuracy: 0.6920\n",
      "Epoch 542/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2693 - accuracy: 0.6934 - val_loss: 0.2700 - val_accuracy: 0.6921\n",
      "Epoch 543/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2693 - accuracy: 0.6934 - val_loss: 0.2699 - val_accuracy: 0.6921\n",
      "Epoch 544/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2692 - accuracy: 0.6934 - val_loss: 0.2699 - val_accuracy: 0.6922\n",
      "Epoch 545/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2692 - accuracy: 0.6935 - val_loss: 0.2699 - val_accuracy: 0.6922\n",
      "Epoch 546/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2692 - accuracy: 0.6934 - val_loss: 0.2699 - val_accuracy: 0.6923\n",
      "Epoch 547/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2691 - accuracy: 0.6935 - val_loss: 0.2698 - val_accuracy: 0.6924\n",
      "Epoch 548/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2691 - accuracy: 0.6935 - val_loss: 0.2698 - val_accuracy: 0.6924\n",
      "Epoch 549/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2691 - accuracy: 0.6935 - val_loss: 0.2698 - val_accuracy: 0.6924\n",
      "Epoch 550/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2691 - accuracy: 0.6936 - val_loss: 0.2697 - val_accuracy: 0.6924\n",
      "Epoch 551/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2690 - accuracy: 0.6936 - val_loss: 0.2697 - val_accuracy: 0.6924\n",
      "Epoch 552/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2690 - accuracy: 0.6935 - val_loss: 0.2697 - val_accuracy: 0.6924\n",
      "Epoch 553/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2690 - accuracy: 0.6935 - val_loss: 0.2697 - val_accuracy: 0.6924\n",
      "Epoch 554/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2690 - accuracy: 0.6936 - val_loss: 0.2696 - val_accuracy: 0.6925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 555/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2689 - accuracy: 0.6936 - val_loss: 0.2696 - val_accuracy: 0.6925\n",
      "Epoch 556/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2689 - accuracy: 0.6936 - val_loss: 0.2696 - val_accuracy: 0.6925\n",
      "Epoch 557/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2689 - accuracy: 0.6937 - val_loss: 0.2696 - val_accuracy: 0.6925\n",
      "Epoch 558/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2688 - accuracy: 0.6938 - val_loss: 0.2695 - val_accuracy: 0.6924\n",
      "Epoch 559/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2688 - accuracy: 0.6938 - val_loss: 0.2695 - val_accuracy: 0.6925\n",
      "Epoch 560/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2688 - accuracy: 0.6938 - val_loss: 0.2695 - val_accuracy: 0.6926\n",
      "Epoch 561/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2688 - accuracy: 0.6939 - val_loss: 0.2694 - val_accuracy: 0.6927\n",
      "Epoch 562/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2687 - accuracy: 0.6939 - val_loss: 0.2694 - val_accuracy: 0.6927\n",
      "Epoch 563/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2687 - accuracy: 0.6939 - val_loss: 0.2694 - val_accuracy: 0.6927\n",
      "Epoch 564/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2687 - accuracy: 0.6939 - val_loss: 0.2694 - val_accuracy: 0.6927\n",
      "Epoch 565/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2686 - accuracy: 0.6940 - val_loss: 0.2693 - val_accuracy: 0.6927\n",
      "Epoch 566/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2686 - accuracy: 0.6940 - val_loss: 0.2693 - val_accuracy: 0.6928\n",
      "Epoch 567/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2686 - accuracy: 0.6940 - val_loss: 0.2693 - val_accuracy: 0.6928\n",
      "Epoch 568/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2686 - accuracy: 0.6940 - val_loss: 0.2692 - val_accuracy: 0.6928\n",
      "Epoch 569/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2685 - accuracy: 0.6941 - val_loss: 0.2692 - val_accuracy: 0.6928\n",
      "Epoch 570/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2685 - accuracy: 0.6941 - val_loss: 0.2692 - val_accuracy: 0.6928\n",
      "Epoch 571/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2685 - accuracy: 0.6940 - val_loss: 0.2692 - val_accuracy: 0.6928\n",
      "Epoch 572/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2685 - accuracy: 0.6940 - val_loss: 0.2691 - val_accuracy: 0.6928\n",
      "Epoch 573/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2684 - accuracy: 0.6940 - val_loss: 0.2691 - val_accuracy: 0.6929\n",
      "Epoch 574/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2684 - accuracy: 0.6941 - val_loss: 0.2691 - val_accuracy: 0.6930\n",
      "Epoch 575/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2684 - accuracy: 0.6940 - val_loss: 0.2690 - val_accuracy: 0.6931\n",
      "Epoch 576/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2683 - accuracy: 0.6940 - val_loss: 0.2690 - val_accuracy: 0.6930\n",
      "Epoch 577/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2683 - accuracy: 0.6941 - val_loss: 0.2690 - val_accuracy: 0.6931\n",
      "Epoch 578/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2683 - accuracy: 0.6941 - val_loss: 0.2690 - val_accuracy: 0.6932\n",
      "Epoch 579/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2683 - accuracy: 0.6942 - val_loss: 0.2689 - val_accuracy: 0.6932\n",
      "Epoch 580/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2682 - accuracy: 0.6942 - val_loss: 0.2689 - val_accuracy: 0.6932\n",
      "Epoch 581/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2682 - accuracy: 0.6942 - val_loss: 0.2689 - val_accuracy: 0.6933\n",
      "Epoch 582/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2682 - accuracy: 0.6943 - val_loss: 0.2688 - val_accuracy: 0.6933\n",
      "Epoch 583/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2681 - accuracy: 0.6943 - val_loss: 0.2688 - val_accuracy: 0.6932\n",
      "Epoch 584/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2681 - accuracy: 0.6943 - val_loss: 0.2688 - val_accuracy: 0.6932\n",
      "Epoch 585/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2681 - accuracy: 0.6943 - val_loss: 0.2687 - val_accuracy: 0.6932\n",
      "Epoch 586/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2681 - accuracy: 0.6943 - val_loss: 0.2687 - val_accuracy: 0.6933\n",
      "Epoch 587/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2680 - accuracy: 0.6944 - val_loss: 0.2687 - val_accuracy: 0.6933\n",
      "Epoch 588/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2680 - accuracy: 0.6944 - val_loss: 0.2687 - val_accuracy: 0.6934\n",
      "Epoch 589/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2680 - accuracy: 0.6945 - val_loss: 0.2686 - val_accuracy: 0.6934\n",
      "Epoch 590/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2680 - accuracy: 0.6945 - val_loss: 0.2686 - val_accuracy: 0.6934\n",
      "Epoch 591/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2679 - accuracy: 0.6945 - val_loss: 0.2686 - val_accuracy: 0.6934\n",
      "Epoch 592/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2679 - accuracy: 0.6946 - val_loss: 0.2686 - val_accuracy: 0.6934\n",
      "Epoch 593/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2679 - accuracy: 0.6946 - val_loss: 0.2685 - val_accuracy: 0.6935\n",
      "Epoch 594/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2679 - accuracy: 0.6946 - val_loss: 0.2685 - val_accuracy: 0.6934\n",
      "Epoch 595/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2679 - accuracy: 0.6946 - val_loss: 0.2685 - val_accuracy: 0.6934\n",
      "Epoch 596/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2678 - accuracy: 0.6946 - val_loss: 0.2685 - val_accuracy: 0.6935\n",
      "Epoch 597/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2678 - accuracy: 0.6946 - val_loss: 0.2684 - val_accuracy: 0.6936\n",
      "Epoch 598/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2678 - accuracy: 0.6946 - val_loss: 0.2684 - val_accuracy: 0.6936\n",
      "Epoch 599/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2678 - accuracy: 0.6946 - val_loss: 0.2684 - val_accuracy: 0.6936\n",
      "Epoch 600/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2677 - accuracy: 0.6947 - val_loss: 0.2684 - val_accuracy: 0.6937\n",
      "Epoch 601/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2677 - accuracy: 0.6946 - val_loss: 0.2683 - val_accuracy: 0.6937\n",
      "Epoch 602/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2677 - accuracy: 0.6947 - val_loss: 0.2683 - val_accuracy: 0.6937\n",
      "Epoch 603/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2677 - accuracy: 0.6946 - val_loss: 0.2683 - val_accuracy: 0.6938\n",
      "Epoch 604/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2676 - accuracy: 0.6947 - val_loss: 0.2683 - val_accuracy: 0.6938\n",
      "Epoch 605/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2676 - accuracy: 0.6946 - val_loss: 0.2682 - val_accuracy: 0.6938\n",
      "Epoch 606/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2676 - accuracy: 0.6946 - val_loss: 0.2682 - val_accuracy: 0.6939\n",
      "Epoch 607/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2676 - accuracy: 0.6946 - val_loss: 0.2682 - val_accuracy: 0.6939\n",
      "Epoch 608/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2676 - accuracy: 0.6947 - val_loss: 0.2682 - val_accuracy: 0.6939\n",
      "Epoch 609/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2675 - accuracy: 0.6947 - val_loss: 0.2682 - val_accuracy: 0.6940\n",
      "Epoch 610/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2675 - accuracy: 0.6947 - val_loss: 0.2681 - val_accuracy: 0.6940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 611/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2675 - accuracy: 0.6947 - val_loss: 0.2681 - val_accuracy: 0.6940\n",
      "Epoch 612/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2675 - accuracy: 0.6947 - val_loss: 0.2681 - val_accuracy: 0.6941\n",
      "Epoch 613/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2674 - accuracy: 0.6948 - val_loss: 0.2680 - val_accuracy: 0.6940\n",
      "Epoch 614/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2674 - accuracy: 0.6948 - val_loss: 0.2680 - val_accuracy: 0.6941\n",
      "Epoch 615/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2674 - accuracy: 0.6949 - val_loss: 0.2680 - val_accuracy: 0.6941\n",
      "Epoch 616/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2674 - accuracy: 0.6949 - val_loss: 0.2680 - val_accuracy: 0.6942\n",
      "Epoch 617/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2673 - accuracy: 0.6950 - val_loss: 0.2679 - val_accuracy: 0.6942\n",
      "Epoch 618/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2673 - accuracy: 0.6950 - val_loss: 0.2679 - val_accuracy: 0.6942\n",
      "Epoch 619/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2673 - accuracy: 0.6950 - val_loss: 0.2679 - val_accuracy: 0.6943\n",
      "Epoch 620/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2673 - accuracy: 0.6951 - val_loss: 0.2679 - val_accuracy: 0.6943\n",
      "Epoch 621/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2672 - accuracy: 0.6951 - val_loss: 0.2678 - val_accuracy: 0.6943\n",
      "Epoch 622/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2672 - accuracy: 0.6951 - val_loss: 0.2678 - val_accuracy: 0.6943\n",
      "Epoch 623/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2672 - accuracy: 0.6951 - val_loss: 0.2678 - val_accuracy: 0.6943\n",
      "Epoch 624/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2672 - accuracy: 0.6951 - val_loss: 0.2678 - val_accuracy: 0.6943\n",
      "Epoch 625/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2672 - accuracy: 0.6952 - val_loss: 0.2677 - val_accuracy: 0.6944\n",
      "Epoch 626/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2671 - accuracy: 0.6952 - val_loss: 0.2677 - val_accuracy: 0.6944\n",
      "Epoch 627/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2671 - accuracy: 0.6952 - val_loss: 0.2677 - val_accuracy: 0.6944\n",
      "Epoch 628/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2671 - accuracy: 0.6953 - val_loss: 0.2677 - val_accuracy: 0.6944\n",
      "Epoch 629/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2671 - accuracy: 0.6953 - val_loss: 0.2677 - val_accuracy: 0.6944\n",
      "Epoch 630/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2671 - accuracy: 0.6953 - val_loss: 0.2676 - val_accuracy: 0.6945\n",
      "Epoch 631/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2670 - accuracy: 0.6953 - val_loss: 0.2676 - val_accuracy: 0.6945\n",
      "Epoch 632/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2670 - accuracy: 0.6954 - val_loss: 0.2676 - val_accuracy: 0.6946\n",
      "Epoch 633/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2670 - accuracy: 0.6954 - val_loss: 0.2676 - val_accuracy: 0.6946\n",
      "Epoch 634/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2670 - accuracy: 0.6954 - val_loss: 0.2675 - val_accuracy: 0.6946\n",
      "Epoch 635/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2670 - accuracy: 0.6954 - val_loss: 0.2675 - val_accuracy: 0.6946\n",
      "Epoch 636/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2669 - accuracy: 0.6954 - val_loss: 0.2675 - val_accuracy: 0.6946\n",
      "Epoch 637/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2669 - accuracy: 0.6955 - val_loss: 0.2675 - val_accuracy: 0.6946\n",
      "Epoch 638/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2669 - accuracy: 0.6955 - val_loss: 0.2674 - val_accuracy: 0.6947\n",
      "Epoch 639/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2669 - accuracy: 0.6955 - val_loss: 0.2674 - val_accuracy: 0.6946\n",
      "Epoch 640/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2668 - accuracy: 0.6955 - val_loss: 0.2674 - val_accuracy: 0.6947\n",
      "Epoch 641/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2668 - accuracy: 0.6955 - val_loss: 0.2674 - val_accuracy: 0.6947\n",
      "Epoch 642/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2668 - accuracy: 0.6956 - val_loss: 0.2673 - val_accuracy: 0.6947\n",
      "Epoch 643/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2668 - accuracy: 0.6956 - val_loss: 0.2673 - val_accuracy: 0.6947\n",
      "Epoch 644/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2667 - accuracy: 0.6957 - val_loss: 0.2673 - val_accuracy: 0.6947\n",
      "Epoch 645/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2667 - accuracy: 0.6957 - val_loss: 0.2672 - val_accuracy: 0.6948\n",
      "Epoch 646/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2667 - accuracy: 0.6957 - val_loss: 0.2672 - val_accuracy: 0.6948\n",
      "Epoch 647/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2667 - accuracy: 0.6958 - val_loss: 0.2672 - val_accuracy: 0.6949\n",
      "Epoch 648/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2666 - accuracy: 0.6957 - val_loss: 0.2672 - val_accuracy: 0.6949\n",
      "Epoch 649/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2666 - accuracy: 0.6957 - val_loss: 0.2671 - val_accuracy: 0.6950\n",
      "Epoch 650/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2666 - accuracy: 0.6957 - val_loss: 0.2671 - val_accuracy: 0.6949\n",
      "Epoch 651/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2666 - accuracy: 0.6958 - val_loss: 0.2671 - val_accuracy: 0.6950\n",
      "Epoch 652/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2665 - accuracy: 0.6957 - val_loss: 0.2671 - val_accuracy: 0.6950\n",
      "Epoch 653/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2665 - accuracy: 0.6958 - val_loss: 0.2671 - val_accuracy: 0.6950\n",
      "Epoch 654/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2665 - accuracy: 0.6959 - val_loss: 0.2670 - val_accuracy: 0.6951\n",
      "Epoch 655/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2665 - accuracy: 0.6959 - val_loss: 0.2670 - val_accuracy: 0.6951\n",
      "Epoch 656/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2664 - accuracy: 0.6960 - val_loss: 0.2670 - val_accuracy: 0.6951\n",
      "Epoch 657/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2664 - accuracy: 0.6959 - val_loss: 0.2670 - val_accuracy: 0.6951\n",
      "Epoch 658/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2664 - accuracy: 0.6959 - val_loss: 0.2669 - val_accuracy: 0.6952\n",
      "Epoch 659/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2663 - accuracy: 0.6959 - val_loss: 0.2669 - val_accuracy: 0.6952\n",
      "Epoch 660/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2663 - accuracy: 0.6960 - val_loss: 0.2669 - val_accuracy: 0.6952\n",
      "Epoch 661/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2663 - accuracy: 0.6960 - val_loss: 0.2669 - val_accuracy: 0.6952\n",
      "Epoch 662/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2663 - accuracy: 0.6960 - val_loss: 0.2669 - val_accuracy: 0.6952\n",
      "Epoch 663/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2663 - accuracy: 0.6960 - val_loss: 0.2668 - val_accuracy: 0.6952\n",
      "Epoch 664/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2662 - accuracy: 0.6961 - val_loss: 0.2668 - val_accuracy: 0.6953\n",
      "Epoch 665/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2662 - accuracy: 0.6961 - val_loss: 0.2668 - val_accuracy: 0.6954\n",
      "Epoch 666/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2662 - accuracy: 0.6961 - val_loss: 0.2668 - val_accuracy: 0.6954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 667/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2662 - accuracy: 0.6962 - val_loss: 0.2668 - val_accuracy: 0.6954\n",
      "Epoch 668/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2662 - accuracy: 0.6962 - val_loss: 0.2668 - val_accuracy: 0.6954\n",
      "Epoch 669/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2661 - accuracy: 0.6962 - val_loss: 0.2667 - val_accuracy: 0.6954\n",
      "Epoch 670/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2661 - accuracy: 0.6962 - val_loss: 0.2667 - val_accuracy: 0.6954\n",
      "Epoch 671/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2661 - accuracy: 0.6963 - val_loss: 0.2667 - val_accuracy: 0.6955\n",
      "Epoch 672/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2661 - accuracy: 0.6964 - val_loss: 0.2667 - val_accuracy: 0.6956\n",
      "Epoch 673/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2660 - accuracy: 0.6964 - val_loss: 0.2667 - val_accuracy: 0.6957\n",
      "Epoch 674/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2660 - accuracy: 0.6964 - val_loss: 0.2667 - val_accuracy: 0.6957\n",
      "Epoch 675/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2660 - accuracy: 0.6964 - val_loss: 0.2666 - val_accuracy: 0.6957\n",
      "Epoch 676/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2660 - accuracy: 0.6964 - val_loss: 0.2666 - val_accuracy: 0.6957\n",
      "Epoch 677/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2660 - accuracy: 0.6964 - val_loss: 0.2666 - val_accuracy: 0.6957\n",
      "Epoch 678/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2659 - accuracy: 0.6964 - val_loss: 0.2666 - val_accuracy: 0.6958\n",
      "Epoch 679/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2659 - accuracy: 0.6964 - val_loss: 0.2666 - val_accuracy: 0.6957\n",
      "Epoch 680/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2659 - accuracy: 0.6964 - val_loss: 0.2665 - val_accuracy: 0.6957\n",
      "Epoch 681/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2659 - accuracy: 0.6965 - val_loss: 0.2665 - val_accuracy: 0.6958\n",
      "Epoch 682/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2659 - accuracy: 0.6965 - val_loss: 0.2665 - val_accuracy: 0.6959\n",
      "Epoch 683/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2659 - accuracy: 0.6966 - val_loss: 0.2665 - val_accuracy: 0.6958\n",
      "Epoch 684/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2658 - accuracy: 0.6966 - val_loss: 0.2665 - val_accuracy: 0.6959\n",
      "Epoch 685/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2658 - accuracy: 0.6966 - val_loss: 0.2665 - val_accuracy: 0.6959\n",
      "Epoch 686/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2658 - accuracy: 0.6966 - val_loss: 0.2664 - val_accuracy: 0.6960\n",
      "Epoch 687/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2658 - accuracy: 0.6966 - val_loss: 0.2664 - val_accuracy: 0.6960\n",
      "Epoch 688/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2658 - accuracy: 0.6967 - val_loss: 0.2664 - val_accuracy: 0.6959\n",
      "Epoch 689/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2657 - accuracy: 0.6967 - val_loss: 0.2664 - val_accuracy: 0.6960\n",
      "Epoch 690/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2657 - accuracy: 0.6967 - val_loss: 0.2664 - val_accuracy: 0.6960\n",
      "Epoch 691/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2657 - accuracy: 0.6967 - val_loss: 0.2663 - val_accuracy: 0.6960\n",
      "Epoch 692/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2657 - accuracy: 0.6968 - val_loss: 0.2663 - val_accuracy: 0.6961\n",
      "Epoch 693/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2657 - accuracy: 0.6968 - val_loss: 0.2663 - val_accuracy: 0.6961\n",
      "Epoch 694/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2656 - accuracy: 0.6968 - val_loss: 0.2663 - val_accuracy: 0.6961\n",
      "Epoch 695/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2656 - accuracy: 0.6968 - val_loss: 0.2663 - val_accuracy: 0.6961\n",
      "Epoch 696/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2656 - accuracy: 0.6968 - val_loss: 0.2662 - val_accuracy: 0.6962\n",
      "Epoch 697/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2656 - accuracy: 0.6968 - val_loss: 0.2662 - val_accuracy: 0.6962\n",
      "Epoch 698/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2656 - accuracy: 0.6969 - val_loss: 0.2662 - val_accuracy: 0.6962\n",
      "Epoch 699/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2656 - accuracy: 0.6969 - val_loss: 0.2662 - val_accuracy: 0.6962\n",
      "Epoch 700/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2655 - accuracy: 0.6969 - val_loss: 0.2662 - val_accuracy: 0.6962\n",
      "Epoch 701/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2655 - accuracy: 0.6970 - val_loss: 0.2662 - val_accuracy: 0.6964\n",
      "Epoch 702/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2655 - accuracy: 0.6970 - val_loss: 0.2661 - val_accuracy: 0.6964\n",
      "Epoch 703/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2655 - accuracy: 0.6970 - val_loss: 0.2661 - val_accuracy: 0.6965\n",
      "Epoch 704/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2655 - accuracy: 0.6971 - val_loss: 0.2661 - val_accuracy: 0.6965\n",
      "Epoch 705/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2654 - accuracy: 0.6971 - val_loss: 0.2661 - val_accuracy: 0.6966\n",
      "Epoch 706/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2654 - accuracy: 0.6971 - val_loss: 0.2661 - val_accuracy: 0.6966\n",
      "Epoch 707/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2654 - accuracy: 0.6972 - val_loss: 0.2661 - val_accuracy: 0.6966\n",
      "Epoch 708/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2654 - accuracy: 0.6972 - val_loss: 0.2660 - val_accuracy: 0.6966\n",
      "Epoch 709/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2654 - accuracy: 0.6972 - val_loss: 0.2660 - val_accuracy: 0.6966\n",
      "Epoch 710/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2654 - accuracy: 0.6972 - val_loss: 0.2660 - val_accuracy: 0.6967\n",
      "Epoch 711/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2653 - accuracy: 0.6972 - val_loss: 0.2660 - val_accuracy: 0.6966\n",
      "Epoch 712/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2653 - accuracy: 0.6972 - val_loss: 0.2660 - val_accuracy: 0.6967\n",
      "Epoch 713/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2653 - accuracy: 0.6972 - val_loss: 0.2659 - val_accuracy: 0.6967\n",
      "Epoch 714/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2653 - accuracy: 0.6972 - val_loss: 0.2659 - val_accuracy: 0.6967\n",
      "Epoch 715/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2653 - accuracy: 0.6972 - val_loss: 0.2659 - val_accuracy: 0.6967\n",
      "Epoch 716/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2653 - accuracy: 0.6972 - val_loss: 0.2659 - val_accuracy: 0.6967\n",
      "Epoch 717/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2652 - accuracy: 0.6973 - val_loss: 0.2659 - val_accuracy: 0.6967\n",
      "Epoch 718/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2652 - accuracy: 0.6973 - val_loss: 0.2659 - val_accuracy: 0.6968\n",
      "Epoch 719/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2652 - accuracy: 0.6973 - val_loss: 0.2658 - val_accuracy: 0.6968\n",
      "Epoch 720/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2652 - accuracy: 0.6973 - val_loss: 0.2658 - val_accuracy: 0.6967\n",
      "Epoch 721/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2652 - accuracy: 0.6974 - val_loss: 0.2658 - val_accuracy: 0.6967\n",
      "Epoch 722/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2652 - accuracy: 0.6974 - val_loss: 0.2658 - val_accuracy: 0.6968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 723/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2651 - accuracy: 0.6974 - val_loss: 0.2658 - val_accuracy: 0.6968\n",
      "Epoch 724/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2651 - accuracy: 0.6974 - val_loss: 0.2658 - val_accuracy: 0.6969\n",
      "Epoch 725/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2651 - accuracy: 0.6974 - val_loss: 0.2657 - val_accuracy: 0.6969\n",
      "Epoch 726/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2651 - accuracy: 0.6974 - val_loss: 0.2657 - val_accuracy: 0.6969\n",
      "Epoch 727/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2651 - accuracy: 0.6975 - val_loss: 0.2657 - val_accuracy: 0.6969\n",
      "Epoch 728/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2651 - accuracy: 0.6975 - val_loss: 0.2657 - val_accuracy: 0.6969\n",
      "Epoch 729/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2650 - accuracy: 0.6975 - val_loss: 0.2657 - val_accuracy: 0.6969\n",
      "Epoch 730/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2650 - accuracy: 0.6975 - val_loss: 0.2657 - val_accuracy: 0.6969\n",
      "Epoch 731/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2650 - accuracy: 0.6975 - val_loss: 0.2656 - val_accuracy: 0.6970\n",
      "Epoch 732/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2650 - accuracy: 0.6975 - val_loss: 0.2656 - val_accuracy: 0.6970\n",
      "Epoch 733/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2650 - accuracy: 0.6975 - val_loss: 0.2656 - val_accuracy: 0.6970\n",
      "Epoch 734/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2649 - accuracy: 0.6975 - val_loss: 0.2656 - val_accuracy: 0.6970\n",
      "Epoch 735/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2649 - accuracy: 0.6975 - val_loss: 0.2656 - val_accuracy: 0.6970\n",
      "Epoch 736/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2649 - accuracy: 0.6975 - val_loss: 0.2656 - val_accuracy: 0.6970\n",
      "Epoch 737/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2649 - accuracy: 0.6975 - val_loss: 0.2655 - val_accuracy: 0.6971\n",
      "Epoch 738/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2649 - accuracy: 0.6975 - val_loss: 0.2655 - val_accuracy: 0.6971\n",
      "Epoch 739/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2649 - accuracy: 0.6975 - val_loss: 0.2655 - val_accuracy: 0.6970\n",
      "Epoch 740/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2648 - accuracy: 0.6975 - val_loss: 0.2655 - val_accuracy: 0.6971\n",
      "Epoch 741/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2648 - accuracy: 0.6975 - val_loss: 0.2655 - val_accuracy: 0.6971\n",
      "Epoch 742/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2648 - accuracy: 0.6975 - val_loss: 0.2655 - val_accuracy: 0.6971\n",
      "Epoch 743/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2648 - accuracy: 0.6976 - val_loss: 0.2654 - val_accuracy: 0.6972\n",
      "Epoch 744/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2648 - accuracy: 0.6976 - val_loss: 0.2654 - val_accuracy: 0.6972\n",
      "Epoch 745/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2648 - accuracy: 0.6976 - val_loss: 0.2654 - val_accuracy: 0.6972\n",
      "Epoch 746/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2647 - accuracy: 0.6977 - val_loss: 0.2654 - val_accuracy: 0.6973\n",
      "Epoch 747/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2647 - accuracy: 0.6976 - val_loss: 0.2654 - val_accuracy: 0.6973\n",
      "Epoch 748/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2647 - accuracy: 0.6977 - val_loss: 0.2654 - val_accuracy: 0.6974\n",
      "Epoch 749/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2647 - accuracy: 0.6977 - val_loss: 0.2653 - val_accuracy: 0.6974\n",
      "Epoch 750/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2647 - accuracy: 0.6977 - val_loss: 0.2653 - val_accuracy: 0.6974\n",
      "Epoch 751/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2647 - accuracy: 0.6977 - val_loss: 0.2653 - val_accuracy: 0.6975\n",
      "Epoch 752/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2646 - accuracy: 0.6977 - val_loss: 0.2653 - val_accuracy: 0.6975\n",
      "Epoch 753/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2646 - accuracy: 0.6977 - val_loss: 0.2653 - val_accuracy: 0.6975\n",
      "Epoch 754/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2646 - accuracy: 0.6978 - val_loss: 0.2653 - val_accuracy: 0.6975\n",
      "Epoch 755/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2646 - accuracy: 0.6978 - val_loss: 0.2652 - val_accuracy: 0.6976\n",
      "Epoch 756/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2646 - accuracy: 0.6978 - val_loss: 0.2652 - val_accuracy: 0.6977\n",
      "Epoch 757/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2646 - accuracy: 0.6978 - val_loss: 0.2652 - val_accuracy: 0.6976\n",
      "Epoch 758/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2645 - accuracy: 0.6978 - val_loss: 0.2652 - val_accuracy: 0.6978\n",
      "Epoch 759/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2645 - accuracy: 0.6978 - val_loss: 0.2652 - val_accuracy: 0.6978\n",
      "Epoch 760/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2645 - accuracy: 0.6978 - val_loss: 0.2652 - val_accuracy: 0.6979\n",
      "Epoch 761/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2645 - accuracy: 0.6979 - val_loss: 0.2651 - val_accuracy: 0.6979\n",
      "Epoch 762/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2645 - accuracy: 0.6979 - val_loss: 0.2651 - val_accuracy: 0.6979\n",
      "Epoch 763/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2645 - accuracy: 0.6979 - val_loss: 0.2651 - val_accuracy: 0.6979\n",
      "Epoch 764/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2644 - accuracy: 0.6980 - val_loss: 0.2651 - val_accuracy: 0.6979\n",
      "Epoch 765/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2644 - accuracy: 0.6980 - val_loss: 0.2651 - val_accuracy: 0.6980\n",
      "Epoch 766/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2644 - accuracy: 0.6980 - val_loss: 0.2651 - val_accuracy: 0.6980\n",
      "Epoch 767/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2644 - accuracy: 0.6980 - val_loss: 0.2651 - val_accuracy: 0.6980\n",
      "Epoch 768/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2644 - accuracy: 0.6980 - val_loss: 0.2650 - val_accuracy: 0.6980\n",
      "Epoch 769/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2644 - accuracy: 0.6980 - val_loss: 0.2650 - val_accuracy: 0.6980\n",
      "Epoch 770/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2643 - accuracy: 0.6980 - val_loss: 0.2650 - val_accuracy: 0.6981\n",
      "Epoch 771/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2643 - accuracy: 0.6980 - val_loss: 0.2650 - val_accuracy: 0.6981\n",
      "Epoch 772/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2643 - accuracy: 0.6980 - val_loss: 0.2650 - val_accuracy: 0.6981\n",
      "Epoch 773/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2643 - accuracy: 0.6980 - val_loss: 0.2650 - val_accuracy: 0.6981\n",
      "Epoch 774/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2643 - accuracy: 0.6980 - val_loss: 0.2649 - val_accuracy: 0.6982\n",
      "Epoch 775/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2642 - accuracy: 0.6980 - val_loss: 0.2649 - val_accuracy: 0.6982\n",
      "Epoch 776/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2642 - accuracy: 0.6981 - val_loss: 0.2649 - val_accuracy: 0.6982\n",
      "Epoch 777/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2642 - accuracy: 0.6981 - val_loss: 0.2649 - val_accuracy: 0.6982\n",
      "Epoch 778/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2642 - accuracy: 0.6981 - val_loss: 0.2649 - val_accuracy: 0.6982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 779/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2642 - accuracy: 0.6981 - val_loss: 0.2649 - val_accuracy: 0.6983\n",
      "Epoch 780/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2642 - accuracy: 0.6981 - val_loss: 0.2648 - val_accuracy: 0.6983\n",
      "Epoch 781/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2641 - accuracy: 0.6981 - val_loss: 0.2648 - val_accuracy: 0.6982\n",
      "Epoch 782/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2641 - accuracy: 0.6982 - val_loss: 0.2648 - val_accuracy: 0.6982\n",
      "Epoch 783/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2641 - accuracy: 0.6982 - val_loss: 0.2648 - val_accuracy: 0.6982\n",
      "Epoch 784/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2641 - accuracy: 0.6982 - val_loss: 0.2648 - val_accuracy: 0.6982\n",
      "Epoch 785/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2641 - accuracy: 0.6982 - val_loss: 0.2647 - val_accuracy: 0.6981\n",
      "Epoch 786/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2640 - accuracy: 0.6982 - val_loss: 0.2647 - val_accuracy: 0.6981\n",
      "Epoch 787/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2640 - accuracy: 0.6982 - val_loss: 0.2647 - val_accuracy: 0.6981\n",
      "Epoch 788/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2640 - accuracy: 0.6982 - val_loss: 0.2647 - val_accuracy: 0.6981\n",
      "Epoch 789/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2640 - accuracy: 0.6982 - val_loss: 0.2647 - val_accuracy: 0.6981\n",
      "Epoch 790/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2640 - accuracy: 0.6983 - val_loss: 0.2647 - val_accuracy: 0.6982\n",
      "Epoch 791/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2640 - accuracy: 0.6983 - val_loss: 0.2647 - val_accuracy: 0.6982\n",
      "Epoch 792/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2639 - accuracy: 0.6983 - val_loss: 0.2646 - val_accuracy: 0.6982\n",
      "Epoch 793/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2639 - accuracy: 0.6983 - val_loss: 0.2646 - val_accuracy: 0.6982\n",
      "Epoch 794/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2639 - accuracy: 0.6983 - val_loss: 0.2646 - val_accuracy: 0.6983\n",
      "Epoch 795/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2639 - accuracy: 0.6983 - val_loss: 0.2646 - val_accuracy: 0.6983\n",
      "Epoch 796/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2639 - accuracy: 0.6983 - val_loss: 0.2646 - val_accuracy: 0.6984\n",
      "Epoch 797/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2639 - accuracy: 0.6984 - val_loss: 0.2646 - val_accuracy: 0.6984\n",
      "Epoch 798/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2638 - accuracy: 0.6984 - val_loss: 0.2646 - val_accuracy: 0.6984\n",
      "Epoch 799/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2638 - accuracy: 0.6984 - val_loss: 0.2645 - val_accuracy: 0.6985\n",
      "Epoch 800/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2638 - accuracy: 0.6984 - val_loss: 0.2645 - val_accuracy: 0.6985\n",
      "Epoch 801/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2638 - accuracy: 0.6985 - val_loss: 0.2645 - val_accuracy: 0.6985\n",
      "Epoch 802/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2638 - accuracy: 0.6985 - val_loss: 0.2645 - val_accuracy: 0.6985\n",
      "Epoch 803/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2637 - accuracy: 0.6985 - val_loss: 0.2645 - val_accuracy: 0.6986\n",
      "Epoch 804/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2637 - accuracy: 0.6985 - val_loss: 0.2645 - val_accuracy: 0.6986\n",
      "Epoch 805/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2637 - accuracy: 0.6985 - val_loss: 0.2644 - val_accuracy: 0.6986\n",
      "Epoch 806/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2637 - accuracy: 0.6985 - val_loss: 0.2644 - val_accuracy: 0.6986\n",
      "Epoch 807/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2637 - accuracy: 0.6985 - val_loss: 0.2644 - val_accuracy: 0.6986\n",
      "Epoch 808/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2636 - accuracy: 0.6985 - val_loss: 0.2644 - val_accuracy: 0.6986\n",
      "Epoch 809/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2636 - accuracy: 0.6984 - val_loss: 0.2644 - val_accuracy: 0.6986\n",
      "Epoch 810/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2636 - accuracy: 0.6985 - val_loss: 0.2643 - val_accuracy: 0.6986\n",
      "Epoch 811/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2636 - accuracy: 0.6985 - val_loss: 0.2643 - val_accuracy: 0.6987\n",
      "Epoch 812/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2636 - accuracy: 0.6986 - val_loss: 0.2643 - val_accuracy: 0.6987\n",
      "Epoch 813/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2635 - accuracy: 0.6986 - val_loss: 0.2643 - val_accuracy: 0.6986\n",
      "Epoch 814/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2635 - accuracy: 0.6985 - val_loss: 0.2643 - val_accuracy: 0.6987\n",
      "Epoch 815/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2635 - accuracy: 0.6985 - val_loss: 0.2642 - val_accuracy: 0.6988\n",
      "Epoch 816/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2635 - accuracy: 0.6985 - val_loss: 0.2642 - val_accuracy: 0.6988\n",
      "Epoch 817/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2635 - accuracy: 0.6985 - val_loss: 0.2642 - val_accuracy: 0.6988\n",
      "Epoch 818/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2634 - accuracy: 0.6985 - val_loss: 0.2642 - val_accuracy: 0.6987\n",
      "Epoch 819/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2634 - accuracy: 0.6986 - val_loss: 0.2641 - val_accuracy: 0.6987\n",
      "Epoch 820/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2634 - accuracy: 0.6985 - val_loss: 0.2641 - val_accuracy: 0.6987\n",
      "Epoch 821/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2634 - accuracy: 0.6986 - val_loss: 0.2641 - val_accuracy: 0.6988\n",
      "Epoch 822/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2634 - accuracy: 0.6986 - val_loss: 0.2641 - val_accuracy: 0.6988\n",
      "Epoch 823/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2633 - accuracy: 0.6986 - val_loss: 0.2641 - val_accuracy: 0.6989\n",
      "Epoch 824/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2633 - accuracy: 0.6986 - val_loss: 0.2641 - val_accuracy: 0.6988\n",
      "Epoch 825/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2633 - accuracy: 0.6986 - val_loss: 0.2640 - val_accuracy: 0.6989\n",
      "Epoch 826/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2633 - accuracy: 0.6987 - val_loss: 0.2640 - val_accuracy: 0.6989\n",
      "Epoch 827/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2633 - accuracy: 0.6987 - val_loss: 0.2640 - val_accuracy: 0.6990\n",
      "Epoch 828/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2633 - accuracy: 0.6987 - val_loss: 0.2640 - val_accuracy: 0.6989\n",
      "Epoch 829/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2632 - accuracy: 0.6987 - val_loss: 0.2640 - val_accuracy: 0.6989\n",
      "Epoch 830/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2632 - accuracy: 0.6987 - val_loss: 0.2640 - val_accuracy: 0.6989\n",
      "Epoch 831/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2632 - accuracy: 0.6987 - val_loss: 0.2639 - val_accuracy: 0.6990\n",
      "Epoch 832/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2632 - accuracy: 0.6987 - val_loss: 0.2639 - val_accuracy: 0.6989\n",
      "Epoch 833/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2631 - accuracy: 0.6988 - val_loss: 0.2639 - val_accuracy: 0.6990\n",
      "Epoch 834/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2631 - accuracy: 0.6988 - val_loss: 0.2639 - val_accuracy: 0.6991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 835/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2631 - accuracy: 0.6988 - val_loss: 0.2639 - val_accuracy: 0.6990\n",
      "Epoch 836/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2631 - accuracy: 0.6988 - val_loss: 0.2639 - val_accuracy: 0.6991\n",
      "Epoch 837/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2631 - accuracy: 0.6988 - val_loss: 0.2638 - val_accuracy: 0.6990\n",
      "Epoch 838/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2631 - accuracy: 0.6988 - val_loss: 0.2638 - val_accuracy: 0.6991\n",
      "Epoch 839/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2630 - accuracy: 0.6988 - val_loss: 0.2638 - val_accuracy: 0.6991\n",
      "Epoch 840/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2630 - accuracy: 0.6987 - val_loss: 0.2638 - val_accuracy: 0.6992\n",
      "Epoch 841/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2630 - accuracy: 0.6988 - val_loss: 0.2638 - val_accuracy: 0.6992\n",
      "Epoch 842/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2630 - accuracy: 0.6988 - val_loss: 0.2638 - val_accuracy: 0.6993\n",
      "Epoch 843/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2629 - accuracy: 0.6987 - val_loss: 0.2637 - val_accuracy: 0.6993\n",
      "Epoch 844/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2629 - accuracy: 0.6987 - val_loss: 0.2637 - val_accuracy: 0.6993\n",
      "Epoch 845/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2629 - accuracy: 0.6987 - val_loss: 0.2637 - val_accuracy: 0.6992\n",
      "Epoch 846/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2629 - accuracy: 0.6987 - val_loss: 0.2637 - val_accuracy: 0.6992\n",
      "Epoch 847/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2628 - accuracy: 0.6987 - val_loss: 0.2637 - val_accuracy: 0.6992\n",
      "Epoch 848/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2628 - accuracy: 0.6987 - val_loss: 0.2637 - val_accuracy: 0.6992\n",
      "Epoch 849/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2628 - accuracy: 0.6988 - val_loss: 0.2637 - val_accuracy: 0.6992\n",
      "Epoch 850/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2628 - accuracy: 0.6988 - val_loss: 0.2636 - val_accuracy: 0.6992\n",
      "Epoch 851/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2628 - accuracy: 0.6988 - val_loss: 0.2636 - val_accuracy: 0.6992\n",
      "Epoch 852/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2628 - accuracy: 0.6988 - val_loss: 0.2636 - val_accuracy: 0.6992\n",
      "Epoch 853/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2627 - accuracy: 0.6988 - val_loss: 0.2636 - val_accuracy: 0.6993\n",
      "Epoch 854/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2627 - accuracy: 0.6989 - val_loss: 0.2636 - val_accuracy: 0.6993\n",
      "Epoch 855/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2627 - accuracy: 0.6988 - val_loss: 0.2635 - val_accuracy: 0.6993\n",
      "Epoch 856/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2627 - accuracy: 0.6989 - val_loss: 0.2635 - val_accuracy: 0.6993\n",
      "Epoch 857/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2627 - accuracy: 0.6989 - val_loss: 0.2635 - val_accuracy: 0.6993\n",
      "Epoch 858/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2626 - accuracy: 0.6989 - val_loss: 0.2635 - val_accuracy: 0.6993\n",
      "Epoch 859/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2626 - accuracy: 0.6990 - val_loss: 0.2635 - val_accuracy: 0.6993\n",
      "Epoch 860/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2626 - accuracy: 0.6990 - val_loss: 0.2634 - val_accuracy: 0.6993\n",
      "Epoch 861/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2626 - accuracy: 0.6990 - val_loss: 0.2634 - val_accuracy: 0.6993\n",
      "Epoch 862/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2626 - accuracy: 0.6990 - val_loss: 0.2634 - val_accuracy: 0.6993\n",
      "Epoch 863/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2626 - accuracy: 0.6990 - val_loss: 0.2634 - val_accuracy: 0.6993\n",
      "Epoch 864/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2625 - accuracy: 0.6990 - val_loss: 0.2634 - val_accuracy: 0.6993\n",
      "Epoch 865/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2625 - accuracy: 0.6990 - val_loss: 0.2634 - val_accuracy: 0.6993\n",
      "Epoch 866/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2625 - accuracy: 0.6991 - val_loss: 0.2634 - val_accuracy: 0.6993\n",
      "Epoch 867/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2625 - accuracy: 0.6991 - val_loss: 0.2633 - val_accuracy: 0.6993\n",
      "Epoch 868/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2625 - accuracy: 0.6991 - val_loss: 0.2633 - val_accuracy: 0.6994\n",
      "Epoch 869/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2625 - accuracy: 0.6991 - val_loss: 0.2633 - val_accuracy: 0.6994\n",
      "Epoch 870/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2624 - accuracy: 0.6992 - val_loss: 0.2633 - val_accuracy: 0.6994\n",
      "Epoch 871/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2624 - accuracy: 0.6992 - val_loss: 0.2633 - val_accuracy: 0.6994\n",
      "Epoch 872/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2624 - accuracy: 0.6992 - val_loss: 0.2633 - val_accuracy: 0.6994\n",
      "Epoch 873/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2624 - accuracy: 0.6992 - val_loss: 0.2632 - val_accuracy: 0.6995\n",
      "Epoch 874/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2624 - accuracy: 0.6993 - val_loss: 0.2632 - val_accuracy: 0.6995\n",
      "Epoch 875/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2624 - accuracy: 0.6993 - val_loss: 0.2632 - val_accuracy: 0.6995\n",
      "Epoch 876/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2623 - accuracy: 0.6993 - val_loss: 0.2632 - val_accuracy: 0.6995\n",
      "Epoch 877/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2623 - accuracy: 0.6994 - val_loss: 0.2632 - val_accuracy: 0.6995\n",
      "Epoch 878/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2623 - accuracy: 0.6993 - val_loss: 0.2632 - val_accuracy: 0.6995\n",
      "Epoch 879/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2623 - accuracy: 0.6994 - val_loss: 0.2632 - val_accuracy: 0.6995\n",
      "Epoch 880/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2623 - accuracy: 0.6994 - val_loss: 0.2631 - val_accuracy: 0.6995\n",
      "Epoch 881/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2623 - accuracy: 0.6994 - val_loss: 0.2631 - val_accuracy: 0.6995\n",
      "Epoch 882/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2622 - accuracy: 0.6994 - val_loss: 0.2631 - val_accuracy: 0.6995\n",
      "Epoch 883/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2622 - accuracy: 0.6994 - val_loss: 0.2631 - val_accuracy: 0.6995\n",
      "Epoch 884/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2622 - accuracy: 0.6994 - val_loss: 0.2631 - val_accuracy: 0.6996\n",
      "Epoch 885/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2622 - accuracy: 0.6995 - val_loss: 0.2631 - val_accuracy: 0.6996\n",
      "Epoch 886/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2622 - accuracy: 0.6994 - val_loss: 0.2630 - val_accuracy: 0.6996\n",
      "Epoch 887/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2622 - accuracy: 0.6995 - val_loss: 0.2630 - val_accuracy: 0.6996\n",
      "Epoch 888/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2622 - accuracy: 0.6994 - val_loss: 0.2630 - val_accuracy: 0.6996\n",
      "Epoch 889/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2621 - accuracy: 0.6995 - val_loss: 0.2630 - val_accuracy: 0.6997\n",
      "Epoch 890/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2621 - accuracy: 0.6995 - val_loss: 0.2629 - val_accuracy: 0.6999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 891/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2621 - accuracy: 0.6995 - val_loss: 0.2629 - val_accuracy: 0.6998\n",
      "Epoch 892/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2621 - accuracy: 0.6994 - val_loss: 0.2629 - val_accuracy: 0.6999\n",
      "Epoch 893/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2621 - accuracy: 0.6993 - val_loss: 0.2628 - val_accuracy: 0.6998\n",
      "Epoch 894/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2620 - accuracy: 0.6993 - val_loss: 0.2628 - val_accuracy: 0.6998\n",
      "Epoch 895/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2620 - accuracy: 0.6993 - val_loss: 0.2626 - val_accuracy: 0.6999\n",
      "Epoch 896/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2619 - accuracy: 0.6994 - val_loss: 0.2625 - val_accuracy: 0.6998\n",
      "Epoch 897/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2617 - accuracy: 0.6994 - val_loss: 0.2620 - val_accuracy: 0.6997\n",
      "Epoch 898/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2612 - accuracy: 0.7000 - val_loss: 0.2615 - val_accuracy: 0.7006\n",
      "Epoch 899/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2610 - accuracy: 0.7002 - val_loss: 0.2615 - val_accuracy: 0.7007\n",
      "Epoch 900/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2610 - accuracy: 0.7003 - val_loss: 0.2614 - val_accuracy: 0.7008\n",
      "Epoch 901/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2609 - accuracy: 0.7003 - val_loss: 0.2614 - val_accuracy: 0.7007\n",
      "Epoch 902/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2609 - accuracy: 0.7004 - val_loss: 0.2614 - val_accuracy: 0.7008\n",
      "Epoch 903/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2609 - accuracy: 0.7004 - val_loss: 0.2614 - val_accuracy: 0.7008\n",
      "Epoch 904/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2609 - accuracy: 0.7003 - val_loss: 0.2614 - val_accuracy: 0.7008\n",
      "Epoch 905/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2609 - accuracy: 0.7004 - val_loss: 0.2614 - val_accuracy: 0.7008\n",
      "Epoch 906/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2608 - accuracy: 0.7004 - val_loss: 0.2613 - val_accuracy: 0.7008\n",
      "Epoch 907/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2608 - accuracy: 0.7004 - val_loss: 0.2613 - val_accuracy: 0.7008\n",
      "Epoch 908/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2608 - accuracy: 0.7004 - val_loss: 0.2613 - val_accuracy: 0.7009\n",
      "Epoch 909/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2608 - accuracy: 0.7004 - val_loss: 0.2613 - val_accuracy: 0.7009\n",
      "Epoch 910/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2608 - accuracy: 0.7004 - val_loss: 0.2613 - val_accuracy: 0.7009\n",
      "Epoch 911/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2608 - accuracy: 0.7004 - val_loss: 0.2613 - val_accuracy: 0.7010\n",
      "Epoch 912/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2607 - accuracy: 0.7005 - val_loss: 0.2612 - val_accuracy: 0.7010\n",
      "Epoch 913/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2607 - accuracy: 0.7005 - val_loss: 0.2612 - val_accuracy: 0.7010\n",
      "Epoch 914/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2607 - accuracy: 0.7006 - val_loss: 0.2612 - val_accuracy: 0.7009\n",
      "Epoch 915/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2607 - accuracy: 0.7006 - val_loss: 0.2612 - val_accuracy: 0.7010\n",
      "Epoch 916/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2607 - accuracy: 0.7006 - val_loss: 0.2612 - val_accuracy: 0.7010\n",
      "Epoch 917/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2606 - accuracy: 0.7006 - val_loss: 0.2611 - val_accuracy: 0.7010\n",
      "Epoch 918/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2606 - accuracy: 0.7007 - val_loss: 0.2611 - val_accuracy: 0.7011\n",
      "Epoch 919/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2606 - accuracy: 0.7007 - val_loss: 0.2611 - val_accuracy: 0.7011\n",
      "Epoch 920/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2606 - accuracy: 0.7007 - val_loss: 0.2611 - val_accuracy: 0.7011\n",
      "Epoch 921/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2606 - accuracy: 0.7007 - val_loss: 0.2611 - val_accuracy: 0.7011\n",
      "Epoch 922/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2606 - accuracy: 0.7007 - val_loss: 0.2611 - val_accuracy: 0.7012\n",
      "Epoch 923/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2605 - accuracy: 0.7007 - val_loss: 0.2611 - val_accuracy: 0.7012\n",
      "Epoch 924/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2605 - accuracy: 0.7007 - val_loss: 0.2610 - val_accuracy: 0.7012\n",
      "Epoch 925/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2605 - accuracy: 0.7008 - val_loss: 0.2610 - val_accuracy: 0.7012\n",
      "Epoch 926/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2605 - accuracy: 0.7008 - val_loss: 0.2610 - val_accuracy: 0.7011\n",
      "Epoch 927/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2605 - accuracy: 0.7009 - val_loss: 0.2610 - val_accuracy: 0.7013\n",
      "Epoch 928/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2605 - accuracy: 0.7009 - val_loss: 0.2610 - val_accuracy: 0.7012\n",
      "Epoch 929/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2604 - accuracy: 0.7009 - val_loss: 0.2610 - val_accuracy: 0.7013\n",
      "Epoch 930/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2604 - accuracy: 0.7010 - val_loss: 0.2610 - val_accuracy: 0.7014\n",
      "Epoch 931/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2604 - accuracy: 0.7010 - val_loss: 0.2610 - val_accuracy: 0.7014\n",
      "Epoch 932/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2604 - accuracy: 0.7010 - val_loss: 0.2609 - val_accuracy: 0.7014\n",
      "Epoch 933/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2604 - accuracy: 0.7010 - val_loss: 0.2609 - val_accuracy: 0.7014\n",
      "Epoch 934/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2604 - accuracy: 0.7010 - val_loss: 0.2609 - val_accuracy: 0.7014\n",
      "Epoch 935/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2603 - accuracy: 0.7011 - val_loss: 0.2609 - val_accuracy: 0.7014\n",
      "Epoch 936/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2603 - accuracy: 0.7011 - val_loss: 0.2609 - val_accuracy: 0.7015\n",
      "Epoch 937/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2603 - accuracy: 0.7011 - val_loss: 0.2609 - val_accuracy: 0.7015\n",
      "Epoch 938/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2603 - accuracy: 0.7011 - val_loss: 0.2609 - val_accuracy: 0.7015\n",
      "Epoch 939/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2603 - accuracy: 0.7011 - val_loss: 0.2608 - val_accuracy: 0.7015\n",
      "Epoch 940/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2603 - accuracy: 0.7011 - val_loss: 0.2608 - val_accuracy: 0.7015\n",
      "Epoch 941/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2602 - accuracy: 0.7011 - val_loss: 0.2608 - val_accuracy: 0.7016\n",
      "Epoch 942/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2602 - accuracy: 0.7012 - val_loss: 0.2608 - val_accuracy: 0.7016\n",
      "Epoch 943/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2602 - accuracy: 0.7012 - val_loss: 0.2608 - val_accuracy: 0.7016\n",
      "Epoch 944/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2602 - accuracy: 0.7012 - val_loss: 0.2608 - val_accuracy: 0.7016\n",
      "Epoch 945/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2602 - accuracy: 0.7012 - val_loss: 0.2608 - val_accuracy: 0.7016\n",
      "Epoch 946/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2602 - accuracy: 0.7012 - val_loss: 0.2607 - val_accuracy: 0.7016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 947/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2601 - accuracy: 0.7012 - val_loss: 0.2607 - val_accuracy: 0.7016\n",
      "Epoch 948/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2601 - accuracy: 0.7012 - val_loss: 0.2607 - val_accuracy: 0.7016\n",
      "Epoch 949/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2601 - accuracy: 0.7012 - val_loss: 0.2607 - val_accuracy: 0.7016\n",
      "Epoch 950/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2601 - accuracy: 0.7012 - val_loss: 0.2607 - val_accuracy: 0.7016\n",
      "Epoch 951/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2601 - accuracy: 0.7012 - val_loss: 0.2607 - val_accuracy: 0.7015\n",
      "Epoch 952/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2601 - accuracy: 0.7012 - val_loss: 0.2607 - val_accuracy: 0.7016\n",
      "Epoch 953/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2600 - accuracy: 0.7012 - val_loss: 0.2607 - val_accuracy: 0.7016\n",
      "Epoch 954/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2600 - accuracy: 0.7012 - val_loss: 0.2606 - val_accuracy: 0.7016\n",
      "Epoch 955/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2600 - accuracy: 0.7012 - val_loss: 0.2606 - val_accuracy: 0.7016\n",
      "Epoch 956/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2600 - accuracy: 0.7012 - val_loss: 0.2606 - val_accuracy: 0.7016\n",
      "Epoch 957/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2600 - accuracy: 0.7012 - val_loss: 0.2606 - val_accuracy: 0.7017\n",
      "Epoch 958/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2600 - accuracy: 0.7012 - val_loss: 0.2606 - val_accuracy: 0.7017\n",
      "Epoch 959/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2599 - accuracy: 0.7012 - val_loss: 0.2606 - val_accuracy: 0.7016\n",
      "Epoch 960/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2599 - accuracy: 0.7013 - val_loss: 0.2606 - val_accuracy: 0.7016\n",
      "Epoch 961/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2599 - accuracy: 0.7013 - val_loss: 0.2606 - val_accuracy: 0.7017\n",
      "Epoch 962/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2599 - accuracy: 0.7013 - val_loss: 0.2605 - val_accuracy: 0.7017\n",
      "Epoch 963/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2599 - accuracy: 0.7013 - val_loss: 0.2605 - val_accuracy: 0.7017\n",
      "Epoch 964/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2599 - accuracy: 0.7013 - val_loss: 0.2605 - val_accuracy: 0.7017\n",
      "Epoch 965/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2599 - accuracy: 0.7013 - val_loss: 0.2605 - val_accuracy: 0.7018\n",
      "Epoch 966/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2598 - accuracy: 0.7013 - val_loss: 0.2605 - val_accuracy: 0.7018\n",
      "Epoch 967/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2598 - accuracy: 0.7014 - val_loss: 0.2605 - val_accuracy: 0.7018\n",
      "Epoch 968/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2598 - accuracy: 0.7014 - val_loss: 0.2605 - val_accuracy: 0.7019\n",
      "Epoch 969/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2598 - accuracy: 0.7014 - val_loss: 0.2604 - val_accuracy: 0.7019\n",
      "Epoch 970/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2598 - accuracy: 0.7014 - val_loss: 0.2604 - val_accuracy: 0.7019\n",
      "Epoch 971/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2598 - accuracy: 0.7014 - val_loss: 0.2604 - val_accuracy: 0.7019\n",
      "Epoch 972/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2598 - accuracy: 0.7014 - val_loss: 0.2604 - val_accuracy: 0.7020\n",
      "Epoch 973/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2597 - accuracy: 0.7015 - val_loss: 0.2604 - val_accuracy: 0.7020\n",
      "Epoch 974/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2597 - accuracy: 0.7015 - val_loss: 0.2604 - val_accuracy: 0.7019\n",
      "Epoch 975/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2597 - accuracy: 0.7015 - val_loss: 0.2604 - val_accuracy: 0.7019\n",
      "Epoch 976/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2597 - accuracy: 0.7015 - val_loss: 0.2603 - val_accuracy: 0.7019\n",
      "Epoch 977/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2597 - accuracy: 0.7015 - val_loss: 0.2603 - val_accuracy: 0.7020\n",
      "Epoch 978/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2597 - accuracy: 0.7015 - val_loss: 0.2603 - val_accuracy: 0.7019\n",
      "Epoch 979/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2596 - accuracy: 0.7015 - val_loss: 0.2603 - val_accuracy: 0.7019\n",
      "Epoch 980/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2596 - accuracy: 0.7015 - val_loss: 0.2603 - val_accuracy: 0.7020\n",
      "Epoch 981/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2596 - accuracy: 0.7016 - val_loss: 0.2603 - val_accuracy: 0.7020\n",
      "Epoch 982/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2596 - accuracy: 0.7015 - val_loss: 0.2603 - val_accuracy: 0.7020\n",
      "Epoch 983/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2596 - accuracy: 0.7016 - val_loss: 0.2602 - val_accuracy: 0.7021\n",
      "Epoch 984/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2596 - accuracy: 0.7016 - val_loss: 0.2602 - val_accuracy: 0.7021\n",
      "Epoch 985/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2595 - accuracy: 0.7016 - val_loss: 0.2602 - val_accuracy: 0.7021\n",
      "Epoch 986/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2595 - accuracy: 0.7016 - val_loss: 0.2602 - val_accuracy: 0.7021\n",
      "Epoch 987/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2595 - accuracy: 0.7016 - val_loss: 0.2602 - val_accuracy: 0.7021\n",
      "Epoch 988/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2595 - accuracy: 0.7017 - val_loss: 0.2602 - val_accuracy: 0.7022\n",
      "Epoch 989/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2595 - accuracy: 0.7017 - val_loss: 0.2601 - val_accuracy: 0.7021\n",
      "Epoch 990/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2595 - accuracy: 0.7017 - val_loss: 0.2601 - val_accuracy: 0.7021\n",
      "Epoch 991/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2594 - accuracy: 0.7017 - val_loss: 0.2601 - val_accuracy: 0.7022\n",
      "Epoch 992/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2594 - accuracy: 0.7018 - val_loss: 0.2601 - val_accuracy: 0.7022\n",
      "Epoch 993/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2594 - accuracy: 0.7018 - val_loss: 0.2601 - val_accuracy: 0.7022\n",
      "Epoch 994/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2594 - accuracy: 0.7018 - val_loss: 0.2600 - val_accuracy: 0.7023\n",
      "Epoch 995/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2594 - accuracy: 0.7018 - val_loss: 0.2600 - val_accuracy: 0.7023\n",
      "Epoch 996/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2593 - accuracy: 0.7019 - val_loss: 0.2600 - val_accuracy: 0.7022\n",
      "Epoch 997/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2593 - accuracy: 0.7019 - val_loss: 0.2600 - val_accuracy: 0.7022\n",
      "Epoch 998/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2593 - accuracy: 0.7019 - val_loss: 0.2600 - val_accuracy: 0.7022\n",
      "Epoch 999/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2593 - accuracy: 0.7019 - val_loss: 0.2599 - val_accuracy: 0.7023\n",
      "Epoch 1000/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2593 - accuracy: 0.7018 - val_loss: 0.2599 - val_accuracy: 0.7023\n",
      "Epoch 1001/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2592 - accuracy: 0.7019 - val_loss: 0.2599 - val_accuracy: 0.7023\n",
      "Epoch 1002/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2592 - accuracy: 0.7019 - val_loss: 0.2599 - val_accuracy: 0.7024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1003/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2592 - accuracy: 0.7019 - val_loss: 0.2599 - val_accuracy: 0.7024\n",
      "Epoch 1004/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2592 - accuracy: 0.7019 - val_loss: 0.2598 - val_accuracy: 0.7025\n",
      "Epoch 1005/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2592 - accuracy: 0.7020 - val_loss: 0.2598 - val_accuracy: 0.7025\n",
      "Epoch 1006/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2591 - accuracy: 0.7019 - val_loss: 0.2598 - val_accuracy: 0.7026\n",
      "Epoch 1007/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2591 - accuracy: 0.7020 - val_loss: 0.2598 - val_accuracy: 0.7025\n",
      "Epoch 1008/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2591 - accuracy: 0.7020 - val_loss: 0.2597 - val_accuracy: 0.7026\n",
      "Epoch 1009/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2591 - accuracy: 0.7020 - val_loss: 0.2597 - val_accuracy: 0.7026\n",
      "Epoch 1010/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2591 - accuracy: 0.7020 - val_loss: 0.2597 - val_accuracy: 0.7026\n",
      "Epoch 1011/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2590 - accuracy: 0.7020 - val_loss: 0.2597 - val_accuracy: 0.7026\n",
      "Epoch 1012/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2590 - accuracy: 0.7020 - val_loss: 0.2597 - val_accuracy: 0.7026\n",
      "Epoch 1013/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2590 - accuracy: 0.7020 - val_loss: 0.2596 - val_accuracy: 0.7027\n",
      "Epoch 1014/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2590 - accuracy: 0.7020 - val_loss: 0.2596 - val_accuracy: 0.7027\n",
      "Epoch 1015/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2590 - accuracy: 0.7020 - val_loss: 0.2596 - val_accuracy: 0.7028\n",
      "Epoch 1016/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2590 - accuracy: 0.7020 - val_loss: 0.2596 - val_accuracy: 0.7028\n",
      "Epoch 1017/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2589 - accuracy: 0.7020 - val_loss: 0.2596 - val_accuracy: 0.7028\n",
      "Epoch 1018/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2589 - accuracy: 0.7020 - val_loss: 0.2596 - val_accuracy: 0.7028\n",
      "Epoch 1019/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2589 - accuracy: 0.7021 - val_loss: 0.2595 - val_accuracy: 0.7029\n",
      "Epoch 1020/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2589 - accuracy: 0.7021 - val_loss: 0.2595 - val_accuracy: 0.7029\n",
      "Epoch 1021/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2589 - accuracy: 0.7021 - val_loss: 0.2595 - val_accuracy: 0.7029\n",
      "Epoch 1022/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2589 - accuracy: 0.7021 - val_loss: 0.2595 - val_accuracy: 0.7030\n",
      "Epoch 1023/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2588 - accuracy: 0.7021 - val_loss: 0.2595 - val_accuracy: 0.7030\n",
      "Epoch 1024/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2588 - accuracy: 0.7021 - val_loss: 0.2594 - val_accuracy: 0.7030\n",
      "Epoch 1025/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2588 - accuracy: 0.7021 - val_loss: 0.2594 - val_accuracy: 0.7029\n",
      "Epoch 1026/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2588 - accuracy: 0.7021 - val_loss: 0.2594 - val_accuracy: 0.7029\n",
      "Epoch 1027/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2588 - accuracy: 0.7022 - val_loss: 0.2594 - val_accuracy: 0.7030\n",
      "Epoch 1028/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2587 - accuracy: 0.7023 - val_loss: 0.2594 - val_accuracy: 0.7030\n",
      "Epoch 1029/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2587 - accuracy: 0.7022 - val_loss: 0.2593 - val_accuracy: 0.7030\n",
      "Epoch 1030/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2587 - accuracy: 0.7022 - val_loss: 0.2593 - val_accuracy: 0.7031\n",
      "Epoch 1031/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2587 - accuracy: 0.7022 - val_loss: 0.2593 - val_accuracy: 0.7031\n",
      "Epoch 1032/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2587 - accuracy: 0.7023 - val_loss: 0.2593 - val_accuracy: 0.7031\n",
      "Epoch 1033/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2586 - accuracy: 0.7023 - val_loss: 0.2593 - val_accuracy: 0.7032\n",
      "Epoch 1034/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2586 - accuracy: 0.7024 - val_loss: 0.2593 - val_accuracy: 0.7032\n",
      "Epoch 1035/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2586 - accuracy: 0.7023 - val_loss: 0.2592 - val_accuracy: 0.7033\n",
      "Epoch 1036/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2586 - accuracy: 0.7024 - val_loss: 0.2592 - val_accuracy: 0.7033\n",
      "Epoch 1037/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2586 - accuracy: 0.7024 - val_loss: 0.2592 - val_accuracy: 0.7033\n",
      "Epoch 1038/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2585 - accuracy: 0.7024 - val_loss: 0.2592 - val_accuracy: 0.7033\n",
      "Epoch 1039/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2585 - accuracy: 0.7024 - val_loss: 0.2592 - val_accuracy: 0.7033\n",
      "Epoch 1040/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2585 - accuracy: 0.7024 - val_loss: 0.2592 - val_accuracy: 0.7033\n",
      "Epoch 1041/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2585 - accuracy: 0.7024 - val_loss: 0.2591 - val_accuracy: 0.7033\n",
      "Epoch 1042/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2585 - accuracy: 0.7025 - val_loss: 0.2591 - val_accuracy: 0.7034\n",
      "Epoch 1043/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2584 - accuracy: 0.7025 - val_loss: 0.2591 - val_accuracy: 0.7033\n",
      "Epoch 1044/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2584 - accuracy: 0.7026 - val_loss: 0.2591 - val_accuracy: 0.7032\n",
      "Epoch 1045/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2584 - accuracy: 0.7026 - val_loss: 0.2591 - val_accuracy: 0.7033\n",
      "Epoch 1046/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2584 - accuracy: 0.7026 - val_loss: 0.2590 - val_accuracy: 0.7032\n",
      "Epoch 1047/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2584 - accuracy: 0.7027 - val_loss: 0.2590 - val_accuracy: 0.7032\n",
      "Epoch 1048/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2583 - accuracy: 0.7027 - val_loss: 0.2590 - val_accuracy: 0.7032\n",
      "Epoch 1049/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2583 - accuracy: 0.7027 - val_loss: 0.2590 - val_accuracy: 0.7032\n",
      "Epoch 1050/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2583 - accuracy: 0.7027 - val_loss: 0.2590 - val_accuracy: 0.7033\n",
      "Epoch 1051/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2583 - accuracy: 0.7027 - val_loss: 0.2590 - val_accuracy: 0.7033\n",
      "Epoch 1052/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2583 - accuracy: 0.7027 - val_loss: 0.2590 - val_accuracy: 0.7032\n",
      "Epoch 1053/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2583 - accuracy: 0.7027 - val_loss: 0.2589 - val_accuracy: 0.7032\n",
      "Epoch 1054/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2582 - accuracy: 0.7028 - val_loss: 0.2589 - val_accuracy: 0.7032\n",
      "Epoch 1055/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2582 - accuracy: 0.7027 - val_loss: 0.2589 - val_accuracy: 0.7032\n",
      "Epoch 1056/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2582 - accuracy: 0.7027 - val_loss: 0.2589 - val_accuracy: 0.7033\n",
      "Epoch 1057/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2582 - accuracy: 0.7027 - val_loss: 0.2589 - val_accuracy: 0.7033\n",
      "Epoch 1058/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2582 - accuracy: 0.7027 - val_loss: 0.2589 - val_accuracy: 0.7034\n",
      "Epoch 1059/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2581 - accuracy: 0.7027 - val_loss: 0.2589 - val_accuracy: 0.7034\n",
      "Epoch 1060/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2581 - accuracy: 0.7027 - val_loss: 0.2588 - val_accuracy: 0.7034\n",
      "Epoch 1061/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2581 - accuracy: 0.7028 - val_loss: 0.2588 - val_accuracy: 0.7034\n",
      "Epoch 1062/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2581 - accuracy: 0.7029 - val_loss: 0.2588 - val_accuracy: 0.7034\n",
      "Epoch 1063/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2581 - accuracy: 0.7029 - val_loss: 0.2588 - val_accuracy: 0.7034\n",
      "Epoch 1064/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2581 - accuracy: 0.7029 - val_loss: 0.2588 - val_accuracy: 0.7034\n",
      "Epoch 1065/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2580 - accuracy: 0.7029 - val_loss: 0.2588 - val_accuracy: 0.7035\n",
      "Epoch 1066/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2580 - accuracy: 0.7029 - val_loss: 0.2588 - val_accuracy: 0.7035\n",
      "Epoch 1067/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2580 - accuracy: 0.7029 - val_loss: 0.2588 - val_accuracy: 0.7035\n",
      "Epoch 1068/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2580 - accuracy: 0.7029 - val_loss: 0.2588 - val_accuracy: 0.7035\n",
      "Epoch 1069/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2580 - accuracy: 0.7029 - val_loss: 0.2587 - val_accuracy: 0.7035\n",
      "Epoch 1070/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2580 - accuracy: 0.7029 - val_loss: 0.2587 - val_accuracy: 0.7035\n",
      "Epoch 1071/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2579 - accuracy: 0.7029 - val_loss: 0.2587 - val_accuracy: 0.7035\n",
      "Epoch 1072/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2579 - accuracy: 0.7030 - val_loss: 0.2587 - val_accuracy: 0.7035\n",
      "Epoch 1073/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2579 - accuracy: 0.7030 - val_loss: 0.2587 - val_accuracy: 0.7035\n",
      "Epoch 1074/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2579 - accuracy: 0.7030 - val_loss: 0.2587 - val_accuracy: 0.7035\n",
      "Epoch 1075/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2579 - accuracy: 0.7031 - val_loss: 0.2586 - val_accuracy: 0.7035\n",
      "Epoch 1076/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2578 - accuracy: 0.7031 - val_loss: 0.2586 - val_accuracy: 0.7035\n",
      "Epoch 1077/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2578 - accuracy: 0.7031 - val_loss: 0.2586 - val_accuracy: 0.7036\n",
      "Epoch 1078/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2578 - accuracy: 0.7031 - val_loss: 0.2586 - val_accuracy: 0.7037\n",
      "Epoch 1079/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2578 - accuracy: 0.7031 - val_loss: 0.2586 - val_accuracy: 0.7037\n",
      "Epoch 1080/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2578 - accuracy: 0.7031 - val_loss: 0.2586 - val_accuracy: 0.7037\n",
      "Epoch 1081/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2578 - accuracy: 0.7031 - val_loss: 0.2585 - val_accuracy: 0.7037\n",
      "Epoch 1082/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2577 - accuracy: 0.7032 - val_loss: 0.2585 - val_accuracy: 0.7037\n",
      "Epoch 1083/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2577 - accuracy: 0.7033 - val_loss: 0.2585 - val_accuracy: 0.7037\n",
      "Epoch 1084/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2577 - accuracy: 0.7033 - val_loss: 0.2585 - val_accuracy: 0.7038\n",
      "Epoch 1085/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2577 - accuracy: 0.7032 - val_loss: 0.2585 - val_accuracy: 0.7038\n",
      "Epoch 1086/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2577 - accuracy: 0.7032 - val_loss: 0.2584 - val_accuracy: 0.7038\n",
      "Epoch 1087/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2577 - accuracy: 0.7032 - val_loss: 0.2584 - val_accuracy: 0.7038\n",
      "Epoch 1088/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2576 - accuracy: 0.7033 - val_loss: 0.2584 - val_accuracy: 0.7039\n",
      "Epoch 1089/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2576 - accuracy: 0.7033 - val_loss: 0.2584 - val_accuracy: 0.7039\n",
      "Epoch 1090/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2576 - accuracy: 0.7033 - val_loss: 0.2584 - val_accuracy: 0.7039\n",
      "Epoch 1091/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2576 - accuracy: 0.7033 - val_loss: 0.2584 - val_accuracy: 0.7040\n",
      "Epoch 1092/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2576 - accuracy: 0.7033 - val_loss: 0.2583 - val_accuracy: 0.7040\n",
      "Epoch 1093/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2575 - accuracy: 0.7033 - val_loss: 0.2583 - val_accuracy: 0.7040\n",
      "Epoch 1094/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2575 - accuracy: 0.7033 - val_loss: 0.2583 - val_accuracy: 0.7041\n",
      "Epoch 1095/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2575 - accuracy: 0.7033 - val_loss: 0.2583 - val_accuracy: 0.7041\n",
      "Epoch 1096/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2575 - accuracy: 0.7033 - val_loss: 0.2583 - val_accuracy: 0.7041\n",
      "Epoch 1097/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2575 - accuracy: 0.7034 - val_loss: 0.2583 - val_accuracy: 0.7041\n",
      "Epoch 1098/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2575 - accuracy: 0.7034 - val_loss: 0.2583 - val_accuracy: 0.7041\n",
      "Epoch 1099/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2574 - accuracy: 0.7034 - val_loss: 0.2583 - val_accuracy: 0.7041\n",
      "Epoch 1100/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2574 - accuracy: 0.7034 - val_loss: 0.2582 - val_accuracy: 0.7041\n",
      "Epoch 1101/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2574 - accuracy: 0.7034 - val_loss: 0.2582 - val_accuracy: 0.7042\n",
      "Epoch 1102/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2574 - accuracy: 0.7035 - val_loss: 0.2582 - val_accuracy: 0.7041\n",
      "Epoch 1103/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2574 - accuracy: 0.7035 - val_loss: 0.2582 - val_accuracy: 0.7041\n",
      "Epoch 1104/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2574 - accuracy: 0.7035 - val_loss: 0.2582 - val_accuracy: 0.7041\n",
      "Epoch 1105/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2573 - accuracy: 0.7035 - val_loss: 0.2582 - val_accuracy: 0.7041\n",
      "Epoch 1106/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2573 - accuracy: 0.7035 - val_loss: 0.2581 - val_accuracy: 0.7041\n",
      "Epoch 1107/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2573 - accuracy: 0.7035 - val_loss: 0.2581 - val_accuracy: 0.7041\n",
      "Epoch 1108/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2573 - accuracy: 0.7035 - val_loss: 0.2581 - val_accuracy: 0.7041\n",
      "Epoch 1109/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2573 - accuracy: 0.7035 - val_loss: 0.2581 - val_accuracy: 0.7041\n",
      "Epoch 1110/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2573 - accuracy: 0.7036 - val_loss: 0.2581 - val_accuracy: 0.7041\n",
      "Epoch 1111/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2572 - accuracy: 0.7036 - val_loss: 0.2581 - val_accuracy: 0.7041\n",
      "Epoch 1112/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2572 - accuracy: 0.7036 - val_loss: 0.2581 - val_accuracy: 0.7042\n",
      "Epoch 1113/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2572 - accuracy: 0.7036 - val_loss: 0.2580 - val_accuracy: 0.7042\n",
      "Epoch 1114/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2572 - accuracy: 0.7037 - val_loss: 0.2580 - val_accuracy: 0.7042\n",
      "Epoch 1115/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2572 - accuracy: 0.7037 - val_loss: 0.2580 - val_accuracy: 0.7042\n",
      "Epoch 1116/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2572 - accuracy: 0.7037 - val_loss: 0.2580 - val_accuracy: 0.7043\n",
      "Epoch 1117/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2571 - accuracy: 0.7038 - val_loss: 0.2580 - val_accuracy: 0.7043\n",
      "Epoch 1118/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2571 - accuracy: 0.7039 - val_loss: 0.2580 - val_accuracy: 0.7043\n",
      "Epoch 1119/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2571 - accuracy: 0.7039 - val_loss: 0.2579 - val_accuracy: 0.7043\n",
      "Epoch 1120/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2571 - accuracy: 0.7038 - val_loss: 0.2579 - val_accuracy: 0.7043\n",
      "Epoch 1121/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2571 - accuracy: 0.7038 - val_loss: 0.2579 - val_accuracy: 0.7044\n",
      "Epoch 1122/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2571 - accuracy: 0.7038 - val_loss: 0.2579 - val_accuracy: 0.7044\n",
      "Epoch 1123/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2570 - accuracy: 0.7039 - val_loss: 0.2579 - val_accuracy: 0.7045\n",
      "Epoch 1124/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2570 - accuracy: 0.7039 - val_loss: 0.2579 - val_accuracy: 0.7045\n",
      "Epoch 1125/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2570 - accuracy: 0.7039 - val_loss: 0.2579 - val_accuracy: 0.7045\n",
      "Epoch 1126/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2570 - accuracy: 0.7039 - val_loss: 0.2578 - val_accuracy: 0.7045\n",
      "Epoch 1127/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2570 - accuracy: 0.7040 - val_loss: 0.2578 - val_accuracy: 0.7045\n",
      "Epoch 1128/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2570 - accuracy: 0.7040 - val_loss: 0.2578 - val_accuracy: 0.7045\n",
      "Epoch 1129/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2569 - accuracy: 0.7040 - val_loss: 0.2578 - val_accuracy: 0.7046\n",
      "Epoch 1130/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2569 - accuracy: 0.7041 - val_loss: 0.2578 - val_accuracy: 0.7046\n",
      "Epoch 1131/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2569 - accuracy: 0.7041 - val_loss: 0.2578 - val_accuracy: 0.7046\n",
      "Epoch 1132/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2569 - accuracy: 0.7041 - val_loss: 0.2577 - val_accuracy: 0.7046\n",
      "Epoch 1133/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2569 - accuracy: 0.7041 - val_loss: 0.2577 - val_accuracy: 0.7046\n",
      "Epoch 1134/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2569 - accuracy: 0.7041 - val_loss: 0.2577 - val_accuracy: 0.7046\n",
      "Epoch 1135/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2569 - accuracy: 0.7041 - val_loss: 0.2577 - val_accuracy: 0.7046\n",
      "Epoch 1136/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2568 - accuracy: 0.7041 - val_loss: 0.2577 - val_accuracy: 0.7047\n",
      "Epoch 1137/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2568 - accuracy: 0.7041 - val_loss: 0.2576 - val_accuracy: 0.7047\n",
      "Epoch 1138/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2568 - accuracy: 0.7041 - val_loss: 0.2576 - val_accuracy: 0.7047\n",
      "Epoch 1139/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2568 - accuracy: 0.7042 - val_loss: 0.2576 - val_accuracy: 0.7048\n",
      "Epoch 1140/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2568 - accuracy: 0.7042 - val_loss: 0.2576 - val_accuracy: 0.7048\n",
      "Epoch 1141/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2568 - accuracy: 0.7042 - val_loss: 0.2576 - val_accuracy: 0.7048\n",
      "Epoch 1142/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2568 - accuracy: 0.7043 - val_loss: 0.2576 - val_accuracy: 0.7049\n",
      "Epoch 1143/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2567 - accuracy: 0.7043 - val_loss: 0.2575 - val_accuracy: 0.7048\n",
      "Epoch 1144/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2567 - accuracy: 0.7043 - val_loss: 0.2575 - val_accuracy: 0.7048\n",
      "Epoch 1145/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2567 - accuracy: 0.7043 - val_loss: 0.2575 - val_accuracy: 0.7048\n",
      "Epoch 1146/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2567 - accuracy: 0.7044 - val_loss: 0.2575 - val_accuracy: 0.7049\n",
      "Epoch 1147/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2567 - accuracy: 0.7044 - val_loss: 0.2575 - val_accuracy: 0.7049\n",
      "Epoch 1148/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2567 - accuracy: 0.7045 - val_loss: 0.2575 - val_accuracy: 0.7049\n",
      "Epoch 1149/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2567 - accuracy: 0.7045 - val_loss: 0.2575 - val_accuracy: 0.7049\n",
      "Epoch 1150/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2566 - accuracy: 0.7045 - val_loss: 0.2574 - val_accuracy: 0.7050\n",
      "Epoch 1151/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2566 - accuracy: 0.7045 - val_loss: 0.2574 - val_accuracy: 0.7050\n",
      "Epoch 1152/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2566 - accuracy: 0.7046 - val_loss: 0.2574 - val_accuracy: 0.7050\n",
      "Epoch 1153/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2566 - accuracy: 0.7046 - val_loss: 0.2574 - val_accuracy: 0.7050\n",
      "Epoch 1154/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2566 - accuracy: 0.7046 - val_loss: 0.2574 - val_accuracy: 0.7051\n",
      "Epoch 1155/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2566 - accuracy: 0.7046 - val_loss: 0.2574 - val_accuracy: 0.7051\n",
      "Epoch 1156/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2566 - accuracy: 0.7046 - val_loss: 0.2573 - val_accuracy: 0.7051\n",
      "Epoch 1157/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2565 - accuracy: 0.7046 - val_loss: 0.2573 - val_accuracy: 0.7051\n",
      "Epoch 1158/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2565 - accuracy: 0.7046 - val_loss: 0.2573 - val_accuracy: 0.7051\n",
      "Epoch 1159/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2565 - accuracy: 0.7046 - val_loss: 0.2573 - val_accuracy: 0.7051\n",
      "Epoch 1160/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2565 - accuracy: 0.7046 - val_loss: 0.2573 - val_accuracy: 0.7051\n",
      "Epoch 1161/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2565 - accuracy: 0.7046 - val_loss: 0.2573 - val_accuracy: 0.7052\n",
      "Epoch 1162/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2565 - accuracy: 0.7046 - val_loss: 0.2572 - val_accuracy: 0.7052\n",
      "Epoch 1163/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2564 - accuracy: 0.7046 - val_loss: 0.2572 - val_accuracy: 0.7052\n",
      "Epoch 1164/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2564 - accuracy: 0.7046 - val_loss: 0.2572 - val_accuracy: 0.7052\n",
      "Epoch 1165/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2564 - accuracy: 0.7047 - val_loss: 0.2572 - val_accuracy: 0.7053\n",
      "Epoch 1166/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2564 - accuracy: 0.7047 - val_loss: 0.2572 - val_accuracy: 0.7052\n",
      "Epoch 1167/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2564 - accuracy: 0.7047 - val_loss: 0.2572 - val_accuracy: 0.7053\n",
      "Epoch 1168/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2564 - accuracy: 0.7047 - val_loss: 0.2571 - val_accuracy: 0.7053\n",
      "Epoch 1169/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2564 - accuracy: 0.7047 - val_loss: 0.2571 - val_accuracy: 0.7053\n",
      "Epoch 1170/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2563 - accuracy: 0.7047 - val_loss: 0.2571 - val_accuracy: 0.7053\n",
      "Epoch 1171/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2563 - accuracy: 0.7047 - val_loss: 0.2571 - val_accuracy: 0.7053\n",
      "Epoch 1172/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2563 - accuracy: 0.7048 - val_loss: 0.2571 - val_accuracy: 0.7053\n",
      "Epoch 1173/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2563 - accuracy: 0.7048 - val_loss: 0.2571 - val_accuracy: 0.7052\n",
      "Epoch 1174/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2563 - accuracy: 0.7047 - val_loss: 0.2570 - val_accuracy: 0.7053\n",
      "Epoch 1175/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2563 - accuracy: 0.7047 - val_loss: 0.2570 - val_accuracy: 0.7054\n",
      "Epoch 1176/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2562 - accuracy: 0.7047 - val_loss: 0.2570 - val_accuracy: 0.7054\n",
      "Epoch 1177/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2562 - accuracy: 0.7047 - val_loss: 0.2569 - val_accuracy: 0.7054\n",
      "Epoch 1178/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2562 - accuracy: 0.7048 - val_loss: 0.2569 - val_accuracy: 0.7055\n",
      "Epoch 1179/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2561 - accuracy: 0.7047 - val_loss: 0.2568 - val_accuracy: 0.7055\n",
      "Epoch 1180/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2561 - accuracy: 0.7048 - val_loss: 0.2568 - val_accuracy: 0.7056\n",
      "Epoch 1181/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2560 - accuracy: 0.7047 - val_loss: 0.2567 - val_accuracy: 0.7056\n",
      "Epoch 1182/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2559 - accuracy: 0.7048 - val_loss: 0.2566 - val_accuracy: 0.7055\n",
      "Epoch 1183/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2556 - accuracy: 0.7051 - val_loss: 0.2558 - val_accuracy: 0.7063\n",
      "Epoch 1184/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2551 - accuracy: 0.7060 - val_loss: 0.2554 - val_accuracy: 0.7065\n",
      "Epoch 1185/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2550 - accuracy: 0.7062 - val_loss: 0.2553 - val_accuracy: 0.7065\n",
      "Epoch 1186/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2550 - accuracy: 0.7062 - val_loss: 0.2553 - val_accuracy: 0.7065\n",
      "Epoch 1187/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2550 - accuracy: 0.7062 - val_loss: 0.2553 - val_accuracy: 0.7066\n",
      "Epoch 1188/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2550 - accuracy: 0.7062 - val_loss: 0.2553 - val_accuracy: 0.7067\n",
      "Epoch 1189/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2550 - accuracy: 0.7062 - val_loss: 0.2553 - val_accuracy: 0.7067\n",
      "Epoch 1190/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2550 - accuracy: 0.7062 - val_loss: 0.2552 - val_accuracy: 0.7067\n",
      "Epoch 1191/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2549 - accuracy: 0.7063 - val_loss: 0.2552 - val_accuracy: 0.7068\n",
      "Epoch 1192/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2549 - accuracy: 0.7063 - val_loss: 0.2552 - val_accuracy: 0.7067\n",
      "Epoch 1193/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2549 - accuracy: 0.7064 - val_loss: 0.2552 - val_accuracy: 0.7068\n",
      "Epoch 1194/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2549 - accuracy: 0.7063 - val_loss: 0.2552 - val_accuracy: 0.7068\n",
      "Epoch 1195/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2549 - accuracy: 0.7064 - val_loss: 0.2552 - val_accuracy: 0.7068\n",
      "Epoch 1196/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2549 - accuracy: 0.7063 - val_loss: 0.2552 - val_accuracy: 0.7068\n",
      "Epoch 1197/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2549 - accuracy: 0.7064 - val_loss: 0.2551 - val_accuracy: 0.7068\n",
      "Epoch 1198/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2548 - accuracy: 0.7064 - val_loss: 0.2551 - val_accuracy: 0.7068\n",
      "Epoch 1199/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2548 - accuracy: 0.7065 - val_loss: 0.2551 - val_accuracy: 0.7069\n",
      "Epoch 1200/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2548 - accuracy: 0.7064 - val_loss: 0.2551 - val_accuracy: 0.7069\n",
      "Epoch 1201/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2548 - accuracy: 0.7065 - val_loss: 0.2551 - val_accuracy: 0.7069\n",
      "Epoch 1202/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2548 - accuracy: 0.7065 - val_loss: 0.2551 - val_accuracy: 0.7068\n",
      "Epoch 1203/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2548 - accuracy: 0.7065 - val_loss: 0.2550 - val_accuracy: 0.7068\n",
      "Epoch 1204/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2547 - accuracy: 0.7065 - val_loss: 0.2550 - val_accuracy: 0.7067\n",
      "Epoch 1205/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2547 - accuracy: 0.7065 - val_loss: 0.2550 - val_accuracy: 0.7067\n",
      "Epoch 1206/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2547 - accuracy: 0.7066 - val_loss: 0.2550 - val_accuracy: 0.7067\n",
      "Epoch 1207/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2547 - accuracy: 0.7066 - val_loss: 0.2550 - val_accuracy: 0.7067\n",
      "Epoch 1208/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2547 - accuracy: 0.7066 - val_loss: 0.2550 - val_accuracy: 0.7066\n",
      "Epoch 1209/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2547 - accuracy: 0.7066 - val_loss: 0.2550 - val_accuracy: 0.7067\n",
      "Epoch 1210/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2547 - accuracy: 0.7066 - val_loss: 0.2549 - val_accuracy: 0.7067\n",
      "Epoch 1211/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2546 - accuracy: 0.7066 - val_loss: 0.2549 - val_accuracy: 0.7067\n",
      "Epoch 1212/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2546 - accuracy: 0.7066 - val_loss: 0.2549 - val_accuracy: 0.7068\n",
      "Epoch 1213/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2546 - accuracy: 0.7066 - val_loss: 0.2549 - val_accuracy: 0.7067\n",
      "Epoch 1214/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2546 - accuracy: 0.7066 - val_loss: 0.2549 - val_accuracy: 0.7068\n",
      "Epoch 1215/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2546 - accuracy: 0.7067 - val_loss: 0.2549 - val_accuracy: 0.7068\n",
      "Epoch 1216/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2546 - accuracy: 0.7066 - val_loss: 0.2548 - val_accuracy: 0.7069\n",
      "Epoch 1217/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2546 - accuracy: 0.7066 - val_loss: 0.2548 - val_accuracy: 0.7069\n",
      "Epoch 1218/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2545 - accuracy: 0.7067 - val_loss: 0.2548 - val_accuracy: 0.7069\n",
      "Epoch 1219/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2545 - accuracy: 0.7067 - val_loss: 0.2548 - val_accuracy: 0.7069\n",
      "Epoch 1220/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2545 - accuracy: 0.7067 - val_loss: 0.2548 - val_accuracy: 0.7069\n",
      "Epoch 1221/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2545 - accuracy: 0.7067 - val_loss: 0.2548 - val_accuracy: 0.7070\n",
      "Epoch 1222/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2545 - accuracy: 0.7068 - val_loss: 0.2548 - val_accuracy: 0.7069\n",
      "Epoch 1223/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2545 - accuracy: 0.7068 - val_loss: 0.2547 - val_accuracy: 0.7070\n",
      "Epoch 1224/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2545 - accuracy: 0.7068 - val_loss: 0.2547 - val_accuracy: 0.7070\n",
      "Epoch 1225/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2544 - accuracy: 0.7068 - val_loss: 0.2547 - val_accuracy: 0.7070\n",
      "Epoch 1226/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2544 - accuracy: 0.7068 - val_loss: 0.2547 - val_accuracy: 0.7071\n",
      "Epoch 1227/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2544 - accuracy: 0.7068 - val_loss: 0.2547 - val_accuracy: 0.7071\n",
      "Epoch 1228/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2544 - accuracy: 0.7068 - val_loss: 0.2547 - val_accuracy: 0.7071\n",
      "Epoch 1229/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2544 - accuracy: 0.7068 - val_loss: 0.2547 - val_accuracy: 0.7071\n",
      "Epoch 1230/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2544 - accuracy: 0.7068 - val_loss: 0.2546 - val_accuracy: 0.7071\n",
      "Epoch 1231/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2544 - accuracy: 0.7068 - val_loss: 0.2546 - val_accuracy: 0.7072\n",
      "Epoch 1232/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2543 - accuracy: 0.7069 - val_loss: 0.2546 - val_accuracy: 0.7072\n",
      "Epoch 1233/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2543 - accuracy: 0.7069 - val_loss: 0.2546 - val_accuracy: 0.7073\n",
      "Epoch 1234/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2543 - accuracy: 0.7069 - val_loss: 0.2546 - val_accuracy: 0.7072\n",
      "Epoch 1235/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2543 - accuracy: 0.7069 - val_loss: 0.2546 - val_accuracy: 0.7073\n",
      "Epoch 1236/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2543 - accuracy: 0.7070 - val_loss: 0.2546 - val_accuracy: 0.7073\n",
      "Epoch 1237/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2543 - accuracy: 0.7070 - val_loss: 0.2545 - val_accuracy: 0.7073\n",
      "Epoch 1238/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2543 - accuracy: 0.7069 - val_loss: 0.2545 - val_accuracy: 0.7073\n",
      "Epoch 1239/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2543 - accuracy: 0.7070 - val_loss: 0.2545 - val_accuracy: 0.7073\n",
      "Epoch 1240/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2542 - accuracy: 0.7070 - val_loss: 0.2545 - val_accuracy: 0.7073\n",
      "Epoch 1241/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2542 - accuracy: 0.7070 - val_loss: 0.2545 - val_accuracy: 0.7073\n",
      "Epoch 1242/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2542 - accuracy: 0.7070 - val_loss: 0.2545 - val_accuracy: 0.7073\n",
      "Epoch 1243/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2542 - accuracy: 0.7070 - val_loss: 0.2545 - val_accuracy: 0.7073\n",
      "Epoch 1244/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2542 - accuracy: 0.7070 - val_loss: 0.2545 - val_accuracy: 0.7073\n",
      "Epoch 1245/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2542 - accuracy: 0.7070 - val_loss: 0.2544 - val_accuracy: 0.7073\n",
      "Epoch 1246/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2542 - accuracy: 0.7070 - val_loss: 0.2544 - val_accuracy: 0.7073\n",
      "Epoch 1247/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2541 - accuracy: 0.7071 - val_loss: 0.2544 - val_accuracy: 0.7073\n",
      "Epoch 1248/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2541 - accuracy: 0.7071 - val_loss: 0.2544 - val_accuracy: 0.7074\n",
      "Epoch 1249/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2541 - accuracy: 0.7071 - val_loss: 0.2544 - val_accuracy: 0.7074\n",
      "Epoch 1250/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2541 - accuracy: 0.7071 - val_loss: 0.2544 - val_accuracy: 0.7074\n",
      "Epoch 1251/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2541 - accuracy: 0.7071 - val_loss: 0.2544 - val_accuracy: 0.7074\n",
      "Epoch 1252/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2541 - accuracy: 0.7071 - val_loss: 0.2543 - val_accuracy: 0.7075\n",
      "Epoch 1253/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2541 - accuracy: 0.7072 - val_loss: 0.2543 - val_accuracy: 0.7075\n",
      "Epoch 1254/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2540 - accuracy: 0.7072 - val_loss: 0.2543 - val_accuracy: 0.7075\n",
      "Epoch 1255/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2540 - accuracy: 0.7072 - val_loss: 0.2543 - val_accuracy: 0.7075\n",
      "Epoch 1256/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2540 - accuracy: 0.7072 - val_loss: 0.2543 - val_accuracy: 0.7075\n",
      "Epoch 1257/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2540 - accuracy: 0.7073 - val_loss: 0.2543 - val_accuracy: 0.7075\n",
      "Epoch 1258/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2540 - accuracy: 0.7072 - val_loss: 0.2543 - val_accuracy: 0.7076\n",
      "Epoch 1259/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2540 - accuracy: 0.7072 - val_loss: 0.2542 - val_accuracy: 0.7076\n",
      "Epoch 1260/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2540 - accuracy: 0.7073 - val_loss: 0.2542 - val_accuracy: 0.7076\n",
      "Epoch 1261/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2540 - accuracy: 0.7072 - val_loss: 0.2542 - val_accuracy: 0.7076\n",
      "Epoch 1262/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2539 - accuracy: 0.7072 - val_loss: 0.2542 - val_accuracy: 0.7076\n",
      "Epoch 1263/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2539 - accuracy: 0.7073 - val_loss: 0.2542 - val_accuracy: 0.7076\n",
      "Epoch 1264/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2539 - accuracy: 0.7073 - val_loss: 0.2542 - val_accuracy: 0.7076\n",
      "Epoch 1265/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2539 - accuracy: 0.7073 - val_loss: 0.2542 - val_accuracy: 0.7076\n",
      "Epoch 1266/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2539 - accuracy: 0.7073 - val_loss: 0.2541 - val_accuracy: 0.7077\n",
      "Epoch 1267/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2539 - accuracy: 0.7073 - val_loss: 0.2541 - val_accuracy: 0.7077\n",
      "Epoch 1268/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2539 - accuracy: 0.7073 - val_loss: 0.2541 - val_accuracy: 0.7077\n",
      "Epoch 1269/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2538 - accuracy: 0.7073 - val_loss: 0.2541 - val_accuracy: 0.7077\n",
      "Epoch 1270/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2538 - accuracy: 0.7073 - val_loss: 0.2541 - val_accuracy: 0.7077\n",
      "Epoch 1271/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2538 - accuracy: 0.7073 - val_loss: 0.2541 - val_accuracy: 0.7077\n",
      "Epoch 1272/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2538 - accuracy: 0.7073 - val_loss: 0.2541 - val_accuracy: 0.7077\n",
      "Epoch 1273/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2538 - accuracy: 0.7074 - val_loss: 0.2541 - val_accuracy: 0.7078\n",
      "Epoch 1274/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2538 - accuracy: 0.7074 - val_loss: 0.2540 - val_accuracy: 0.7078\n",
      "Epoch 1275/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2538 - accuracy: 0.7074 - val_loss: 0.2540 - val_accuracy: 0.7077\n",
      "Epoch 1276/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2538 - accuracy: 0.7075 - val_loss: 0.2540 - val_accuracy: 0.7077\n",
      "Epoch 1277/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2537 - accuracy: 0.7075 - val_loss: 0.2540 - val_accuracy: 0.7078\n",
      "Epoch 1278/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2537 - accuracy: 0.7075 - val_loss: 0.2540 - val_accuracy: 0.7078\n",
      "Epoch 1279/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2537 - accuracy: 0.7075 - val_loss: 0.2540 - val_accuracy: 0.7078\n",
      "Epoch 1280/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2537 - accuracy: 0.7075 - val_loss: 0.2540 - val_accuracy: 0.7078\n",
      "Epoch 1281/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2537 - accuracy: 0.7075 - val_loss: 0.2540 - val_accuracy: 0.7077\n",
      "Epoch 1282/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2537 - accuracy: 0.7075 - val_loss: 0.2539 - val_accuracy: 0.7078\n",
      "Epoch 1283/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2537 - accuracy: 0.7075 - val_loss: 0.2539 - val_accuracy: 0.7078\n",
      "Epoch 1284/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2536 - accuracy: 0.7076 - val_loss: 0.2539 - val_accuracy: 0.7078\n",
      "Epoch 1285/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2536 - accuracy: 0.7076 - val_loss: 0.2539 - val_accuracy: 0.7078\n",
      "Epoch 1286/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2536 - accuracy: 0.7076 - val_loss: 0.2539 - val_accuracy: 0.7078\n",
      "Epoch 1287/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2536 - accuracy: 0.7076 - val_loss: 0.2539 - val_accuracy: 0.7078\n",
      "Epoch 1288/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2536 - accuracy: 0.7076 - val_loss: 0.2539 - val_accuracy: 0.7079\n",
      "Epoch 1289/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2536 - accuracy: 0.7076 - val_loss: 0.2539 - val_accuracy: 0.7079\n",
      "Epoch 1290/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2536 - accuracy: 0.7076 - val_loss: 0.2538 - val_accuracy: 0.7079\n",
      "Epoch 1291/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2536 - accuracy: 0.7077 - val_loss: 0.2538 - val_accuracy: 0.7079\n",
      "Epoch 1292/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2536 - accuracy: 0.7077 - val_loss: 0.2538 - val_accuracy: 0.7079\n",
      "Epoch 1293/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2535 - accuracy: 0.7077 - val_loss: 0.2538 - val_accuracy: 0.7079\n",
      "Epoch 1294/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2535 - accuracy: 0.7077 - val_loss: 0.2538 - val_accuracy: 0.7079\n",
      "Epoch 1295/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2535 - accuracy: 0.7077 - val_loss: 0.2538 - val_accuracy: 0.7080\n",
      "Epoch 1296/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2535 - accuracy: 0.7077 - val_loss: 0.2538 - val_accuracy: 0.7080\n",
      "Epoch 1297/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2535 - accuracy: 0.7077 - val_loss: 0.2538 - val_accuracy: 0.7080\n",
      "Epoch 1298/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2535 - accuracy: 0.7077 - val_loss: 0.2537 - val_accuracy: 0.7080\n",
      "Epoch 1299/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2535 - accuracy: 0.7078 - val_loss: 0.2537 - val_accuracy: 0.7080\n",
      "Epoch 1300/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2535 - accuracy: 0.7078 - val_loss: 0.2537 - val_accuracy: 0.7081\n",
      "Epoch 1301/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2534 - accuracy: 0.7078 - val_loss: 0.2537 - val_accuracy: 0.7081\n",
      "Epoch 1302/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2534 - accuracy: 0.7078 - val_loss: 0.2537 - val_accuracy: 0.7081\n",
      "Epoch 1303/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2534 - accuracy: 0.7078 - val_loss: 0.2537 - val_accuracy: 0.7081\n",
      "Epoch 1304/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2534 - accuracy: 0.7078 - val_loss: 0.2537 - val_accuracy: 0.7081\n",
      "Epoch 1305/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2534 - accuracy: 0.7078 - val_loss: 0.2537 - val_accuracy: 0.7082\n",
      "Epoch 1306/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2534 - accuracy: 0.7078 - val_loss: 0.2536 - val_accuracy: 0.7081\n",
      "Epoch 1307/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2534 - accuracy: 0.7078 - val_loss: 0.2536 - val_accuracy: 0.7082\n",
      "Epoch 1308/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2534 - accuracy: 0.7078 - val_loss: 0.2536 - val_accuracy: 0.7082\n",
      "Epoch 1309/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2534 - accuracy: 0.7078 - val_loss: 0.2536 - val_accuracy: 0.7082\n",
      "Epoch 1310/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2533 - accuracy: 0.7078 - val_loss: 0.2536 - val_accuracy: 0.7082\n",
      "Epoch 1311/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2533 - accuracy: 0.7079 - val_loss: 0.2536 - val_accuracy: 0.7082\n",
      "Epoch 1312/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2533 - accuracy: 0.7079 - val_loss: 0.2536 - val_accuracy: 0.7082\n",
      "Epoch 1313/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2533 - accuracy: 0.7079 - val_loss: 0.2536 - val_accuracy: 0.7082\n",
      "Epoch 1314/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2533 - accuracy: 0.7079 - val_loss: 0.2535 - val_accuracy: 0.7083\n",
      "Epoch 1315/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2533 - accuracy: 0.7079 - val_loss: 0.2535 - val_accuracy: 0.7083\n",
      "Epoch 1316/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2533 - accuracy: 0.7080 - val_loss: 0.2535 - val_accuracy: 0.7083\n",
      "Epoch 1317/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2533 - accuracy: 0.7080 - val_loss: 0.2535 - val_accuracy: 0.7083\n",
      "Epoch 1318/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2532 - accuracy: 0.7081 - val_loss: 0.2535 - val_accuracy: 0.7083\n",
      "Epoch 1319/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2532 - accuracy: 0.7081 - val_loss: 0.2535 - val_accuracy: 0.7083\n",
      "Epoch 1320/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2532 - accuracy: 0.7081 - val_loss: 0.2535 - val_accuracy: 0.7083\n",
      "Epoch 1321/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2532 - accuracy: 0.7081 - val_loss: 0.2535 - val_accuracy: 0.7083\n",
      "Epoch 1322/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2532 - accuracy: 0.7082 - val_loss: 0.2534 - val_accuracy: 0.7082\n",
      "Epoch 1323/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2532 - accuracy: 0.7082 - val_loss: 0.2534 - val_accuracy: 0.7083\n",
      "Epoch 1324/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2532 - accuracy: 0.7082 - val_loss: 0.2534 - val_accuracy: 0.7083\n",
      "Epoch 1325/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2532 - accuracy: 0.7082 - val_loss: 0.2534 - val_accuracy: 0.7083\n",
      "Epoch 1326/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2532 - accuracy: 0.7082 - val_loss: 0.2534 - val_accuracy: 0.7083\n",
      "Epoch 1327/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2531 - accuracy: 0.7082 - val_loss: 0.2534 - val_accuracy: 0.7084\n",
      "Epoch 1328/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2531 - accuracy: 0.7083 - val_loss: 0.2534 - val_accuracy: 0.7084\n",
      "Epoch 1329/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2531 - accuracy: 0.7083 - val_loss: 0.2534 - val_accuracy: 0.7084\n",
      "Epoch 1330/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2531 - accuracy: 0.7083 - val_loss: 0.2534 - val_accuracy: 0.7084\n",
      "Epoch 1331/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2531 - accuracy: 0.7083 - val_loss: 0.2533 - val_accuracy: 0.7084\n",
      "Epoch 1332/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2531 - accuracy: 0.7083 - val_loss: 0.2533 - val_accuracy: 0.7084\n",
      "Epoch 1333/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2531 - accuracy: 0.7084 - val_loss: 0.2533 - val_accuracy: 0.7084\n",
      "Epoch 1334/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2531 - accuracy: 0.7084 - val_loss: 0.2533 - val_accuracy: 0.7084\n",
      "Epoch 1335/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2531 - accuracy: 0.7084 - val_loss: 0.2533 - val_accuracy: 0.7085\n",
      "Epoch 1336/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2530 - accuracy: 0.7084 - val_loss: 0.2533 - val_accuracy: 0.7084\n",
      "Epoch 1337/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2530 - accuracy: 0.7084 - val_loss: 0.2533 - val_accuracy: 0.7085\n",
      "Epoch 1338/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2530 - accuracy: 0.7084 - val_loss: 0.2533 - val_accuracy: 0.7085\n",
      "Epoch 1339/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2530 - accuracy: 0.7084 - val_loss: 0.2532 - val_accuracy: 0.7085\n",
      "Epoch 1340/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2530 - accuracy: 0.7085 - val_loss: 0.2532 - val_accuracy: 0.7085\n",
      "Epoch 1341/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2530 - accuracy: 0.7085 - val_loss: 0.2532 - val_accuracy: 0.7085\n",
      "Epoch 1342/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2530 - accuracy: 0.7085 - val_loss: 0.2532 - val_accuracy: 0.7085\n",
      "Epoch 1343/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2530 - accuracy: 0.7085 - val_loss: 0.2532 - val_accuracy: 0.7085\n",
      "Epoch 1344/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2530 - accuracy: 0.7085 - val_loss: 0.2532 - val_accuracy: 0.7085\n",
      "Epoch 1345/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2529 - accuracy: 0.7085 - val_loss: 0.2532 - val_accuracy: 0.7086\n",
      "Epoch 1346/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2529 - accuracy: 0.7085 - val_loss: 0.2532 - val_accuracy: 0.7086\n",
      "Epoch 1347/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2529 - accuracy: 0.7086 - val_loss: 0.2531 - val_accuracy: 0.7086\n",
      "Epoch 1348/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2529 - accuracy: 0.7086 - val_loss: 0.2531 - val_accuracy: 0.7086\n",
      "Epoch 1349/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2529 - accuracy: 0.7086 - val_loss: 0.2531 - val_accuracy: 0.7086\n",
      "Epoch 1350/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2529 - accuracy: 0.7086 - val_loss: 0.2531 - val_accuracy: 0.7086\n",
      "Epoch 1351/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2529 - accuracy: 0.7086 - val_loss: 0.2531 - val_accuracy: 0.7086\n",
      "Epoch 1352/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2529 - accuracy: 0.7086 - val_loss: 0.2531 - val_accuracy: 0.7086\n",
      "Epoch 1353/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2529 - accuracy: 0.7086 - val_loss: 0.2531 - val_accuracy: 0.7087\n",
      "Epoch 1354/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2528 - accuracy: 0.7086 - val_loss: 0.2531 - val_accuracy: 0.7087\n",
      "Epoch 1355/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2528 - accuracy: 0.7086 - val_loss: 0.2531 - val_accuracy: 0.7087\n",
      "Epoch 1356/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2528 - accuracy: 0.7086 - val_loss: 0.2530 - val_accuracy: 0.7087\n",
      "Epoch 1357/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2528 - accuracy: 0.7086 - val_loss: 0.2530 - val_accuracy: 0.7087\n",
      "Epoch 1358/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2528 - accuracy: 0.7086 - val_loss: 0.2530 - val_accuracy: 0.7088\n",
      "Epoch 1359/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2528 - accuracy: 0.7086 - val_loss: 0.2530 - val_accuracy: 0.7088\n",
      "Epoch 1360/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2528 - accuracy: 0.7086 - val_loss: 0.2530 - val_accuracy: 0.7088\n",
      "Epoch 1361/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2528 - accuracy: 0.7087 - val_loss: 0.2530 - val_accuracy: 0.7088\n",
      "Epoch 1362/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2528 - accuracy: 0.7087 - val_loss: 0.2530 - val_accuracy: 0.7088\n",
      "Epoch 1363/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2527 - accuracy: 0.7087 - val_loss: 0.2530 - val_accuracy: 0.7089\n",
      "Epoch 1364/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2527 - accuracy: 0.7087 - val_loss: 0.2530 - val_accuracy: 0.7088\n",
      "Epoch 1365/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2527 - accuracy: 0.7087 - val_loss: 0.2529 - val_accuracy: 0.7088\n",
      "Epoch 1366/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2527 - accuracy: 0.7087 - val_loss: 0.2529 - val_accuracy: 0.7089\n",
      "Epoch 1367/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2527 - accuracy: 0.7088 - val_loss: 0.2529 - val_accuracy: 0.7089\n",
      "Epoch 1368/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2527 - accuracy: 0.7088 - val_loss: 0.2529 - val_accuracy: 0.7089\n",
      "Epoch 1369/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2527 - accuracy: 0.7088 - val_loss: 0.2529 - val_accuracy: 0.7089\n",
      "Epoch 1370/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2527 - accuracy: 0.7088 - val_loss: 0.2529 - val_accuracy: 0.7089\n",
      "Epoch 1371/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2527 - accuracy: 0.7088 - val_loss: 0.2529 - val_accuracy: 0.7089\n",
      "Epoch 1372/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2526 - accuracy: 0.7088 - val_loss: 0.2529 - val_accuracy: 0.7089\n",
      "Epoch 1373/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2526 - accuracy: 0.7088 - val_loss: 0.2528 - val_accuracy: 0.7090\n",
      "Epoch 1374/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2526 - accuracy: 0.7088 - val_loss: 0.2528 - val_accuracy: 0.7090\n",
      "Epoch 1375/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2526 - accuracy: 0.7088 - val_loss: 0.2528 - val_accuracy: 0.7091\n",
      "Epoch 1376/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2526 - accuracy: 0.7088 - val_loss: 0.2528 - val_accuracy: 0.7090\n",
      "Epoch 1377/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2526 - accuracy: 0.7088 - val_loss: 0.2528 - val_accuracy: 0.7091\n",
      "Epoch 1378/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2526 - accuracy: 0.7088 - val_loss: 0.2528 - val_accuracy: 0.7091\n",
      "Epoch 1379/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2526 - accuracy: 0.7088 - val_loss: 0.2528 - val_accuracy: 0.7091\n",
      "Epoch 1380/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2526 - accuracy: 0.7089 - val_loss: 0.2528 - val_accuracy: 0.7091\n",
      "Epoch 1381/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2525 - accuracy: 0.7089 - val_loss: 0.2528 - val_accuracy: 0.7091\n",
      "Epoch 1382/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2525 - accuracy: 0.7089 - val_loss: 0.2527 - val_accuracy: 0.7091\n",
      "Epoch 1383/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2525 - accuracy: 0.7089 - val_loss: 0.2527 - val_accuracy: 0.7091\n",
      "Epoch 1384/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2525 - accuracy: 0.7089 - val_loss: 0.2527 - val_accuracy: 0.7091\n",
      "Epoch 1385/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2525 - accuracy: 0.7089 - val_loss: 0.2527 - val_accuracy: 0.7091\n",
      "Epoch 1386/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2525 - accuracy: 0.7089 - val_loss: 0.2527 - val_accuracy: 0.7091\n",
      "Epoch 1387/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2525 - accuracy: 0.7090 - val_loss: 0.2527 - val_accuracy: 0.7091\n",
      "Epoch 1388/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2525 - accuracy: 0.7090 - val_loss: 0.2527 - val_accuracy: 0.7091\n",
      "Epoch 1389/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2525 - accuracy: 0.7090 - val_loss: 0.2527 - val_accuracy: 0.7091\n",
      "Epoch 1390/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2524 - accuracy: 0.7090 - val_loss: 0.2526 - val_accuracy: 0.7091\n",
      "Epoch 1391/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2524 - accuracy: 0.7090 - val_loss: 0.2526 - val_accuracy: 0.7092\n",
      "Epoch 1392/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2524 - accuracy: 0.7090 - val_loss: 0.2526 - val_accuracy: 0.7092\n",
      "Epoch 1393/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2524 - accuracy: 0.7090 - val_loss: 0.2526 - val_accuracy: 0.7092\n",
      "Epoch 1394/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2524 - accuracy: 0.7090 - val_loss: 0.2526 - val_accuracy: 0.7092\n",
      "Epoch 1395/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2524 - accuracy: 0.7090 - val_loss: 0.2526 - val_accuracy: 0.7093\n",
      "Epoch 1396/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2524 - accuracy: 0.7090 - val_loss: 0.2526 - val_accuracy: 0.7093\n",
      "Epoch 1397/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2524 - accuracy: 0.7090 - val_loss: 0.2526 - val_accuracy: 0.7093\n",
      "Epoch 1398/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2523 - accuracy: 0.7090 - val_loss: 0.2526 - val_accuracy: 0.7093\n",
      "Epoch 1399/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2523 - accuracy: 0.7091 - val_loss: 0.2525 - val_accuracy: 0.7094\n",
      "Epoch 1400/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2523 - accuracy: 0.7090 - val_loss: 0.2525 - val_accuracy: 0.7093\n",
      "Epoch 1401/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2523 - accuracy: 0.7091 - val_loss: 0.2525 - val_accuracy: 0.7094\n",
      "Epoch 1402/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2523 - accuracy: 0.7091 - val_loss: 0.2525 - val_accuracy: 0.7094\n",
      "Epoch 1403/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2523 - accuracy: 0.7091 - val_loss: 0.2525 - val_accuracy: 0.7094\n",
      "Epoch 1404/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2523 - accuracy: 0.7091 - val_loss: 0.2525 - val_accuracy: 0.7094\n",
      "Epoch 1405/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2523 - accuracy: 0.7091 - val_loss: 0.2525 - val_accuracy: 0.7094\n",
      "Epoch 1406/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2523 - accuracy: 0.7091 - val_loss: 0.2525 - val_accuracy: 0.7094\n",
      "Epoch 1407/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2522 - accuracy: 0.7092 - val_loss: 0.2524 - val_accuracy: 0.7094\n",
      "Epoch 1408/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2522 - accuracy: 0.7091 - val_loss: 0.2524 - val_accuracy: 0.7094\n",
      "Epoch 1409/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2522 - accuracy: 0.7092 - val_loss: 0.2524 - val_accuracy: 0.7094\n",
      "Epoch 1410/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2522 - accuracy: 0.7092 - val_loss: 0.2524 - val_accuracy: 0.7095\n",
      "Epoch 1411/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2522 - accuracy: 0.7091 - val_loss: 0.2524 - val_accuracy: 0.7095\n",
      "Epoch 1412/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2522 - accuracy: 0.7091 - val_loss: 0.2524 - val_accuracy: 0.7094\n",
      "Epoch 1413/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2522 - accuracy: 0.7091 - val_loss: 0.2524 - val_accuracy: 0.7094\n",
      "Epoch 1414/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2522 - accuracy: 0.7091 - val_loss: 0.2523 - val_accuracy: 0.7094\n",
      "Epoch 1415/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2521 - accuracy: 0.7091 - val_loss: 0.2523 - val_accuracy: 0.7095\n",
      "Epoch 1416/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2521 - accuracy: 0.7091 - val_loss: 0.2523 - val_accuracy: 0.7095\n",
      "Epoch 1417/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2521 - accuracy: 0.7091 - val_loss: 0.2523 - val_accuracy: 0.7096\n",
      "Epoch 1418/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2521 - accuracy: 0.7092 - val_loss: 0.2523 - val_accuracy: 0.7096\n",
      "Epoch 1419/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2521 - accuracy: 0.7092 - val_loss: 0.2523 - val_accuracy: 0.7096\n",
      "Epoch 1420/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2521 - accuracy: 0.7092 - val_loss: 0.2523 - val_accuracy: 0.7096\n",
      "Epoch 1421/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2521 - accuracy: 0.7092 - val_loss: 0.2522 - val_accuracy: 0.7097\n",
      "Epoch 1422/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2521 - accuracy: 0.7092 - val_loss: 0.2522 - val_accuracy: 0.7097\n",
      "Epoch 1423/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2520 - accuracy: 0.7092 - val_loss: 0.2522 - val_accuracy: 0.7097\n",
      "Epoch 1424/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2520 - accuracy: 0.7093 - val_loss: 0.2522 - val_accuracy: 0.7097\n",
      "Epoch 1425/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2520 - accuracy: 0.7093 - val_loss: 0.2522 - val_accuracy: 0.7098\n",
      "Epoch 1426/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2520 - accuracy: 0.7093 - val_loss: 0.2522 - val_accuracy: 0.7098\n",
      "Epoch 1427/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2520 - accuracy: 0.7094 - val_loss: 0.2522 - val_accuracy: 0.7098\n",
      "Epoch 1428/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2520 - accuracy: 0.7094 - val_loss: 0.2522 - val_accuracy: 0.7098\n",
      "Epoch 1429/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2520 - accuracy: 0.7094 - val_loss: 0.2522 - val_accuracy: 0.7098\n",
      "Epoch 1430/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2520 - accuracy: 0.7094 - val_loss: 0.2521 - val_accuracy: 0.7098\n",
      "Epoch 1431/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2520 - accuracy: 0.7094 - val_loss: 0.2521 - val_accuracy: 0.7098\n",
      "Epoch 1432/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2519 - accuracy: 0.7095 - val_loss: 0.2521 - val_accuracy: 0.7098\n",
      "Epoch 1433/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2519 - accuracy: 0.7095 - val_loss: 0.2521 - val_accuracy: 0.7098\n",
      "Epoch 1434/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2519 - accuracy: 0.7095 - val_loss: 0.2521 - val_accuracy: 0.7098\n",
      "Epoch 1435/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2519 - accuracy: 0.7095 - val_loss: 0.2521 - val_accuracy: 0.7099\n",
      "Epoch 1436/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2519 - accuracy: 0.7095 - val_loss: 0.2521 - val_accuracy: 0.7099\n",
      "Epoch 1437/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2519 - accuracy: 0.7095 - val_loss: 0.2521 - val_accuracy: 0.7098\n",
      "Epoch 1438/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2519 - accuracy: 0.7095 - val_loss: 0.2521 - val_accuracy: 0.7098\n",
      "Epoch 1439/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2519 - accuracy: 0.7095 - val_loss: 0.2520 - val_accuracy: 0.7099\n",
      "Epoch 1440/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2519 - accuracy: 0.7096 - val_loss: 0.2520 - val_accuracy: 0.7099\n",
      "Epoch 1441/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2518 - accuracy: 0.7095 - val_loss: 0.2520 - val_accuracy: 0.7099\n",
      "Epoch 1442/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2518 - accuracy: 0.7095 - val_loss: 0.2520 - val_accuracy: 0.7099\n",
      "Epoch 1443/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2518 - accuracy: 0.7096 - val_loss: 0.2520 - val_accuracy: 0.7099\n",
      "Epoch 1444/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2518 - accuracy: 0.7095 - val_loss: 0.2520 - val_accuracy: 0.7100\n",
      "Epoch 1445/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2518 - accuracy: 0.7095 - val_loss: 0.2520 - val_accuracy: 0.7100\n",
      "Epoch 1446/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2518 - accuracy: 0.7096 - val_loss: 0.2520 - val_accuracy: 0.7100\n",
      "Epoch 1447/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2518 - accuracy: 0.7096 - val_loss: 0.2520 - val_accuracy: 0.7100\n",
      "Epoch 1448/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2518 - accuracy: 0.7096 - val_loss: 0.2519 - val_accuracy: 0.7100\n",
      "Epoch 1449/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2518 - accuracy: 0.7096 - val_loss: 0.2519 - val_accuracy: 0.7100\n",
      "Epoch 1450/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2518 - accuracy: 0.7096 - val_loss: 0.2519 - val_accuracy: 0.7101\n",
      "Epoch 1451/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2517 - accuracy: 0.7096 - val_loss: 0.2519 - val_accuracy: 0.7101\n",
      "Epoch 1452/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2517 - accuracy: 0.7096 - val_loss: 0.2519 - val_accuracy: 0.7101\n",
      "Epoch 1453/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2517 - accuracy: 0.7096 - val_loss: 0.2519 - val_accuracy: 0.7102\n",
      "Epoch 1454/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2517 - accuracy: 0.7096 - val_loss: 0.2519 - val_accuracy: 0.7102\n",
      "Epoch 1455/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2517 - accuracy: 0.7096 - val_loss: 0.2519 - val_accuracy: 0.7102\n",
      "Epoch 1456/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2517 - accuracy: 0.7096 - val_loss: 0.2519 - val_accuracy: 0.7102\n",
      "Epoch 1457/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2517 - accuracy: 0.7096 - val_loss: 0.2519 - val_accuracy: 0.7102\n",
      "Epoch 1458/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2517 - accuracy: 0.7096 - val_loss: 0.2518 - val_accuracy: 0.7102\n",
      "Epoch 1459/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2517 - accuracy: 0.7096 - val_loss: 0.2518 - val_accuracy: 0.7103\n",
      "Epoch 1460/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2517 - accuracy: 0.7096 - val_loss: 0.2518 - val_accuracy: 0.7103\n",
      "Epoch 1461/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2516 - accuracy: 0.7096 - val_loss: 0.2518 - val_accuracy: 0.7103\n",
      "Epoch 1462/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2516 - accuracy: 0.7096 - val_loss: 0.2518 - val_accuracy: 0.7104\n",
      "Epoch 1463/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2516 - accuracy: 0.7097 - val_loss: 0.2518 - val_accuracy: 0.7104\n",
      "Epoch 1464/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2516 - accuracy: 0.7097 - val_loss: 0.2518 - val_accuracy: 0.7104\n",
      "Epoch 1465/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2516 - accuracy: 0.7097 - val_loss: 0.2518 - val_accuracy: 0.7104\n",
      "Epoch 1466/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2516 - accuracy: 0.7097 - val_loss: 0.2518 - val_accuracy: 0.7104\n",
      "Epoch 1467/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2516 - accuracy: 0.7097 - val_loss: 0.2517 - val_accuracy: 0.7104\n",
      "Epoch 1468/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2516 - accuracy: 0.7098 - val_loss: 0.2517 - val_accuracy: 0.7104\n",
      "Epoch 1469/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2516 - accuracy: 0.7098 - val_loss: 0.2517 - val_accuracy: 0.7105\n",
      "Epoch 1470/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2515 - accuracy: 0.7098 - val_loss: 0.2517 - val_accuracy: 0.7105\n",
      "Epoch 1471/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2515 - accuracy: 0.7098 - val_loss: 0.2517 - val_accuracy: 0.7105\n",
      "Epoch 1472/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2515 - accuracy: 0.7098 - val_loss: 0.2517 - val_accuracy: 0.7105\n",
      "Epoch 1473/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2515 - accuracy: 0.7098 - val_loss: 0.2517 - val_accuracy: 0.7105\n",
      "Epoch 1474/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2515 - accuracy: 0.7099 - val_loss: 0.2517 - val_accuracy: 0.7105\n",
      "Epoch 1475/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2515 - accuracy: 0.7099 - val_loss: 0.2517 - val_accuracy: 0.7105\n",
      "Epoch 1476/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2515 - accuracy: 0.7099 - val_loss: 0.2516 - val_accuracy: 0.7105\n",
      "Epoch 1477/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2515 - accuracy: 0.7099 - val_loss: 0.2516 - val_accuracy: 0.7105\n",
      "Epoch 1478/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2515 - accuracy: 0.7099 - val_loss: 0.2516 - val_accuracy: 0.7105\n",
      "Epoch 1479/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2515 - accuracy: 0.7099 - val_loss: 0.2516 - val_accuracy: 0.7105\n",
      "Epoch 1480/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2514 - accuracy: 0.7099 - val_loss: 0.2516 - val_accuracy: 0.7105\n",
      "Epoch 1481/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2514 - accuracy: 0.7099 - val_loss: 0.2516 - val_accuracy: 0.7105\n",
      "Epoch 1482/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2514 - accuracy: 0.7100 - val_loss: 0.2516 - val_accuracy: 0.7105\n",
      "Epoch 1483/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2514 - accuracy: 0.7099 - val_loss: 0.2516 - val_accuracy: 0.7105\n",
      "Epoch 1484/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2514 - accuracy: 0.7100 - val_loss: 0.2516 - val_accuracy: 0.7106\n",
      "Epoch 1485/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2514 - accuracy: 0.7099 - val_loss: 0.2515 - val_accuracy: 0.7106\n",
      "Epoch 1486/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2514 - accuracy: 0.7099 - val_loss: 0.2515 - val_accuracy: 0.7106\n",
      "Epoch 1487/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2514 - accuracy: 0.7099 - val_loss: 0.2515 - val_accuracy: 0.7106\n",
      "Epoch 1488/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2514 - accuracy: 0.7099 - val_loss: 0.2515 - val_accuracy: 0.7106\n",
      "Epoch 1489/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2514 - accuracy: 0.7100 - val_loss: 0.2515 - val_accuracy: 0.7106\n",
      "Epoch 1490/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2513 - accuracy: 0.7100 - val_loss: 0.2515 - val_accuracy: 0.7106\n",
      "Epoch 1491/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2513 - accuracy: 0.7100 - val_loss: 0.2515 - val_accuracy: 0.7106\n",
      "Epoch 1492/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2513 - accuracy: 0.7099 - val_loss: 0.2515 - val_accuracy: 0.7106\n",
      "Epoch 1493/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2513 - accuracy: 0.7099 - val_loss: 0.2515 - val_accuracy: 0.7106\n",
      "Epoch 1494/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2513 - accuracy: 0.7100 - val_loss: 0.2514 - val_accuracy: 0.7106\n",
      "Epoch 1495/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2513 - accuracy: 0.7100 - val_loss: 0.2514 - val_accuracy: 0.7106\n",
      "Epoch 1496/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2513 - accuracy: 0.7100 - val_loss: 0.2514 - val_accuracy: 0.7106\n",
      "Epoch 1497/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2513 - accuracy: 0.7100 - val_loss: 0.2514 - val_accuracy: 0.7107\n",
      "Epoch 1498/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2513 - accuracy: 0.7100 - val_loss: 0.2514 - val_accuracy: 0.7106\n",
      "Epoch 1499/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2513 - accuracy: 0.7101 - val_loss: 0.2514 - val_accuracy: 0.7107\n",
      "Epoch 1500/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2512 - accuracy: 0.7100 - val_loss: 0.2514 - val_accuracy: 0.7107\n",
      "Epoch 1501/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2512 - accuracy: 0.7101 - val_loss: 0.2514 - val_accuracy: 0.7107\n",
      "Epoch 1502/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2512 - accuracy: 0.7101 - val_loss: 0.2514 - val_accuracy: 0.7107\n",
      "Epoch 1503/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2512 - accuracy: 0.7101 - val_loss: 0.2513 - val_accuracy: 0.7107\n",
      "Epoch 1504/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2512 - accuracy: 0.7101 - val_loss: 0.2513 - val_accuracy: 0.7107\n",
      "Epoch 1505/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2512 - accuracy: 0.7101 - val_loss: 0.2513 - val_accuracy: 0.7108\n",
      "Epoch 1506/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2512 - accuracy: 0.7101 - val_loss: 0.2513 - val_accuracy: 0.7108\n",
      "Epoch 1507/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2512 - accuracy: 0.7101 - val_loss: 0.2513 - val_accuracy: 0.7108\n",
      "Epoch 1508/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2512 - accuracy: 0.7101 - val_loss: 0.2513 - val_accuracy: 0.7108\n",
      "Epoch 1509/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2512 - accuracy: 0.7102 - val_loss: 0.2513 - val_accuracy: 0.7108\n",
      "Epoch 1510/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2511 - accuracy: 0.7102 - val_loss: 0.2513 - val_accuracy: 0.7108\n",
      "Epoch 1511/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2511 - accuracy: 0.7102 - val_loss: 0.2513 - val_accuracy: 0.7108\n",
      "Epoch 1512/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2511 - accuracy: 0.7102 - val_loss: 0.2512 - val_accuracy: 0.7109\n",
      "Epoch 1513/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2511 - accuracy: 0.7102 - val_loss: 0.2512 - val_accuracy: 0.7109\n",
      "Epoch 1514/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2511 - accuracy: 0.7102 - val_loss: 0.2512 - val_accuracy: 0.7109\n",
      "Epoch 1515/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2511 - accuracy: 0.7102 - val_loss: 0.2512 - val_accuracy: 0.7109\n",
      "Epoch 1516/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2511 - accuracy: 0.7102 - val_loss: 0.2512 - val_accuracy: 0.7109\n",
      "Epoch 1517/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2511 - accuracy: 0.7102 - val_loss: 0.2512 - val_accuracy: 0.7110\n",
      "Epoch 1518/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2511 - accuracy: 0.7102 - val_loss: 0.2512 - val_accuracy: 0.7110\n",
      "Epoch 1519/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2511 - accuracy: 0.7102 - val_loss: 0.2512 - val_accuracy: 0.7110\n",
      "Epoch 1520/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2510 - accuracy: 0.7103 - val_loss: 0.2512 - val_accuracy: 0.7110\n",
      "Epoch 1521/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2510 - accuracy: 0.7103 - val_loss: 0.2511 - val_accuracy: 0.7110\n",
      "Epoch 1522/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2510 - accuracy: 0.7103 - val_loss: 0.2511 - val_accuracy: 0.7110\n",
      "Epoch 1523/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2510 - accuracy: 0.7103 - val_loss: 0.2511 - val_accuracy: 0.7111\n",
      "Epoch 1524/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2510 - accuracy: 0.7103 - val_loss: 0.2511 - val_accuracy: 0.7111\n",
      "Epoch 1525/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2510 - accuracy: 0.7103 - val_loss: 0.2511 - val_accuracy: 0.7112\n",
      "Epoch 1526/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2510 - accuracy: 0.7103 - val_loss: 0.2511 - val_accuracy: 0.7111\n",
      "Epoch 1527/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2510 - accuracy: 0.7103 - val_loss: 0.2511 - val_accuracy: 0.7111\n",
      "Epoch 1528/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2510 - accuracy: 0.7103 - val_loss: 0.2511 - val_accuracy: 0.7111\n",
      "Epoch 1529/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2510 - accuracy: 0.7103 - val_loss: 0.2511 - val_accuracy: 0.7112\n",
      "Epoch 1530/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2509 - accuracy: 0.7103 - val_loss: 0.2510 - val_accuracy: 0.7112\n",
      "Epoch 1531/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2509 - accuracy: 0.7103 - val_loss: 0.2510 - val_accuracy: 0.7112\n",
      "Epoch 1532/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2509 - accuracy: 0.7103 - val_loss: 0.2510 - val_accuracy: 0.7112\n",
      "Epoch 1533/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2509 - accuracy: 0.7103 - val_loss: 0.2510 - val_accuracy: 0.7112\n",
      "Epoch 1534/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2509 - accuracy: 0.7104 - val_loss: 0.2510 - val_accuracy: 0.7113\n",
      "Epoch 1535/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2509 - accuracy: 0.7104 - val_loss: 0.2510 - val_accuracy: 0.7113\n",
      "Epoch 1536/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2509 - accuracy: 0.7104 - val_loss: 0.2510 - val_accuracy: 0.7113\n",
      "Epoch 1537/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2509 - accuracy: 0.7104 - val_loss: 0.2510 - val_accuracy: 0.7113\n",
      "Epoch 1538/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2509 - accuracy: 0.7104 - val_loss: 0.2510 - val_accuracy: 0.7113\n",
      "Epoch 1539/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2509 - accuracy: 0.7105 - val_loss: 0.2509 - val_accuracy: 0.7114\n",
      "Epoch 1540/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2509 - accuracy: 0.7105 - val_loss: 0.2509 - val_accuracy: 0.7114\n",
      "Epoch 1541/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2508 - accuracy: 0.7105 - val_loss: 0.2509 - val_accuracy: 0.7114\n",
      "Epoch 1542/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2508 - accuracy: 0.7105 - val_loss: 0.2509 - val_accuracy: 0.7114\n",
      "Epoch 1543/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2508 - accuracy: 0.7105 - val_loss: 0.2509 - val_accuracy: 0.7114\n",
      "Epoch 1544/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2508 - accuracy: 0.7105 - val_loss: 0.2509 - val_accuracy: 0.7114\n",
      "Epoch 1545/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2508 - accuracy: 0.7106 - val_loss: 0.2509 - val_accuracy: 0.7114\n",
      "Epoch 1546/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2508 - accuracy: 0.7106 - val_loss: 0.2509 - val_accuracy: 0.7114\n",
      "Epoch 1547/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2508 - accuracy: 0.7105 - val_loss: 0.2508 - val_accuracy: 0.7115\n",
      "Epoch 1548/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2508 - accuracy: 0.7106 - val_loss: 0.2508 - val_accuracy: 0.7114\n",
      "Epoch 1549/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2508 - accuracy: 0.7106 - val_loss: 0.2508 - val_accuracy: 0.7114\n",
      "Epoch 1550/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2508 - accuracy: 0.7106 - val_loss: 0.2508 - val_accuracy: 0.7115\n",
      "Epoch 1551/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.7106 - val_loss: 0.2508 - val_accuracy: 0.7115\n",
      "Epoch 1552/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.7106 - val_loss: 0.2508 - val_accuracy: 0.7115\n",
      "Epoch 1553/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.7106 - val_loss: 0.2508 - val_accuracy: 0.7115\n",
      "Epoch 1554/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.7107 - val_loss: 0.2508 - val_accuracy: 0.7115\n",
      "Epoch 1555/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.7107 - val_loss: 0.2508 - val_accuracy: 0.7115\n",
      "Epoch 1556/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.7107 - val_loss: 0.2508 - val_accuracy: 0.7115\n",
      "Epoch 1557/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.7107 - val_loss: 0.2507 - val_accuracy: 0.7115\n",
      "Epoch 1558/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2507 - accuracy: 0.7108 - val_loss: 0.2507 - val_accuracy: 0.7116\n",
      "Epoch 1559/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.7108 - val_loss: 0.2507 - val_accuracy: 0.7116\n",
      "Epoch 1560/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.7108 - val_loss: 0.2507 - val_accuracy: 0.7116\n",
      "Epoch 1561/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2507 - accuracy: 0.7108 - val_loss: 0.2507 - val_accuracy: 0.7116\n",
      "Epoch 1562/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2506 - accuracy: 0.7108 - val_loss: 0.2507 - val_accuracy: 0.7115\n",
      "Epoch 1563/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.7108 - val_loss: 0.2507 - val_accuracy: 0.7116\n",
      "Epoch 1564/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2506 - accuracy: 0.7108 - val_loss: 0.2507 - val_accuracy: 0.7116\n",
      "Epoch 1565/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.7108 - val_loss: 0.2507 - val_accuracy: 0.7116\n",
      "Epoch 1566/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2506 - accuracy: 0.7108 - val_loss: 0.2507 - val_accuracy: 0.7116\n",
      "Epoch 1567/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.7108 - val_loss: 0.2506 - val_accuracy: 0.7116\n",
      "Epoch 1568/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.7108 - val_loss: 0.2506 - val_accuracy: 0.7116\n",
      "Epoch 1569/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.7108 - val_loss: 0.2506 - val_accuracy: 0.7116\n",
      "Epoch 1570/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2506 - accuracy: 0.7108 - val_loss: 0.2506 - val_accuracy: 0.7116\n",
      "Epoch 1571/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2506 - accuracy: 0.7108 - val_loss: 0.2506 - val_accuracy: 0.7116\n",
      "Epoch 1572/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2506 - accuracy: 0.7108 - val_loss: 0.2506 - val_accuracy: 0.7116\n",
      "Epoch 1573/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.7108 - val_loss: 0.2506 - val_accuracy: 0.7117\n",
      "Epoch 1574/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2505 - accuracy: 0.7108 - val_loss: 0.2506 - val_accuracy: 0.7117\n",
      "Epoch 1575/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.7108 - val_loss: 0.2506 - val_accuracy: 0.7117\n",
      "Epoch 1576/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.7108 - val_loss: 0.2506 - val_accuracy: 0.7118\n",
      "Epoch 1577/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.7108 - val_loss: 0.2505 - val_accuracy: 0.7117\n",
      "Epoch 1578/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.7108 - val_loss: 0.2505 - val_accuracy: 0.7118\n",
      "Epoch 1579/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.7108 - val_loss: 0.2505 - val_accuracy: 0.7118\n",
      "Epoch 1580/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2505 - accuracy: 0.7108 - val_loss: 0.2505 - val_accuracy: 0.7118\n",
      "Epoch 1581/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.7109 - val_loss: 0.2505 - val_accuracy: 0.7118\n",
      "Epoch 1582/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.7108 - val_loss: 0.2505 - val_accuracy: 0.7118\n",
      "Epoch 1583/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2505 - accuracy: 0.7108 - val_loss: 0.2505 - val_accuracy: 0.7118\n",
      "Epoch 1584/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2505 - accuracy: 0.7109 - val_loss: 0.2505 - val_accuracy: 0.7118\n",
      "Epoch 1585/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2504 - accuracy: 0.7109 - val_loss: 0.2505 - val_accuracy: 0.7118\n",
      "Epoch 1586/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2504 - accuracy: 0.7109 - val_loss: 0.2505 - val_accuracy: 0.7118\n",
      "Epoch 1587/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2504 - accuracy: 0.7109 - val_loss: 0.2505 - val_accuracy: 0.7118\n",
      "Epoch 1588/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2504 - accuracy: 0.7109 - val_loss: 0.2504 - val_accuracy: 0.7118\n",
      "Epoch 1589/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2504 - accuracy: 0.7109 - val_loss: 0.2504 - val_accuracy: 0.7118\n",
      "Epoch 1590/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2504 - accuracy: 0.7109 - val_loss: 0.2504 - val_accuracy: 0.7118\n",
      "Epoch 1591/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2504 - accuracy: 0.7110 - val_loss: 0.2504 - val_accuracy: 0.7118\n",
      "Epoch 1592/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2504 - accuracy: 0.7110 - val_loss: 0.2504 - val_accuracy: 0.7118\n",
      "Epoch 1593/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2504 - accuracy: 0.7110 - val_loss: 0.2504 - val_accuracy: 0.7118\n",
      "Epoch 1594/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2504 - accuracy: 0.7110 - val_loss: 0.2504 - val_accuracy: 0.7118\n",
      "Epoch 1595/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2504 - accuracy: 0.7110 - val_loss: 0.2504 - val_accuracy: 0.7118\n",
      "Epoch 1596/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.7110 - val_loss: 0.2504 - val_accuracy: 0.7119\n",
      "Epoch 1597/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.7110 - val_loss: 0.2504 - val_accuracy: 0.7119\n",
      "Epoch 1598/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.7110 - val_loss: 0.2503 - val_accuracy: 0.7119\n",
      "Epoch 1599/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.7110 - val_loss: 0.2503 - val_accuracy: 0.7119\n",
      "Epoch 1600/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.7110 - val_loss: 0.2503 - val_accuracy: 0.7119\n",
      "Epoch 1601/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.7111 - val_loss: 0.2503 - val_accuracy: 0.7118\n",
      "Epoch 1602/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.7111 - val_loss: 0.2503 - val_accuracy: 0.7118\n",
      "Epoch 1603/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.7111 - val_loss: 0.2503 - val_accuracy: 0.7118\n",
      "Epoch 1604/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.7111 - val_loss: 0.2503 - val_accuracy: 0.7118\n",
      "Epoch 1605/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.7111 - val_loss: 0.2503 - val_accuracy: 0.7118\n",
      "Epoch 1606/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.7111 - val_loss: 0.2503 - val_accuracy: 0.7118\n",
      "Epoch 1607/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.7111 - val_loss: 0.2503 - val_accuracy: 0.7118\n",
      "Epoch 1608/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.7112 - val_loss: 0.2503 - val_accuracy: 0.7118\n",
      "Epoch 1609/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.7112 - val_loss: 0.2502 - val_accuracy: 0.7118\n",
      "Epoch 1610/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.7112 - val_loss: 0.2502 - val_accuracy: 0.7118\n",
      "Epoch 1611/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2502 - accuracy: 0.7112 - val_loss: 0.2502 - val_accuracy: 0.7118\n",
      "Epoch 1612/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2502 - accuracy: 0.7112 - val_loss: 0.2502 - val_accuracy: 0.7118\n",
      "Epoch 1613/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.7112 - val_loss: 0.2502 - val_accuracy: 0.7119\n",
      "Epoch 1614/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.7112 - val_loss: 0.2502 - val_accuracy: 0.7119\n",
      "Epoch 1615/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.7112 - val_loss: 0.2502 - val_accuracy: 0.7119\n",
      "Epoch 1616/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.7113 - val_loss: 0.2502 - val_accuracy: 0.7119\n",
      "Epoch 1617/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.7113 - val_loss: 0.2502 - val_accuracy: 0.7119\n",
      "Epoch 1618/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.7113 - val_loss: 0.2502 - val_accuracy: 0.7119\n",
      "Epoch 1619/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2501 - accuracy: 0.7113 - val_loss: 0.2502 - val_accuracy: 0.7119\n",
      "Epoch 1620/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2501 - accuracy: 0.7113 - val_loss: 0.2501 - val_accuracy: 0.7119\n",
      "Epoch 1621/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2501 - accuracy: 0.7113 - val_loss: 0.2501 - val_accuracy: 0.7119\n",
      "Epoch 1622/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2501 - accuracy: 0.7113 - val_loss: 0.2501 - val_accuracy: 0.7119\n",
      "Epoch 1623/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2501 - accuracy: 0.7113 - val_loss: 0.2501 - val_accuracy: 0.7119\n",
      "Epoch 1624/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2501 - accuracy: 0.7113 - val_loss: 0.2501 - val_accuracy: 0.7119\n",
      "Epoch 1625/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2501 - accuracy: 0.7113 - val_loss: 0.2501 - val_accuracy: 0.7119\n",
      "Epoch 1626/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2501 - accuracy: 0.7113 - val_loss: 0.2501 - val_accuracy: 0.7119\n",
      "Epoch 1627/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2501 - accuracy: 0.7113 - val_loss: 0.2501 - val_accuracy: 0.7119\n",
      "Epoch 1628/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2501 - accuracy: 0.7114 - val_loss: 0.2501 - val_accuracy: 0.7119\n",
      "Epoch 1629/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2501 - accuracy: 0.7114 - val_loss: 0.2501 - val_accuracy: 0.7119\n",
      "Epoch 1630/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2500 - accuracy: 0.7114 - val_loss: 0.2500 - val_accuracy: 0.7119\n",
      "Epoch 1631/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2500 - accuracy: 0.7114 - val_loss: 0.2500 - val_accuracy: 0.7119\n",
      "Epoch 1632/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2500 - accuracy: 0.7115 - val_loss: 0.2500 - val_accuracy: 0.7119\n",
      "Epoch 1633/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2500 - accuracy: 0.7114 - val_loss: 0.2500 - val_accuracy: 0.7119\n",
      "Epoch 1634/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2500 - accuracy: 0.7115 - val_loss: 0.2500 - val_accuracy: 0.7119\n",
      "Epoch 1635/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2500 - accuracy: 0.7115 - val_loss: 0.2500 - val_accuracy: 0.7119\n",
      "Epoch 1636/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2500 - accuracy: 0.7115 - val_loss: 0.2500 - val_accuracy: 0.7119\n",
      "Epoch 1637/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2500 - accuracy: 0.7115 - val_loss: 0.2500 - val_accuracy: 0.7119\n",
      "Epoch 1638/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2500 - accuracy: 0.7114 - val_loss: 0.2500 - val_accuracy: 0.7119\n",
      "Epoch 1639/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2500 - accuracy: 0.7115 - val_loss: 0.2500 - val_accuracy: 0.7119\n",
      "Epoch 1640/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2500 - accuracy: 0.7115 - val_loss: 0.2500 - val_accuracy: 0.7119\n",
      "Epoch 1641/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2500 - accuracy: 0.7114 - val_loss: 0.2499 - val_accuracy: 0.7119\n",
      "Epoch 1642/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2499 - accuracy: 0.7115 - val_loss: 0.2499 - val_accuracy: 0.7120\n",
      "Epoch 1643/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2499 - accuracy: 0.7115 - val_loss: 0.2499 - val_accuracy: 0.7120\n",
      "Epoch 1644/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2499 - accuracy: 0.7115 - val_loss: 0.2499 - val_accuracy: 0.7120\n",
      "Epoch 1645/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2499 - accuracy: 0.7115 - val_loss: 0.2499 - val_accuracy: 0.7120\n",
      "Epoch 1646/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2499 - accuracy: 0.7115 - val_loss: 0.2499 - val_accuracy: 0.7120\n",
      "Epoch 1647/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2499 - accuracy: 0.7115 - val_loss: 0.2499 - val_accuracy: 0.7121\n",
      "Epoch 1648/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2499 - accuracy: 0.7115 - val_loss: 0.2499 - val_accuracy: 0.7121\n",
      "Epoch 1649/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2499 - accuracy: 0.7116 - val_loss: 0.2499 - val_accuracy: 0.7121\n",
      "Epoch 1650/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2499 - accuracy: 0.7115 - val_loss: 0.2499 - val_accuracy: 0.7121\n",
      "Epoch 1651/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2499 - accuracy: 0.7116 - val_loss: 0.2498 - val_accuracy: 0.7121\n",
      "Epoch 1652/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2499 - accuracy: 0.7116 - val_loss: 0.2498 - val_accuracy: 0.7121\n",
      "Epoch 1653/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2498 - accuracy: 0.7116 - val_loss: 0.2498 - val_accuracy: 0.7121\n",
      "Epoch 1654/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2498 - accuracy: 0.7116 - val_loss: 0.2498 - val_accuracy: 0.7121\n",
      "Epoch 1655/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2498 - accuracy: 0.7116 - val_loss: 0.2498 - val_accuracy: 0.7121\n",
      "Epoch 1656/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2498 - accuracy: 0.7116 - val_loss: 0.2498 - val_accuracy: 0.7121\n",
      "Epoch 1657/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2498 - accuracy: 0.7115 - val_loss: 0.2498 - val_accuracy: 0.7120\n",
      "Epoch 1658/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2498 - accuracy: 0.7116 - val_loss: 0.2498 - val_accuracy: 0.7121\n",
      "Epoch 1659/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2498 - accuracy: 0.7116 - val_loss: 0.2498 - val_accuracy: 0.7121\n",
      "Epoch 1660/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2498 - accuracy: 0.7116 - val_loss: 0.2497 - val_accuracy: 0.7121\n",
      "Epoch 1661/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2498 - accuracy: 0.7116 - val_loss: 0.2497 - val_accuracy: 0.7121\n",
      "Epoch 1662/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2498 - accuracy: 0.7116 - val_loss: 0.2497 - val_accuracy: 0.7121\n",
      "Epoch 1663/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2498 - accuracy: 0.7116 - val_loss: 0.2497 - val_accuracy: 0.7121\n",
      "Epoch 1664/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2497 - accuracy: 0.7116 - val_loss: 0.2497 - val_accuracy: 0.7121\n",
      "Epoch 1665/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2497 - accuracy: 0.7116 - val_loss: 0.2497 - val_accuracy: 0.7121\n",
      "Epoch 1666/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2497 - accuracy: 0.7116 - val_loss: 0.2497 - val_accuracy: 0.7121\n",
      "Epoch 1667/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2497 - accuracy: 0.7116 - val_loss: 0.2497 - val_accuracy: 0.7122\n",
      "Epoch 1668/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2497 - accuracy: 0.7116 - val_loss: 0.2497 - val_accuracy: 0.7122\n",
      "Epoch 1669/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2497 - accuracy: 0.7117 - val_loss: 0.2497 - val_accuracy: 0.7122\n",
      "Epoch 1670/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2497 - accuracy: 0.7117 - val_loss: 0.2496 - val_accuracy: 0.7122\n",
      "Epoch 1671/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2497 - accuracy: 0.7117 - val_loss: 0.2496 - val_accuracy: 0.7122\n",
      "Epoch 1672/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2497 - accuracy: 0.7117 - val_loss: 0.2496 - val_accuracy: 0.7122\n",
      "Epoch 1673/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2497 - accuracy: 0.7117 - val_loss: 0.2496 - val_accuracy: 0.7122\n",
      "Epoch 1674/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2497 - accuracy: 0.7117 - val_loss: 0.2496 - val_accuracy: 0.7123\n",
      "Epoch 1675/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2496 - accuracy: 0.7117 - val_loss: 0.2496 - val_accuracy: 0.7123\n",
      "Epoch 1676/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2496 - accuracy: 0.7118 - val_loss: 0.2496 - val_accuracy: 0.7123\n",
      "Epoch 1677/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2496 - accuracy: 0.7118 - val_loss: 0.2496 - val_accuracy: 0.7123\n",
      "Epoch 1678/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2496 - accuracy: 0.7118 - val_loss: 0.2496 - val_accuracy: 0.7123\n",
      "Epoch 1679/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2496 - accuracy: 0.7118 - val_loss: 0.2496 - val_accuracy: 0.7122\n",
      "Epoch 1680/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2496 - accuracy: 0.7118 - val_loss: 0.2495 - val_accuracy: 0.7122\n",
      "Epoch 1681/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2496 - accuracy: 0.7118 - val_loss: 0.2495 - val_accuracy: 0.7122\n",
      "Epoch 1682/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2496 - accuracy: 0.7118 - val_loss: 0.2495 - val_accuracy: 0.7121\n",
      "Epoch 1683/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2496 - accuracy: 0.7118 - val_loss: 0.2495 - val_accuracy: 0.7122\n",
      "Epoch 1684/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2496 - accuracy: 0.7119 - val_loss: 0.2495 - val_accuracy: 0.7122\n",
      "Epoch 1685/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2496 - accuracy: 0.7119 - val_loss: 0.2495 - val_accuracy: 0.7122\n",
      "Epoch 1686/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2496 - accuracy: 0.7119 - val_loss: 0.2495 - val_accuracy: 0.7122\n",
      "Epoch 1687/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.7119 - val_loss: 0.2495 - val_accuracy: 0.7122\n",
      "Epoch 1688/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2495 - accuracy: 0.7118 - val_loss: 0.2495 - val_accuracy: 0.7123\n",
      "Epoch 1689/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2495 - accuracy: 0.7118 - val_loss: 0.2495 - val_accuracy: 0.7123\n",
      "Epoch 1690/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.7118 - val_loss: 0.2495 - val_accuracy: 0.7123\n",
      "Epoch 1691/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.7118 - val_loss: 0.2494 - val_accuracy: 0.7123\n",
      "Epoch 1692/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.7118 - val_loss: 0.2494 - val_accuracy: 0.7123\n",
      "Epoch 1693/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.7119 - val_loss: 0.2494 - val_accuracy: 0.7123\n",
      "Epoch 1694/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.7119 - val_loss: 0.2494 - val_accuracy: 0.7123\n",
      "Epoch 1695/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.7119 - val_loss: 0.2494 - val_accuracy: 0.7123\n",
      "Epoch 1696/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.7119 - val_loss: 0.2494 - val_accuracy: 0.7123\n",
      "Epoch 1697/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.7119 - val_loss: 0.2494 - val_accuracy: 0.7123\n",
      "Epoch 1698/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.7119 - val_loss: 0.2494 - val_accuracy: 0.7122\n",
      "Epoch 1699/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.7119 - val_loss: 0.2494 - val_accuracy: 0.7122\n",
      "Epoch 1700/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2494 - accuracy: 0.7119 - val_loss: 0.2494 - val_accuracy: 0.7122\n",
      "Epoch 1701/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2494 - accuracy: 0.7119 - val_loss: 0.2494 - val_accuracy: 0.7122\n",
      "Epoch 1702/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2494 - accuracy: 0.7120 - val_loss: 0.2493 - val_accuracy: 0.7122\n",
      "Epoch 1703/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2494 - accuracy: 0.7120 - val_loss: 0.2493 - val_accuracy: 0.7122\n",
      "Epoch 1704/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2494 - accuracy: 0.7120 - val_loss: 0.2493 - val_accuracy: 0.7123\n",
      "Epoch 1705/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2494 - accuracy: 0.7120 - val_loss: 0.2493 - val_accuracy: 0.7124\n",
      "Epoch 1706/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2494 - accuracy: 0.7120 - val_loss: 0.2493 - val_accuracy: 0.7123\n",
      "Epoch 1707/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2494 - accuracy: 0.7120 - val_loss: 0.2493 - val_accuracy: 0.7123\n",
      "Epoch 1708/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2494 - accuracy: 0.7120 - val_loss: 0.2493 - val_accuracy: 0.7124\n",
      "Epoch 1709/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2494 - accuracy: 0.7120 - val_loss: 0.2493 - val_accuracy: 0.7124\n",
      "Epoch 1710/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2494 - accuracy: 0.7120 - val_loss: 0.2493 - val_accuracy: 0.7124\n",
      "Epoch 1711/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2494 - accuracy: 0.7120 - val_loss: 0.2493 - val_accuracy: 0.7124\n",
      "Epoch 1712/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2493 - accuracy: 0.7120 - val_loss: 0.2493 - val_accuracy: 0.7124\n",
      "Epoch 1713/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2493 - accuracy: 0.7120 - val_loss: 0.2492 - val_accuracy: 0.7124\n",
      "Epoch 1714/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2493 - accuracy: 0.7120 - val_loss: 0.2492 - val_accuracy: 0.7124\n",
      "Epoch 1715/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2493 - accuracy: 0.7120 - val_loss: 0.2492 - val_accuracy: 0.7124\n",
      "Epoch 1716/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2493 - accuracy: 0.7120 - val_loss: 0.2492 - val_accuracy: 0.7124\n",
      "Epoch 1717/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2493 - accuracy: 0.7120 - val_loss: 0.2492 - val_accuracy: 0.7124\n",
      "Epoch 1718/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2493 - accuracy: 0.7120 - val_loss: 0.2492 - val_accuracy: 0.7124\n",
      "Epoch 1719/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2493 - accuracy: 0.7120 - val_loss: 0.2492 - val_accuracy: 0.7124\n",
      "Epoch 1720/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2493 - accuracy: 0.7121 - val_loss: 0.2492 - val_accuracy: 0.7124\n",
      "Epoch 1721/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2493 - accuracy: 0.7121 - val_loss: 0.2492 - val_accuracy: 0.7125\n",
      "Epoch 1722/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2493 - accuracy: 0.7120 - val_loss: 0.2492 - val_accuracy: 0.7125\n",
      "Epoch 1723/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2493 - accuracy: 0.7120 - val_loss: 0.2492 - val_accuracy: 0.7124\n",
      "Epoch 1724/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2492 - accuracy: 0.7120 - val_loss: 0.2491 - val_accuracy: 0.7124\n",
      "Epoch 1725/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2492 - accuracy: 0.7121 - val_loss: 0.2491 - val_accuracy: 0.7124\n",
      "Epoch 1726/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2492 - accuracy: 0.7120 - val_loss: 0.2491 - val_accuracy: 0.7125\n",
      "Epoch 1727/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2492 - accuracy: 0.7120 - val_loss: 0.2491 - val_accuracy: 0.7125\n",
      "Epoch 1728/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2492 - accuracy: 0.7120 - val_loss: 0.2491 - val_accuracy: 0.7125\n",
      "Epoch 1729/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2492 - accuracy: 0.7120 - val_loss: 0.2491 - val_accuracy: 0.7125\n",
      "Epoch 1730/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2492 - accuracy: 0.7120 - val_loss: 0.2491 - val_accuracy: 0.7125\n",
      "Epoch 1731/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2492 - accuracy: 0.7120 - val_loss: 0.2491 - val_accuracy: 0.7125\n",
      "Epoch 1732/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2492 - accuracy: 0.7121 - val_loss: 0.2491 - val_accuracy: 0.7125\n",
      "Epoch 1733/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2492 - accuracy: 0.7120 - val_loss: 0.2491 - val_accuracy: 0.7126\n",
      "Epoch 1734/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2491 - accuracy: 0.7121 - val_loss: 0.2491 - val_accuracy: 0.7126\n",
      "Epoch 1735/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2491 - accuracy: 0.7121 - val_loss: 0.2490 - val_accuracy: 0.7125\n",
      "Epoch 1736/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2491 - accuracy: 0.7121 - val_loss: 0.2490 - val_accuracy: 0.7126\n",
      "Epoch 1737/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2491 - accuracy: 0.7120 - val_loss: 0.2490 - val_accuracy: 0.7125\n",
      "Epoch 1738/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2491 - accuracy: 0.7120 - val_loss: 0.2490 - val_accuracy: 0.7125\n",
      "Epoch 1739/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2491 - accuracy: 0.7120 - val_loss: 0.2490 - val_accuracy: 0.7125\n",
      "Epoch 1740/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2491 - accuracy: 0.7120 - val_loss: 0.2490 - val_accuracy: 0.7124\n",
      "Epoch 1741/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2491 - accuracy: 0.7120 - val_loss: 0.2490 - val_accuracy: 0.7124\n",
      "Epoch 1742/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2491 - accuracy: 0.7120 - val_loss: 0.2490 - val_accuracy: 0.7124\n",
      "Epoch 1743/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2491 - accuracy: 0.7120 - val_loss: 0.2490 - val_accuracy: 0.7124\n",
      "Epoch 1744/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2490 - accuracy: 0.7120 - val_loss: 0.2490 - val_accuracy: 0.7124\n",
      "Epoch 1745/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2490 - accuracy: 0.7120 - val_loss: 0.2490 - val_accuracy: 0.7124\n",
      "Epoch 1746/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2490 - accuracy: 0.7120 - val_loss: 0.2490 - val_accuracy: 0.7124\n",
      "Epoch 1747/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2490 - accuracy: 0.7120 - val_loss: 0.2489 - val_accuracy: 0.7124\n",
      "Epoch 1748/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2490 - accuracy: 0.7120 - val_loss: 0.2489 - val_accuracy: 0.7125\n",
      "Epoch 1749/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2490 - accuracy: 0.7120 - val_loss: 0.2489 - val_accuracy: 0.7125\n",
      "Epoch 1750/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2490 - accuracy: 0.7120 - val_loss: 0.2489 - val_accuracy: 0.7125\n",
      "Epoch 1751/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2490 - accuracy: 0.7120 - val_loss: 0.2489 - val_accuracy: 0.7125\n",
      "Epoch 1752/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2490 - accuracy: 0.7120 - val_loss: 0.2489 - val_accuracy: 0.7125\n",
      "Epoch 1753/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2490 - accuracy: 0.7120 - val_loss: 0.2489 - val_accuracy: 0.7125\n",
      "Epoch 1754/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2490 - accuracy: 0.7120 - val_loss: 0.2489 - val_accuracy: 0.7125\n",
      "Epoch 1755/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2489 - accuracy: 0.7121 - val_loss: 0.2489 - val_accuracy: 0.7125\n",
      "Epoch 1756/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2489 - accuracy: 0.7120 - val_loss: 0.2489 - val_accuracy: 0.7125\n",
      "Epoch 1757/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2489 - accuracy: 0.7121 - val_loss: 0.2489 - val_accuracy: 0.7126\n",
      "Epoch 1758/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2489 - accuracy: 0.7121 - val_loss: 0.2489 - val_accuracy: 0.7126\n",
      "Epoch 1759/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2489 - accuracy: 0.7121 - val_loss: 0.2489 - val_accuracy: 0.7126\n",
      "Epoch 1760/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2489 - accuracy: 0.7121 - val_loss: 0.2488 - val_accuracy: 0.7127\n",
      "Epoch 1761/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2489 - accuracy: 0.7121 - val_loss: 0.2488 - val_accuracy: 0.7127\n",
      "Epoch 1762/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2489 - accuracy: 0.7121 - val_loss: 0.2488 - val_accuracy: 0.7128\n",
      "Epoch 1763/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2488 - accuracy: 0.7120 - val_loss: 0.2488 - val_accuracy: 0.7127\n",
      "Epoch 1764/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2488 - accuracy: 0.7120 - val_loss: 0.2488 - val_accuracy: 0.7129\n",
      "Epoch 1765/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2488 - accuracy: 0.7120 - val_loss: 0.2488 - val_accuracy: 0.7129\n",
      "Epoch 1766/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2488 - accuracy: 0.7120 - val_loss: 0.2488 - val_accuracy: 0.7128\n",
      "Epoch 1767/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2488 - accuracy: 0.7120 - val_loss: 0.2488 - val_accuracy: 0.7129\n",
      "Epoch 1768/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2488 - accuracy: 0.7120 - val_loss: 0.2488 - val_accuracy: 0.7129\n",
      "Epoch 1769/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2487 - accuracy: 0.7120 - val_loss: 0.2487 - val_accuracy: 0.7129\n",
      "Epoch 1770/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2487 - accuracy: 0.7120 - val_loss: 0.2487 - val_accuracy: 0.7128\n",
      "Epoch 1771/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2487 - accuracy: 0.7120 - val_loss: 0.2487 - val_accuracy: 0.7128\n",
      "Epoch 1772/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2487 - accuracy: 0.7120 - val_loss: 0.2487 - val_accuracy: 0.7128\n",
      "Epoch 1773/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2487 - accuracy: 0.7120 - val_loss: 0.2487 - val_accuracy: 0.7128\n",
      "Epoch 1774/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2487 - accuracy: 0.7120 - val_loss: 0.2487 - val_accuracy: 0.7129\n",
      "Epoch 1775/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2487 - accuracy: 0.7120 - val_loss: 0.2487 - val_accuracy: 0.7129\n",
      "Epoch 1776/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2487 - accuracy: 0.7120 - val_loss: 0.2487 - val_accuracy: 0.7129\n",
      "Epoch 1777/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2486 - accuracy: 0.7119 - val_loss: 0.2487 - val_accuracy: 0.7129\n",
      "Epoch 1778/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2486 - accuracy: 0.7119 - val_loss: 0.2487 - val_accuracy: 0.7129\n",
      "Epoch 1779/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2486 - accuracy: 0.7120 - val_loss: 0.2486 - val_accuracy: 0.7130\n",
      "Epoch 1780/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2486 - accuracy: 0.7119 - val_loss: 0.2486 - val_accuracy: 0.7130\n",
      "Epoch 1781/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2486 - accuracy: 0.7119 - val_loss: 0.2486 - val_accuracy: 0.7129\n",
      "Epoch 1782/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2486 - accuracy: 0.7118 - val_loss: 0.2486 - val_accuracy: 0.7130\n",
      "Epoch 1783/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2485 - accuracy: 0.7119 - val_loss: 0.2485 - val_accuracy: 0.7128\n",
      "Epoch 1784/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2485 - accuracy: 0.7119 - val_loss: 0.2485 - val_accuracy: 0.7128\n",
      "Epoch 1785/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2485 - accuracy: 0.7118 - val_loss: 0.2484 - val_accuracy: 0.7129\n",
      "Epoch 1786/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2484 - accuracy: 0.7119 - val_loss: 0.2484 - val_accuracy: 0.7128\n",
      "Epoch 1787/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2484 - accuracy: 0.7119 - val_loss: 0.2483 - val_accuracy: 0.7128\n",
      "Epoch 1788/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2483 - accuracy: 0.7119 - val_loss: 0.2483 - val_accuracy: 0.7130\n",
      "Epoch 1789/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2483 - accuracy: 0.7119 - val_loss: 0.2482 - val_accuracy: 0.7129\n",
      "Epoch 1790/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2482 - accuracy: 0.7120 - val_loss: 0.2481 - val_accuracy: 0.7130\n",
      "Epoch 1791/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2480 - accuracy: 0.7119 - val_loss: 0.2478 - val_accuracy: 0.7131\n",
      "Epoch 1792/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2476 - accuracy: 0.7126 - val_loss: 0.2472 - val_accuracy: 0.7138\n",
      "Epoch 1793/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2467 - accuracy: 0.7132 - val_loss: 0.2463 - val_accuracy: 0.7143\n",
      "Epoch 1794/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2463 - accuracy: 0.7136 - val_loss: 0.2461 - val_accuracy: 0.7144\n",
      "Epoch 1795/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2463 - accuracy: 0.7139 - val_loss: 0.2461 - val_accuracy: 0.7146\n",
      "Epoch 1796/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2462 - accuracy: 0.7139 - val_loss: 0.2461 - val_accuracy: 0.7147\n",
      "Epoch 1797/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2462 - accuracy: 0.7139 - val_loss: 0.2461 - val_accuracy: 0.7147\n",
      "Epoch 1798/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2462 - accuracy: 0.7139 - val_loss: 0.2460 - val_accuracy: 0.7147\n",
      "Epoch 1799/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2462 - accuracy: 0.7139 - val_loss: 0.2460 - val_accuracy: 0.7147\n",
      "Epoch 1800/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2462 - accuracy: 0.7139 - val_loss: 0.2460 - val_accuracy: 0.7147\n",
      "Epoch 1801/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2462 - accuracy: 0.7139 - val_loss: 0.2460 - val_accuracy: 0.7147\n",
      "Epoch 1802/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2462 - accuracy: 0.7139 - val_loss: 0.2460 - val_accuracy: 0.7147\n",
      "Epoch 1803/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2462 - accuracy: 0.7139 - val_loss: 0.2460 - val_accuracy: 0.7147\n",
      "Epoch 1804/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2462 - accuracy: 0.7139 - val_loss: 0.2460 - val_accuracy: 0.7148\n",
      "Epoch 1805/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2462 - accuracy: 0.7139 - val_loss: 0.2460 - val_accuracy: 0.7148\n",
      "Epoch 1806/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2462 - accuracy: 0.7139 - val_loss: 0.2460 - val_accuracy: 0.7148\n",
      "Epoch 1807/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.7140 - val_loss: 0.2460 - val_accuracy: 0.7148\n",
      "Epoch 1808/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.7140 - val_loss: 0.2460 - val_accuracy: 0.7148\n",
      "Epoch 1809/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.7140 - val_loss: 0.2460 - val_accuracy: 0.7148\n",
      "Epoch 1810/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.7140 - val_loss: 0.2459 - val_accuracy: 0.7148\n",
      "Epoch 1811/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.7140 - val_loss: 0.2459 - val_accuracy: 0.7148\n",
      "Epoch 1812/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.7140 - val_loss: 0.2459 - val_accuracy: 0.7149\n",
      "Epoch 1813/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2461 - accuracy: 0.7140 - val_loss: 0.2459 - val_accuracy: 0.7149\n",
      "Epoch 1814/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2461 - accuracy: 0.7140 - val_loss: 0.2459 - val_accuracy: 0.7149\n",
      "Epoch 1815/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2461 - accuracy: 0.7140 - val_loss: 0.2459 - val_accuracy: 0.7149\n",
      "Epoch 1816/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2461 - accuracy: 0.7140 - val_loss: 0.2459 - val_accuracy: 0.7149\n",
      "Epoch 1817/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.7141 - val_loss: 0.2459 - val_accuracy: 0.7149\n",
      "Epoch 1818/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.7141 - val_loss: 0.2459 - val_accuracy: 0.7149\n",
      "Epoch 1819/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2460 - accuracy: 0.7141 - val_loss: 0.2459 - val_accuracy: 0.7150\n",
      "Epoch 1820/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2460 - accuracy: 0.7141 - val_loss: 0.2459 - val_accuracy: 0.7150\n",
      "Epoch 1821/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2460 - accuracy: 0.7141 - val_loss: 0.2459 - val_accuracy: 0.7150\n",
      "Epoch 1822/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2460 - accuracy: 0.7141 - val_loss: 0.2459 - val_accuracy: 0.7150\n",
      "Epoch 1823/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2460 - accuracy: 0.7141 - val_loss: 0.2458 - val_accuracy: 0.7150\n",
      "Epoch 1824/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2460 - accuracy: 0.7142 - val_loss: 0.2458 - val_accuracy: 0.7150\n",
      "Epoch 1825/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2460 - accuracy: 0.7142 - val_loss: 0.2458 - val_accuracy: 0.7150\n",
      "Epoch 1826/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2460 - accuracy: 0.7142 - val_loss: 0.2458 - val_accuracy: 0.7150\n",
      "Epoch 1827/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2460 - accuracy: 0.7142 - val_loss: 0.2458 - val_accuracy: 0.7150\n",
      "Epoch 1828/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2460 - accuracy: 0.7142 - val_loss: 0.2458 - val_accuracy: 0.7151\n",
      "Epoch 1829/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2460 - accuracy: 0.7142 - val_loss: 0.2458 - val_accuracy: 0.7151\n",
      "Epoch 1830/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2460 - accuracy: 0.7142 - val_loss: 0.2458 - val_accuracy: 0.7151\n",
      "Epoch 1831/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.7142 - val_loss: 0.2458 - val_accuracy: 0.7151\n",
      "Epoch 1832/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.7142 - val_loss: 0.2458 - val_accuracy: 0.7150\n",
      "Epoch 1833/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.7142 - val_loss: 0.2458 - val_accuracy: 0.7151\n",
      "Epoch 1834/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.7142 - val_loss: 0.2458 - val_accuracy: 0.7151\n",
      "Epoch 1835/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.7142 - val_loss: 0.2457 - val_accuracy: 0.7150\n",
      "Epoch 1836/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.7142 - val_loss: 0.2457 - val_accuracy: 0.7151\n",
      "Epoch 1837/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.7142 - val_loss: 0.2457 - val_accuracy: 0.7151\n",
      "Epoch 1838/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2459 - accuracy: 0.7142 - val_loss: 0.2457 - val_accuracy: 0.7151\n",
      "Epoch 1839/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.7142 - val_loss: 0.2457 - val_accuracy: 0.7151\n",
      "Epoch 1840/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.7142 - val_loss: 0.2457 - val_accuracy: 0.7151\n",
      "Epoch 1841/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.7142 - val_loss: 0.2457 - val_accuracy: 0.7151\n",
      "Epoch 1842/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.7142 - val_loss: 0.2457 - val_accuracy: 0.7151\n",
      "Epoch 1843/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.7142 - val_loss: 0.2457 - val_accuracy: 0.7151\n",
      "Epoch 1844/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.7143 - val_loss: 0.2457 - val_accuracy: 0.7151\n",
      "Epoch 1845/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.7143 - val_loss: 0.2457 - val_accuracy: 0.7151\n",
      "Epoch 1846/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.7143 - val_loss: 0.2457 - val_accuracy: 0.7151\n",
      "Epoch 1847/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2458 - accuracy: 0.7143 - val_loss: 0.2456 - val_accuracy: 0.7151\n",
      "Epoch 1848/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.7143 - val_loss: 0.2456 - val_accuracy: 0.7151\n",
      "Epoch 1849/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.7143 - val_loss: 0.2456 - val_accuracy: 0.7151\n",
      "Epoch 1850/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2458 - accuracy: 0.7144 - val_loss: 0.2456 - val_accuracy: 0.7151\n",
      "Epoch 1851/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.7144 - val_loss: 0.2456 - val_accuracy: 0.7152\n",
      "Epoch 1852/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.7144 - val_loss: 0.2456 - val_accuracy: 0.7152\n",
      "Epoch 1853/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2458 - accuracy: 0.7144 - val_loss: 0.2456 - val_accuracy: 0.7152\n",
      "Epoch 1854/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.7144 - val_loss: 0.2456 - val_accuracy: 0.7152\n",
      "Epoch 1855/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.7144 - val_loss: 0.2456 - val_accuracy: 0.7152\n",
      "Epoch 1856/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.7144 - val_loss: 0.2456 - val_accuracy: 0.7152\n",
      "Epoch 1857/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.7144 - val_loss: 0.2456 - val_accuracy: 0.7153\n",
      "Epoch 1858/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.7144 - val_loss: 0.2456 - val_accuracy: 0.7152\n",
      "Epoch 1859/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.7144 - val_loss: 0.2456 - val_accuracy: 0.7152\n",
      "Epoch 1860/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.7145 - val_loss: 0.2455 - val_accuracy: 0.7153\n",
      "Epoch 1861/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.7144 - val_loss: 0.2455 - val_accuracy: 0.7153\n",
      "Epoch 1862/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.7144 - val_loss: 0.2455 - val_accuracy: 0.7153\n",
      "Epoch 1863/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.7144 - val_loss: 0.2455 - val_accuracy: 0.7153\n",
      "Epoch 1864/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.7144 - val_loss: 0.2455 - val_accuracy: 0.7153\n",
      "Epoch 1865/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.7144 - val_loss: 0.2455 - val_accuracy: 0.7153\n",
      "Epoch 1866/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2457 - accuracy: 0.7144 - val_loss: 0.2455 - val_accuracy: 0.7153\n",
      "Epoch 1867/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.7144 - val_loss: 0.2455 - val_accuracy: 0.7153\n",
      "Epoch 1868/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.7144 - val_loss: 0.2455 - val_accuracy: 0.7153\n",
      "Epoch 1869/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.7145 - val_loss: 0.2455 - val_accuracy: 0.7153\n",
      "Epoch 1870/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.7144 - val_loss: 0.2455 - val_accuracy: 0.7153\n",
      "Epoch 1871/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.7145 - val_loss: 0.2455 - val_accuracy: 0.7154\n",
      "Epoch 1872/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.7145 - val_loss: 0.2454 - val_accuracy: 0.7153\n",
      "Epoch 1873/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.7145 - val_loss: 0.2454 - val_accuracy: 0.7153\n",
      "Epoch 1874/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.7145 - val_loss: 0.2454 - val_accuracy: 0.7153\n",
      "Epoch 1875/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.7146 - val_loss: 0.2454 - val_accuracy: 0.7153\n",
      "Epoch 1876/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.7146 - val_loss: 0.2454 - val_accuracy: 0.7153\n",
      "Epoch 1877/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.7146 - val_loss: 0.2454 - val_accuracy: 0.7153\n",
      "Epoch 1878/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2456 - accuracy: 0.7146 - val_loss: 0.2454 - val_accuracy: 0.7153\n",
      "Epoch 1879/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.7146 - val_loss: 0.2454 - val_accuracy: 0.7153\n",
      "Epoch 1880/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.7146 - val_loss: 0.2454 - val_accuracy: 0.7153\n",
      "Epoch 1881/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2456 - accuracy: 0.7146 - val_loss: 0.2454 - val_accuracy: 0.7153\n",
      "Epoch 1882/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.7146 - val_loss: 0.2454 - val_accuracy: 0.7153\n",
      "Epoch 1883/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.7146 - val_loss: 0.2454 - val_accuracy: 0.7154\n",
      "Epoch 1884/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.7146 - val_loss: 0.2453 - val_accuracy: 0.7154\n",
      "Epoch 1885/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2455 - accuracy: 0.7146 - val_loss: 0.2453 - val_accuracy: 0.7154\n",
      "Epoch 1886/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.7147 - val_loss: 0.2453 - val_accuracy: 0.7154\n",
      "Epoch 1887/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.7147 - val_loss: 0.2453 - val_accuracy: 0.7154\n",
      "Epoch 1888/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.7147 - val_loss: 0.2453 - val_accuracy: 0.7154\n",
      "Epoch 1889/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.7147 - val_loss: 0.2453 - val_accuracy: 0.7154\n",
      "Epoch 1890/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.7147 - val_loss: 0.2453 - val_accuracy: 0.7154\n",
      "Epoch 1891/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.7147 - val_loss: 0.2453 - val_accuracy: 0.7155\n",
      "Epoch 1892/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2455 - accuracy: 0.7147 - val_loss: 0.2453 - val_accuracy: 0.7154\n",
      "Epoch 1893/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2455 - accuracy: 0.7148 - val_loss: 0.2453 - val_accuracy: 0.7155\n",
      "Epoch 1894/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2455 - accuracy: 0.7148 - val_loss: 0.2453 - val_accuracy: 0.7155\n",
      "Epoch 1895/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.7148 - val_loss: 0.2453 - val_accuracy: 0.7155\n",
      "Epoch 1896/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.7148 - val_loss: 0.2452 - val_accuracy: 0.7155\n",
      "Epoch 1897/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.7148 - val_loss: 0.2452 - val_accuracy: 0.7155\n",
      "Epoch 1898/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.7148 - val_loss: 0.2452 - val_accuracy: 0.7155\n",
      "Epoch 1899/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.7149 - val_loss: 0.2452 - val_accuracy: 0.7155\n",
      "Epoch 1900/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2454 - accuracy: 0.7149 - val_loss: 0.2452 - val_accuracy: 0.7155\n",
      "Epoch 1901/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2454 - accuracy: 0.7149 - val_loss: 0.2452 - val_accuracy: 0.7155\n",
      "Epoch 1902/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2454 - accuracy: 0.7149 - val_loss: 0.2452 - val_accuracy: 0.7155\n",
      "Epoch 1903/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2454 - accuracy: 0.7149 - val_loss: 0.2452 - val_accuracy: 0.7155\n",
      "Epoch 1904/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2454 - accuracy: 0.7149 - val_loss: 0.2452 - val_accuracy: 0.7155\n",
      "Epoch 1905/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2454 - accuracy: 0.7149 - val_loss: 0.2452 - val_accuracy: 0.7156\n",
      "Epoch 1906/10000\n",
      "281/281 [==============================] - 1s 4ms/step - loss: 0.2454 - accuracy: 0.7149 - val_loss: 0.2452 - val_accuracy: 0.7156\n",
      "Epoch 1907/10000\n",
      "281/281 [==============================] - 1s 3ms/step - loss: 0.2454 - accuracy: 0.7149 - val_loss: 0.2452 - val_accuracy: 0.7156\n",
      "Epoch 1908/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2453 - accuracy: 0.7149 - val_loss: 0.2452 - val_accuracy: 0.7157\n",
      "Epoch 1909/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.7149 - val_loss: 0.2451 - val_accuracy: 0.7157\n",
      "Epoch 1910/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.7149 - val_loss: 0.2451 - val_accuracy: 0.7157\n",
      "Epoch 1911/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.7149 - val_loss: 0.2451 - val_accuracy: 0.7157\n",
      "Epoch 1912/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.7150 - val_loss: 0.2451 - val_accuracy: 0.7157\n",
      "Epoch 1913/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.7150 - val_loss: 0.2451 - val_accuracy: 0.7157\n",
      "Epoch 1914/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.7150 - val_loss: 0.2451 - val_accuracy: 0.7157\n",
      "Epoch 1915/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.7150 - val_loss: 0.2451 - val_accuracy: 0.7158\n",
      "Epoch 1916/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.7150 - val_loss: 0.2451 - val_accuracy: 0.7158\n",
      "Epoch 1917/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.7150 - val_loss: 0.2451 - val_accuracy: 0.7158\n",
      "Epoch 1918/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.7150 - val_loss: 0.2451 - val_accuracy: 0.7158\n",
      "Epoch 1919/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.7150 - val_loss: 0.2451 - val_accuracy: 0.7158\n",
      "Epoch 1920/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.7151 - val_loss: 0.2451 - val_accuracy: 0.7158\n",
      "Epoch 1921/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.7150 - val_loss: 0.2450 - val_accuracy: 0.7159\n",
      "Epoch 1922/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2452 - accuracy: 0.7151 - val_loss: 0.2450 - val_accuracy: 0.7159\n",
      "Epoch 1923/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.7151 - val_loss: 0.2450 - val_accuracy: 0.7159\n",
      "Epoch 1924/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.7151 - val_loss: 0.2450 - val_accuracy: 0.7158\n",
      "Epoch 1925/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.7151 - val_loss: 0.2450 - val_accuracy: 0.7159\n",
      "Epoch 1926/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.7151 - val_loss: 0.2450 - val_accuracy: 0.7159\n",
      "Epoch 1927/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.7151 - val_loss: 0.2450 - val_accuracy: 0.7159\n",
      "Epoch 1928/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.7151 - val_loss: 0.2450 - val_accuracy: 0.7159\n",
      "Epoch 1929/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.7151 - val_loss: 0.2450 - val_accuracy: 0.7159\n",
      "Epoch 1930/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.7151 - val_loss: 0.2450 - val_accuracy: 0.7159\n",
      "Epoch 1931/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.7151 - val_loss: 0.2450 - val_accuracy: 0.7159\n",
      "Epoch 1932/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.7151 - val_loss: 0.2450 - val_accuracy: 0.7159\n",
      "Epoch 1933/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.7151 - val_loss: 0.2449 - val_accuracy: 0.7159\n",
      "Epoch 1934/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.7151 - val_loss: 0.2449 - val_accuracy: 0.7159\n",
      "Epoch 1935/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.7152 - val_loss: 0.2449 - val_accuracy: 0.7159\n",
      "Epoch 1936/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2451 - accuracy: 0.7151 - val_loss: 0.2449 - val_accuracy: 0.7159\n",
      "Epoch 1937/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.7151 - val_loss: 0.2449 - val_accuracy: 0.7159\n",
      "Epoch 1938/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2451 - accuracy: 0.7152 - val_loss: 0.2449 - val_accuracy: 0.7159\n",
      "Epoch 1939/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.7152 - val_loss: 0.2449 - val_accuracy: 0.7159\n",
      "Epoch 1940/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.7152 - val_loss: 0.2449 - val_accuracy: 0.7160\n",
      "Epoch 1941/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.7152 - val_loss: 0.2449 - val_accuracy: 0.7159\n",
      "Epoch 1942/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2451 - accuracy: 0.7152 - val_loss: 0.2449 - val_accuracy: 0.7160\n",
      "Epoch 1943/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.7152 - val_loss: 0.2449 - val_accuracy: 0.7160\n",
      "Epoch 1944/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2451 - accuracy: 0.7152 - val_loss: 0.2449 - val_accuracy: 0.7160\n",
      "Epoch 1945/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2451 - accuracy: 0.7152 - val_loss: 0.2448 - val_accuracy: 0.7160\n",
      "Epoch 1946/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2451 - accuracy: 0.7152 - val_loss: 0.2448 - val_accuracy: 0.7160\n",
      "Epoch 1947/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.7152 - val_loss: 0.2448 - val_accuracy: 0.7160\n",
      "Epoch 1948/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.7152 - val_loss: 0.2448 - val_accuracy: 0.7161\n",
      "Epoch 1949/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.7152 - val_loss: 0.2448 - val_accuracy: 0.7160\n",
      "Epoch 1950/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.7152 - val_loss: 0.2448 - val_accuracy: 0.7161\n",
      "Epoch 1951/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.7152 - val_loss: 0.2448 - val_accuracy: 0.7161\n",
      "Epoch 1952/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.7152 - val_loss: 0.2448 - val_accuracy: 0.7161\n",
      "Epoch 1953/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.7153 - val_loss: 0.2448 - val_accuracy: 0.7161\n",
      "Epoch 1954/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.7153 - val_loss: 0.2448 - val_accuracy: 0.7161\n",
      "Epoch 1955/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.7153 - val_loss: 0.2448 - val_accuracy: 0.7161\n",
      "Epoch 1956/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.7153 - val_loss: 0.2448 - val_accuracy: 0.7162\n",
      "Epoch 1957/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2450 - accuracy: 0.7153 - val_loss: 0.2448 - val_accuracy: 0.7162\n",
      "Epoch 1958/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.7153 - val_loss: 0.2447 - val_accuracy: 0.7162\n",
      "Epoch 1959/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.7153 - val_loss: 0.2447 - val_accuracy: 0.7162\n",
      "Epoch 1960/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.7153 - val_loss: 0.2447 - val_accuracy: 0.7162\n",
      "Epoch 1961/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.7154 - val_loss: 0.2447 - val_accuracy: 0.7162\n",
      "Epoch 1962/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.7153 - val_loss: 0.2447 - val_accuracy: 0.7162\n",
      "Epoch 1963/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.7153 - val_loss: 0.2447 - val_accuracy: 0.7162\n",
      "Epoch 1964/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.7153 - val_loss: 0.2447 - val_accuracy: 0.7162\n",
      "Epoch 1965/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.7153 - val_loss: 0.2447 - val_accuracy: 0.7162\n",
      "Epoch 1966/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2449 - accuracy: 0.7153 - val_loss: 0.2447 - val_accuracy: 0.7162\n",
      "Epoch 1967/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.7153 - val_loss: 0.2447 - val_accuracy: 0.7162\n",
      "Epoch 1968/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.7153 - val_loss: 0.2447 - val_accuracy: 0.7162\n",
      "Epoch 1969/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.7153 - val_loss: 0.2447 - val_accuracy: 0.7162\n",
      "Epoch 1970/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.7153 - val_loss: 0.2446 - val_accuracy: 0.7162\n",
      "Epoch 1971/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.7153 - val_loss: 0.2446 - val_accuracy: 0.7162\n",
      "Epoch 1972/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.7153 - val_loss: 0.2446 - val_accuracy: 0.7162\n",
      "Epoch 1973/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.7153 - val_loss: 0.2446 - val_accuracy: 0.7162\n",
      "Epoch 1974/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.7153 - val_loss: 0.2446 - val_accuracy: 0.7162\n",
      "Epoch 1975/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.7153 - val_loss: 0.2446 - val_accuracy: 0.7162\n",
      "Epoch 1976/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.7153 - val_loss: 0.2446 - val_accuracy: 0.7163\n",
      "Epoch 1977/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2448 - accuracy: 0.7153 - val_loss: 0.2446 - val_accuracy: 0.7163\n",
      "Epoch 1978/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2448 - accuracy: 0.7153 - val_loss: 0.2446 - val_accuracy: 0.7163\n",
      "Epoch 1979/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.7154 - val_loss: 0.2446 - val_accuracy: 0.7163\n",
      "Epoch 1980/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.7153 - val_loss: 0.2446 - val_accuracy: 0.7163\n",
      "Epoch 1981/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.7154 - val_loss: 0.2446 - val_accuracy: 0.7163\n",
      "Epoch 1982/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.7154 - val_loss: 0.2446 - val_accuracy: 0.7163\n",
      "Epoch 1983/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.7153 - val_loss: 0.2445 - val_accuracy: 0.7163\n",
      "Epoch 1984/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.7153 - val_loss: 0.2445 - val_accuracy: 0.7163\n",
      "Epoch 1985/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.7154 - val_loss: 0.2445 - val_accuracy: 0.7163\n",
      "Epoch 1986/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.7153 - val_loss: 0.2445 - val_accuracy: 0.7164\n",
      "Epoch 1987/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.7154 - val_loss: 0.2445 - val_accuracy: 0.7164\n",
      "Epoch 1988/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.7154 - val_loss: 0.2445 - val_accuracy: 0.7164\n",
      "Epoch 1989/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.7154 - val_loss: 0.2445 - val_accuracy: 0.7164\n",
      "Epoch 1990/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.7154 - val_loss: 0.2445 - val_accuracy: 0.7164\n",
      "Epoch 1991/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.7154 - val_loss: 0.2445 - val_accuracy: 0.7164\n",
      "Epoch 1992/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2447 - accuracy: 0.7154 - val_loss: 0.2445 - val_accuracy: 0.7164\n",
      "Epoch 1993/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.7154 - val_loss: 0.2445 - val_accuracy: 0.7165\n",
      "Epoch 1994/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2447 - accuracy: 0.7155 - val_loss: 0.2445 - val_accuracy: 0.7164\n",
      "Epoch 1995/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.7155 - val_loss: 0.2445 - val_accuracy: 0.7165\n",
      "Epoch 1996/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.7155 - val_loss: 0.2444 - val_accuracy: 0.7165\n",
      "Epoch 1997/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.7155 - val_loss: 0.2444 - val_accuracy: 0.7165\n",
      "Epoch 1998/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.7155 - val_loss: 0.2444 - val_accuracy: 0.7165\n",
      "Epoch 1999/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.7156 - val_loss: 0.2444 - val_accuracy: 0.7165\n",
      "Epoch 2000/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2447 - accuracy: 0.7156 - val_loss: 0.2444 - val_accuracy: 0.7165\n",
      "Epoch 2001/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.7156 - val_loss: 0.2444 - val_accuracy: 0.7165\n",
      "Epoch 2002/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.7156 - val_loss: 0.2444 - val_accuracy: 0.7165\n",
      "Epoch 2003/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.7156 - val_loss: 0.2444 - val_accuracy: 0.7165\n",
      "Epoch 2004/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.7156 - val_loss: 0.2444 - val_accuracy: 0.7165\n",
      "Epoch 2005/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.7156 - val_loss: 0.2444 - val_accuracy: 0.7166\n",
      "Epoch 2006/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.7156 - val_loss: 0.2444 - val_accuracy: 0.7165\n",
      "Epoch 2007/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2446 - accuracy: 0.7156 - val_loss: 0.2444 - val_accuracy: 0.7165\n",
      "Epoch 2008/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.7156 - val_loss: 0.2444 - val_accuracy: 0.7165\n",
      "Epoch 2009/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2446 - accuracy: 0.7157 - val_loss: 0.2444 - val_accuracy: 0.7165\n",
      "Epoch 2010/10000\n",
      "281/281 [==============================] - 1s 3ms/step - loss: 0.2446 - accuracy: 0.7157 - val_loss: 0.2443 - val_accuracy: 0.7166\n",
      "Epoch 2011/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2446 - accuracy: 0.7157 - val_loss: 0.2443 - val_accuracy: 0.7166\n",
      "Epoch 2012/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2446 - accuracy: 0.7157 - val_loss: 0.2443 - val_accuracy: 0.7166\n",
      "Epoch 2013/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.7157 - val_loss: 0.2443 - val_accuracy: 0.7166\n",
      "Epoch 2014/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.7157 - val_loss: 0.2443 - val_accuracy: 0.7167\n",
      "Epoch 2015/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.7157 - val_loss: 0.2443 - val_accuracy: 0.7166\n",
      "Epoch 2016/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.7157 - val_loss: 0.2443 - val_accuracy: 0.7167\n",
      "Epoch 2017/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2445 - accuracy: 0.7157 - val_loss: 0.2443 - val_accuracy: 0.7167\n",
      "Epoch 2018/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2445 - accuracy: 0.7157 - val_loss: 0.2443 - val_accuracy: 0.7167\n",
      "Epoch 2019/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.7157 - val_loss: 0.2443 - val_accuracy: 0.7167\n",
      "Epoch 2020/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.7157 - val_loss: 0.2443 - val_accuracy: 0.7167\n",
      "Epoch 2021/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.7158 - val_loss: 0.2443 - val_accuracy: 0.7168\n",
      "Epoch 2022/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.7158 - val_loss: 0.2443 - val_accuracy: 0.7168\n",
      "Epoch 2023/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.7158 - val_loss: 0.2442 - val_accuracy: 0.7168\n",
      "Epoch 2024/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.7158 - val_loss: 0.2442 - val_accuracy: 0.7168\n",
      "Epoch 2025/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.7158 - val_loss: 0.2442 - val_accuracy: 0.7168\n",
      "Epoch 2026/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.7158 - val_loss: 0.2442 - val_accuracy: 0.7168\n",
      "Epoch 2027/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.7158 - val_loss: 0.2442 - val_accuracy: 0.7169\n",
      "Epoch 2028/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.7158 - val_loss: 0.2442 - val_accuracy: 0.7169\n",
      "Epoch 2029/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.7158 - val_loss: 0.2442 - val_accuracy: 0.7169\n",
      "Epoch 2030/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2444 - accuracy: 0.7158 - val_loss: 0.2442 - val_accuracy: 0.7169\n",
      "Epoch 2031/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.7159 - val_loss: 0.2442 - val_accuracy: 0.7169\n",
      "Epoch 2032/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.7158 - val_loss: 0.2442 - val_accuracy: 0.7169\n",
      "Epoch 2033/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.7158 - val_loss: 0.2442 - val_accuracy: 0.7169\n",
      "Epoch 2034/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.7159 - val_loss: 0.2442 - val_accuracy: 0.7169\n",
      "Epoch 2035/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.7159 - val_loss: 0.2442 - val_accuracy: 0.7169\n",
      "Epoch 2036/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.7159 - val_loss: 0.2442 - val_accuracy: 0.7169\n",
      "Epoch 2037/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.7159 - val_loss: 0.2441 - val_accuracy: 0.7169\n",
      "Epoch 2038/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.7159 - val_loss: 0.2441 - val_accuracy: 0.7169\n",
      "Epoch 2039/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2444 - accuracy: 0.7159 - val_loss: 0.2441 - val_accuracy: 0.7168\n",
      "Epoch 2040/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.7159 - val_loss: 0.2441 - val_accuracy: 0.7168\n",
      "Epoch 2041/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.7159 - val_loss: 0.2441 - val_accuracy: 0.7169\n",
      "Epoch 2042/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.7159 - val_loss: 0.2441 - val_accuracy: 0.7169\n",
      "Epoch 2043/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2443 - accuracy: 0.7160 - val_loss: 0.2441 - val_accuracy: 0.7169\n",
      "Epoch 2044/10000\n",
      "281/281 [==============================] - 0s 1ms/step - loss: 0.2443 - accuracy: 0.7159 - val_loss: 0.2441 - val_accuracy: 0.7169\n",
      "Epoch 2045/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.7159 - val_loss: 0.2441 - val_accuracy: 0.7169\n",
      "Epoch 2046/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2443 - accuracy: 0.7160 - val_loss: 0.2441 - val_accuracy: 0.7169\n",
      "Epoch 2047/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.7160 - val_loss: 0.2441 - val_accuracy: 0.7170\n",
      "Epoch 2048/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.7160 - val_loss: 0.2441 - val_accuracy: 0.7170\n",
      "Epoch 2049/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2443 - accuracy: 0.7160 - val_loss: 0.2441 - val_accuracy: 0.7170\n",
      "Epoch 2050/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2443 - accuracy: 0.7160 - val_loss: 0.2441 - val_accuracy: 0.7170\n",
      "Epoch 2051/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2443 - accuracy: 0.7160 - val_loss: 0.2440 - val_accuracy: 0.7170\n",
      "Epoch 2052/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.7160 - val_loss: 0.2440 - val_accuracy: 0.7170\n",
      "Epoch 2053/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.7160 - val_loss: 0.2440 - val_accuracy: 0.7171\n",
      "Epoch 2054/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2443 - accuracy: 0.7160 - val_loss: 0.2440 - val_accuracy: 0.7171\n",
      "Epoch 2055/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.7160 - val_loss: 0.2440 - val_accuracy: 0.7171\n",
      "Epoch 2056/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.7160 - val_loss: 0.2440 - val_accuracy: 0.7171\n",
      "Epoch 2057/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.7160 - val_loss: 0.2440 - val_accuracy: 0.7171\n",
      "Epoch 2058/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.7160 - val_loss: 0.2440 - val_accuracy: 0.7171\n",
      "Epoch 2059/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2442 - accuracy: 0.7160 - val_loss: 0.2440 - val_accuracy: 0.7171\n",
      "Epoch 2060/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.7161 - val_loss: 0.2440 - val_accuracy: 0.7171\n",
      "Epoch 2061/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2442 - accuracy: 0.7161 - val_loss: 0.2440 - val_accuracy: 0.7171\n",
      "Epoch 2062/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.7161 - val_loss: 0.2440 - val_accuracy: 0.7171\n",
      "Epoch 2063/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.7161 - val_loss: 0.2440 - val_accuracy: 0.7171\n",
      "Epoch 2064/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.7161 - val_loss: 0.2440 - val_accuracy: 0.7171\n",
      "Epoch 2065/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.7161 - val_loss: 0.2439 - val_accuracy: 0.7171\n",
      "Epoch 2066/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.7161 - val_loss: 0.2439 - val_accuracy: 0.7171\n",
      "Epoch 2067/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.7161 - val_loss: 0.2439 - val_accuracy: 0.7171\n",
      "Epoch 2068/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2442 - accuracy: 0.7161 - val_loss: 0.2439 - val_accuracy: 0.7171\n",
      "Epoch 2069/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2442 - accuracy: 0.7161 - val_loss: 0.2439 - val_accuracy: 0.7171\n",
      "Epoch 2070/10000\n",
      "281/281 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.7161 - val_loss: 0.2439 - val_accuracy: 0.7171\n",
      "Epoch 2071/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2441 - accuracy: 0.7161 - val_loss: 0.2439 - val_accuracy: 0.7171\n",
      "Epoch 2072/10000\n",
      "281/281 [==============================] - 1s 2ms/step - loss: 0.2441 - accuracy: 0.7161 - val_loss: 0.2439 - val_accuracy: 0.7171\n",
      "Epoch 2073/10000\n",
      " 85/281 [========>.....................] - ETA: 0s - loss: 0.2424 - accuracy: 0.7187"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"archimedes-dl-w\")\n",
    "with mlflow.start_run():\n",
    "    mlflow.tensorflow.autolog()\n",
    "    num_features = x_train.shape[1]\n",
    "    tiny = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(main_units, activation=tf.nn.relu, input_shape=(num_features,)),\n",
    "        tf.keras.layers.Dense(num_classes, activation=tf.nn.sigmoid)])\n",
    "\n",
    "    size_histories['fcnn/tiny'] = compile_and_fit(tiny, train_dataset, \n",
    "                                                  test_dataset,\n",
    "                                                  \"fcnn/tiny\", \n",
    "                                                   optimizer=get_optimizer(),\n",
    "    #                                             optimizer=tf.keras.optimizers.Adam(lr), \n",
    "    #                                               optimizer = tf.keras.optimizers.SGD(lr=lr, momentum=0.9),\n",
    "                                                  max_epochs=num_epochs)\n",
    "\n",
    "print(\"\\n#######################Evaluation###########################\")\n",
    "# Evaluate the model on the test data using `evaluate`\n",
    "print('train acc:', max(size_histories['fcnn/tiny'].history[\"accuracy\"]))\n",
    "print('test acc:', max(size_histories['fcnn/tiny'].history[\"val_accuracy\"]))\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = [20.0, 15.0]\n",
    "plot_report(size_histories, metric='accuracy')\n",
    "plot_report(size_histories, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    mlflow.tensorflow.autolog()\n",
    "    small_model = tf.keras.Sequential([\n",
    "        # `input_shape` is only required here so that `.summary` works.\n",
    "        tf.keras.layers.Dense(main_units, activation=tf.nn.relu, input_shape=(num_features,)),\n",
    "        tf.keras.layers.Dense(secondary_units, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(num_classes, activation=tf.nn.sigmoid)\n",
    "    ])\n",
    "    size_histories['fcnn/small'] = compile_and_fit(small_model, train_dataset, \n",
    "                                                  test_dataset,'fcnn/small',\n",
    "    #                                               optimizer=get_optimizer(),\n",
    "                                                  optimizer=tf.keras.optimizers.Adam(lr), \n",
    "    #                                               optimizer = tf.keras.optimizers.SGD(lr=lr, momentum=0.9),\n",
    "                                                  max_epochs=num_epochs)\n",
    "\n",
    "print(\"\\n#######################Evaluation###########################\")\n",
    "# Evaluate the model on the test data using `evaluate`\n",
    "print('train acc:', max(size_histories['fcnn/small'].history[\"accuracy\"]))\n",
    "print('test acc:', max(size_histories['fcnn/small'].history[\"val_accuracy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_report(size_histories)\n",
    "plot_report(size_histories, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    mlflow.tensorflow.autolog()\n",
    "    large_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(main_units, activation=tf.nn.relu, input_shape=(num_features,)),  \n",
    "    tf.keras.layers.Dense(main_units, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(secondary_units, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(last_unit, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(num_classes, activation=tf.nn.sigmoid)\n",
    "])\n",
    "    size_histories['fcnn/large'] = compile_and_fit(large_model, train_dataset, \n",
    "                                                  test_dataset, \"fcnn/large\",\n",
    "                                                  optimizer=tf.keras.optimizers.Adam(lr), \n",
    "    #                                               optimizer=get_optimizer(), \n",
    "                                                  max_epochs=num_epochs)\n",
    "\n",
    "print(\"Evaluation\")\n",
    "# Evaluate the model on the test data using `evaluate`\n",
    "print('train acc:', max(size_histories['fcnn/large'].history[\"accuracy\"]))\n",
    "print('test acc:', max(size_histories['fcnn/large'].history[\"val_accuracy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_report(size_histories)\n",
    "plot_report(size_histories, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    mlflow.tensorflow.autolog()\n",
    "    tiny_dropout = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(main_units, activation=tf.nn.relu, input_shape=(num_features,)), \n",
    "        tf.keras.layers.Dropout(dr),\n",
    "        tf.keras.layers.Dense(main_units, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(secondary_units, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(last_unit, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dropout(dr),\n",
    "        tf.keras.layers.Dense(num_classes, activation=tf.nn.sigmoid)\n",
    "    ])\n",
    "    size_histories['fcnn/tiny/dropout'] = compile_and_fit(tiny_dropout, \n",
    "                                                      train_dataset,\n",
    "                                                      test_dataset,\n",
    "                                                      \"fcnn/tiny/dropout\", \n",
    "                                                      optimizer=tf.keras.optimizers.Adam(lr), \n",
    "                                                      max_epochs=num_epochs)\n",
    "\n",
    "print(\"\\n#######################EVALUATIO######################\")\n",
    "# Evaluate the model on the test data using `evaluate`\n",
    "print('train acc:', max(size_histories['fcnn/tiny/dropout'].history[\"accuracy\"]))\n",
    "print('test acc:', max(size_histories['fcnn/tiny/dropout'].history[\"val_accuracy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_report(size_histories)\n",
    "plot_report(size_histories, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regularizer_histories = {}\n",
    "regularizer_histories['large'] = size_histories['fcnn/large']\n",
    "regularizer_histories['dropout'] = size_histories['fcnn/tiny/dropout']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    mlflow.tensorflow.autolog()\n",
    "    l2_model = tf.keras.Sequential([\n",
    "    layers.Dense(main_units, activation=tf.nn.relu,\n",
    "                 kernel_regularizer=regularizers.l1(lr1),\n",
    "                 input_shape=(num_features,)),\n",
    "    layers.Dense(main_units, activation=tf.nn.relu,\n",
    "                 kernel_regularizer=regularizers.l1(lr1)),\n",
    "    layers.Dense(secondary_units, activation=tf.nn.relu,\n",
    "                 kernel_regularizer=regularizers.l1(lr1)),\n",
    "    layers.Dense(last_unit, activation=tf.nn.relu,\n",
    "                 kernel_regularizer=regularizers.l1(lr1)),\n",
    "    layers.Dense(num_classes, activation=tf.nn.sigmoid)\n",
    "])\n",
    "    regularizer_histories['l2'] = compile_and_fit(l2_model, train_dataset, \n",
    "                                              test_dataset, \n",
    "                                              optimizer=tf.keras.optimizers.Adam(lr),\n",
    "                                              name=\"regularizers/l2\")\n",
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"\\n#######################EVALUATIO######################\")\n",
    "print('train acc:', max(regularizer_histories['l2'].history[\"accuracy\"]))\n",
    "print('test acc:', max(regularizer_histories['l2'].history[\"val_accuracy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_report(regularizer_histories)\n",
    "plot_report(regularizer_histories, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    mlflow.tensorflow.autolog()\n",
    "    combined_model = tf.keras.Sequential([\n",
    "    layers.Dense(main_units, activation=tf.nn.relu,\n",
    "                 kernel_regularizer=regularizers.l1(lr1),\n",
    "                 input_shape=(num_features,)),\n",
    "    layers.Dense(main_units, activation=tf.nn.relu,\n",
    "                 kernel_regularizer=regularizers.l1(lr1)),\n",
    "    layers.Dense(secondary_units, activation=tf.nn.relu,\n",
    "                 kernel_regularizer=regularizers.l1(lr1)),\n",
    "    layers.Dense(last_unit, activation=tf.nn.relu,\n",
    "                 kernel_regularizer=regularizers.l1(lr1)),\n",
    "    tf.keras.layers.Dropout(dr),\n",
    "    layers.Dense(num_classes, activation=tf.nn.sigmoid)\n",
    "])\n",
    "\n",
    "    tf.keras.backend.clear_session()# para evitar que entrenamientos annteriores afecten\n",
    "    regularizer_histories['combined'] = compile_and_fit(combined_model, train_dataset, test_dataset, \"regularizers/combined\",\n",
    "                                                   optimizer=get_optimizer())\n",
    "\n",
    "# Evaluate the model on the test data using `evaluate`\n",
    "print()\n",
    "print('train acc:', max(regularizer_histories['combined'].history[\"accuracy\"]))\n",
    "print('test acc:', max(regularizer_histories['combined'].history[\"val_accuracy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_report(regularizer_histories)\n",
    "plot_report(regularizer_histories, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_histories = {}\n",
    "batch_histories['large'] = size_histories['fcnn/large']\n",
    "batch_histories['dropout'] = size_histories['fcnn/tiny/dropout']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_batch = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(main_units, activation=tf.nn.relu, input_shape=(num_features,)), \n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(main_units, activation=tf.nn.relu),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(secondary_units, activation=tf.nn.relu),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(last_unit, activation=tf.nn.relu),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(dr),\n",
    "    tf.keras.layers.Dense(num_classes, activation=tf.nn.sigmoid)\n",
    "])\n",
    "with mlflow.start_run():\n",
    "    mlflow.tensorflow.autolog()\n",
    "    batch_histories['fcnn/small/batch'] = compile_and_fit(small_batch, \n",
    "                                                          train_dataset,\n",
    "                                                          test_dataset,\n",
    "                                                          \"fcnn/small/batch\", \n",
    "                                                          optimizer=tf.keras.optimizers.Adam(lr), \n",
    "                                                          max_epochs=num_epochs)\n",
    "\n",
    "print(\"\\n#######################EVALUATION######################\")\n",
    "# Evaluate the model on the test data using `evaluate`\n",
    "print('train acc:', max(batch_histories['fcnn/small/batch'].history[\"accuracy\"]))\n",
    "print('test acc:', max(batch_histories['fcnn/small/batch'].history[\"val_accuracy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_report(batch_histories)\n",
    "plot_report(batch_histories, 'loss')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
